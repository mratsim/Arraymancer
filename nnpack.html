<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!--  This file is generated by Nim. -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Favicon -->
<link rel="shortcut icon" href="data:image/x-icon;base64,AAABAAEAEBAAAAEAIABoBAAAFgAAACgAAAAQAAAAIAAAAAEAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AAAAAAUAAAAF////AP///wD///8A////AP///wD///8A////AP///wD///8A////AAAAAAIAAABbAAAAlQAAAKIAAACbAAAAmwAAAKIAAACVAAAAWwAAAAL///8A////AP///wD///8A////AAAAABQAAADAAAAAYwAAAA3///8A////AP///wD///8AAAAADQAAAGMAAADAAAAAFP///wD///8A////AP///wAAAACdAAAAOv///wD///8A////AP///wD///8A////AP///wD///8AAAAAOgAAAJ3///8A////AP///wAAAAAnAAAAcP///wAAAAAoAAAASv///wD///8A////AP///wAAAABKAAAAKP///wAAAABwAAAAJ////wD///8AAAAAgQAAABwAAACIAAAAkAAAAJMAAACtAAAAFQAAABUAAACtAAAAkwAAAJAAAACIAAAAHAAAAIH///8A////AAAAAKQAAACrAAAAaP///wD///8AAAAARQAAANIAAADSAAAARf///wD///8AAAAAaAAAAKsAAACk////AAAAADMAAACcAAAAnQAAABj///8A////AP///wAAAAAYAAAAGP///wD///8A////AAAAABgAAACdAAAAnAAAADMAAAB1AAAAwwAAAP8AAADpAAAAsQAAAE4AAAAb////AP///wAAAAAbAAAATgAAALEAAADpAAAA/wAAAMMAAAB1AAAAtwAAAOkAAAD/AAAA/wAAAP8AAADvAAAA3gAAAN4AAADeAAAA3gAAAO8AAAD/AAAA/wAAAP8AAADpAAAAtwAAAGUAAAA/AAAA3wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAADfAAAAPwAAAGX///8A////AAAAAEgAAADtAAAAvwAAAL0AAADGAAAA7wAAAO8AAADGAAAAvQAAAL8AAADtAAAASP///wD///8A////AP///wD///8AAAAAO////wD///8A////AAAAAIcAAACH////AP///wD///8AAAAAO////wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A//8AAP//AAD4HwAA7/cAAN/7AAD//wAAoYUAAJ55AACf+QAAh+EAAAAAAADAAwAA4AcAAP5/AAD//wAA//8AAA=="/>
<link rel="icon" type="image/png" sizes="32x32" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABmJLR0QA/wD/AP+gvaeTAAAACXBIWXMAAA3XAAAN1wFCKJt4AAAAB3RJTUUH4QQQEwksSS9ZWwAAAk1JREFUWMPtll2ITVEUx39nn/O7Y5qR8f05wtCUUr6ZIS++8pEnkZInPImneaCQ5METNdOkeFBKUhMPRIkHKfEuUZSUlGlKPN2TrgfncpvmnntnmlEyq1Z7t89/rf9a6+y99oZxGZf/XeIq61EdtgKXgdXA0xrYAvBjOIF1AI9zvjcC74BSpndrJPkBWDScTF8Aa4E3wDlgHbASaANmVqlcCnwHvgDvgVfAJ+AikAAvgfVZwLnSVZHZaOuKoQi3ZOMi4NkYkpe1p4J7A8BpYAD49hfIy/oqG0+hLomiKP2L5L+1ubn5115S+3OAn4EnwBlgMzCjyt6ZAnQCJ4A7wOs88iRJHvw50HoujuPBoCKwHWiosy8MdfZnAdcHk8dxXFJ3VQbQlCTJvRBCGdRbD4M6uc5glpY3eAihpN5S5w12diSEcCCEcKUO4ljdr15T76ur1FDDLIQQ3qv71EdDOe3Kxj3leRXyk+pxdWnFWod6Wt2bY3de3aSuUHcPBVimHs7mK9WrmeOF6lR1o9qnzskh2ar2qm1qizpfXaPeVGdlmGN5pb09qMxz1Xb1kLqgzn1RyH7JUXW52lr5e/Kqi9qpto7V1atuUzfnARrV7jEib1T76gG2qxdGmXyiekkt1GswPTtek0aBfJp6YySGBfWg2tPQ0FAYgf1stUfdmdcjarbYJEniKIq6gY/Aw+zWHAC+p2labGpqiorFYgGYCEzN7oQdQClN07O1/EfDyGgC0ALMBdYAi4FyK+4H3gLPsxfR1zRNi+NP7nH5J+QntnXe5B5mpfQAAAAASUVORK5CYII=">

<!-- Google fonts -->
<link href='https://fonts.googleapis.com/css?family=Lato:400,600,900' rel='stylesheet' type='text/css'/>
<link href='https://fonts.googleapis.com/css?family=Source+Code+Pro:400,500,600' rel='stylesheet' type='text/css'/>

<!-- CSS -->
<title>src/arraymancer/nn_primitives/backend/nnpack</title>
<link rel="stylesheet" type="text/css" href="nimdoc.out.css">

<script type="text/javascript" src="dochack.js"></script>

<script type="text/javascript">
function main() {
  var pragmaDots = document.getElementsByClassName("pragmadots");
  for (var i = 0; i < pragmaDots.length; i++) {
    pragmaDots[i].onclick = function(event) {
      // Hide tease
      event.target.parentNode.style.display = "none";
      // Show actual
      event.target.parentNode.nextElementSibling.style.display = "inline";
    }
  }

  const toggleSwitch = document.querySelector('.theme-switch input[type="checkbox"]');
  function switchTheme(e) {
      if (e.target.checked) {
          document.documentElement.setAttribute('data-theme', 'dark');
          localStorage.setItem('theme', 'dark');
      } else {
          document.documentElement.setAttribute('data-theme', 'light');
          localStorage.setItem('theme', 'light');
      }
  }

  toggleSwitch.addEventListener('change', switchTheme, false);


  if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
    document.documentElement.setAttribute('data-theme', "dark");
    toggleSwitch.checked = true;
  } else if (window.matchMedia && window.matchMedia('(prefers-color-scheme: light)').matches) {
    document.documentElement.setAttribute('data-theme', "light");
    toggleSwitch.checked = false;
  } else {
    const currentTheme = localStorage.getItem('theme') ? localStorage.getItem('theme') : null;
    if (currentTheme) {
      document.documentElement.setAttribute('data-theme', currentTheme);

      if (currentTheme === 'dark') {
        toggleSwitch.checked = true;
      }
    }
  }
}
</script>

</head>

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Arraymancer - src/arraymancer/nn_primitives/backend/nnpack</title>

<link href="docutils.css" rel="stylesheet" type="text/css"/>
<link href="nav.css" rel="stylesheet" type="text/css"/>

<link href='http://fonts.googleapis.com/css?family=Raleway:400,600,900' rel='stylesheet' type='text/css'/>
<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:400,500,600' rel='stylesheet' type='text/css'/>

<a href="https://github.com/mratsim/arraymancer"><img style="position: fixed; top: 0; right: 0; border: 0; z-index: 10;" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_gray_6d6d6d.png?resize=150%2C150" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png"></a>

<body onload="main()">
<div class="document" id="documentId">
  <div class="container">
    <h1 class="title">src/arraymancer/nn_primitives/backend/nnpack</h1>
    <div class="row">
  <div class="three columns">
    <div class="theme-select-wrapper">
      <label for="theme-select">Theme:&nbsp;</label>
      <select id="theme-select" onchange="setTheme(this.value)">
        <option value="auto">ðŸŒ— Match OS</option>
        <option value="dark">ðŸŒ‘ Dark</option>
        <option value="light">ðŸŒ• Light</option>
      </select>
    </div>
    <div id="global-links">
      <ul class="simple">
        <li><a id="indexLink" href="theindex.html">Index</a></li>
      </ul>
    </div>
    <div id="searchInputDiv">
      Search: <input type="search" id="searchInput" onkeyup="search()"/>
    </div>
    <div>
      Group by:
      <select onchange="groupBy(this.value)">
        <option value="section">Section</option>
        <option value="type">Type</option>
      </select>
    </div>
    <ul class="simple simple-toc" id="toc-list">
  <li>
  <a class="reference reference-toplevel" href="#6" id="56">Imports</a>
</li>
<li>
  <details open>
    <summary><a class="reference reference-toplevel" href="#7" id="57">Types</a></summary>
    <ul class="simple simple-toc-section">
      <li><a class="reference" href="#nnp_activation" title="nnp_activation {.size: 4.} = enum
  nnp_activation_identity = 0, ## * ReLU activation f(x) := max(0, x)
  nnp_activation_relu = 1">nnp_activation</a></li>
<li><a class="reference" href="#nnp_convolution_algorithm" title="nnp_convolution_algorithm {.size: 4.} = enum
  nnp_convolution_algorithm_auto = 0, ## * Tiled convolution based on 2D Fourier transform with 8x8 blocks. Supports kernels up to 8x8.
  nnp_convolution_algorithm_ft8x8 = 1, ## * Tiled convolution based on 2D Fourier transform with 16x16 blocks. Supports kernels up to 16x16.
  nnp_convolution_algorithm_ft16x16 = 2, ## * Tiled convolution based on 2D Winograd transform F(3x3, 6x6) with 8x8 blocks. Supports only 3x3 kernels.
  nnp_convolution_algorithm_wt8x8 = 3, ## * Direct convolution via implicit GEMM.
  nnp_convolution_algorithm_implicit_gemm = 4, ## * Direct convolution implementation.
  nnp_convolution_algorithm_direct = 5, ## *
                                         ##  Tiled convolution based on 2D Winograd transform F(3x3, 6x6) with 8x8 blocks in FP16.
                                         ##  Supports only 3x3 kernels. Implemented only for new ARM processors (with NEON-HP),
                                         ##  on non-supported processors falls back to nnp_convolution_algorithm_wt8x8.
                                         ## 
  nnp_convolution_algorithm_wt8x8_fp16 = 6">nnp_convolution_algorithm</a></li>
<li><a class="reference" href="#nnp_convolution_transform_strategy" title="nnp_convolution_transform_strategy {.size: 4.} = enum
  nnp_convolution_transform_strategy_compute = 1,
  nnp_convolution_transform_strategy_precompute = 2,
  nnp_convolution_transform_strategy_reuse = 3">nnp_convolution_transform_strategy</a></li>
<li><a class="reference" href="#nnp_padding" title="nnp_padding {.bycopy.} = object
  top*: csize_t              ## * Padding above the image data
                             ## * Padding on the right of image data
  right*: csize_t            ## * Padding below the image data
  bottom*: csize_t           ## * Padding on the left of image data
  left*: csize_t">nnp_padding</a></li>
<li><a class="reference" href="#nnp_profile" title="nnp_profile {.bycopy.} = object
  total*: cdouble            ## * Time spent inside the function call, in seconds.
                             ## * Time spend on transformation of the input or input gradient tensor, in seconds.
  input_transform*: cdouble  ## * Time spend on transformation of the kernel or kernel gradient tensor, in seconds.
  kernel_transform*: cdouble ## * Time spend on transformation of the output or output gradient tensor, in seconds.
  output_transform*: cdouble ## * Time spend on multiplication-accumulation of transformed coefficients, in seconds.
  block_multiplication*: cdouble">nnp_profile</a></li>
<li><a class="reference" href="#nnp_size" title="nnp_size {.bycopy.} = object
  width*: csize_t ## * Width (horizontal size) of an image, kernel, or pooling filter.
                  ## * Height (vertical size) of an image, kernel, or pooling filter.
  height*: csize_t">nnp_size</a></li>
<li><a class="reference" href="#nnp_status" title="nnp_status {.size: 4.} = enum
  nnp_status_success = 0,   ## * NNPACK function was called with batch_size == 0.
  nnp_status_invalid_batch_size = 2, ## * NNPACK function was called with channels == 0.
  nnp_status_invalid_channels = 3, ## * NNPACK function was called with input_channels == 0.
  nnp_status_invalid_input_channels = 4, ## * NNPACK function was called with output_channels == 0.
  nnp_status_invalid_output_channels = 5, ## * NNPACK function was called with input_size.height == 0 or input_size.width == 0
  nnp_status_invalid_input_size = 10, ## * NNPACK function was called with input_stride.height == 0 or input_stride.width == 0
  nnp_status_invalid_input_stride = 11, ## * NNPACK function was called with input_padding not less than respective kernel (or pooling) size, i.e.:
                                         ## 
                                         ##   - input_padding.left   &gt;= kernel_size.width  (&gt;= pooling_size.width)
                                         ##   - input_padding.right  &gt;= kernel_size.width  (&gt;= pooling_size.width)
                                         ##   - input_padding.top    &gt;= kernel_size.height (&gt;= pooling_size.height)
                                         ##   - input_padding.bottom &gt;= kernel_size.height (&gt;= pooling_size.height)
                                         ## 
  nnp_status_invalid_input_padding = 12, ## * NNPACK function was called with kernel_size.height == 0 or kernel_size.width == 0
  nnp_status_invalid_kernel_size = 13, ## * NNPACK function was called with pooling_size.height == 0 or pooling_size.width == 0
  nnp_status_invalid_pooling_size = 14, ## * NNPACK function was called with pooling_stride.height == 0 or pooling_stride.width == 0
  nnp_status_invalid_pooling_stride = 15, ## * NNPACK function was called with convolution algorithm not in nnp_convolution_algorithm enumeration
  nnp_status_invalid_algorithm = 16, ## * NNPACK function was called with convolution transform strategy not in nnp_convolution_transform_strategy enum
  nnp_status_invalid_transform_strategy = 17, ## * NNPACK function was called with output_subsampling.height == 0 or output_subsampling.width == 0
  nnp_status_unsupported_input_size = 20, ## * NNPACK does not support the particular input stride for the function
  nnp_status_unsupported_input_stride = 21, ## * NNPACK does not support the particular input padding for the function
  nnp_status_unsupported_input_padding = 22, ## * NNPACK does not support the particular kernel size for the function
  nnp_status_unsupported_kernel_size = 23, ## * NNPACK does not support the particular pooling size for the function
  nnp_status_unsupported_pooling_size = 24, ## * NNPACK does not support the particular pooling stride for the function
  nnp_status_unsupported_pooling_stride = 25, ## * NNPACK does not support the particular convolution algorithm for the function
  nnp_status_unsupported_algorithm = 26, ## * NNPACK does not support the particular convolution transform strategy for the algorithm
  nnp_status_unsupported_transform_strategy = 27, ## * NNPACK does not support the particular activation function for the function
  nnp_status_unsupported_activation = 28, ## * NNPACK does not support the particular activation function parameters for the function
  nnp_status_unsupported_activation_parameters = 29, ## * NNPACK function was called before the library was initialized
  nnp_status_uninitialized = 50, ## * NNPACK does not implement this function for the host CPU
  nnp_status_unsupported_hardware = 51, ## * NNPACK failed to allocate memory for temporary buffers
  nnp_status_out_of_memory = 52, ## * Scratch space buffer is too small
  nnp_status_insufficient_buffer = 53, ## * Scratch space buffer is not properly aligned
  nnp_status_misaligned_buffer = 54">nnp_status</a></li>
<li><a class="reference" href="#pthreadpool_t" title="pthreadpool_t = pointer">pthreadpool_t</a></li>

    </ul>
  </details>
</li>
<li>
  <details open>
    <summary><a class="reference reference-toplevel" href="#10" id="60">Consts</a></summary>
    <ul class="simple simple-toc-section">
      <li><a class="reference" href="#nnp_convolution_transform_strategy_block_based" title="nnp_convolution_transform_strategy_block_based = nnp_convolution_transform_strategy_compute">nnp_convolution_transform_strategy_block_based</a></li>
<li><a class="reference" href="#nnp_convolution_transform_strategy_tuple_based" title="nnp_convolution_transform_strategy_tuple_based = nnp_convolution_transform_strategy_compute">nnp_convolution_transform_strategy_tuple_based</a></li>
<li><a class="reference" href="#nnp_status_invalid_activation" title="nnp_status_invalid_activation = nnp_status_invalid_pooling_size">nnp_status_invalid_activation</a></li>
<li><a class="reference" href="#nnp_status_invalid_activation_parameters" title="nnp_status_invalid_activation_parameters = nnp_status_invalid_pooling_stride">nnp_status_invalid_activation_parameters</a></li>
<li><a class="reference" href="#nnp_status_invalid_output_subsampling" title="nnp_status_invalid_output_subsampling = nnp_status_invalid_kernel_size">nnp_status_invalid_output_subsampling</a></li>

    </ul>
  </details>
</li>
<li>
  <details open>
    <summary><a class="reference reference-toplevel" href="#12" id="62">Procs</a></summary>
    <ul class="simple simple-toc-section">
      <ul class="simple nested-toc-section">nnp_convolution_inference
  <li><a class="reference" href="#nnp_convolution_inference%2Cnnp_convolution_algorithm%2Cnnp_convolution_transform_strategy%2Ccsize_t%2Ccsize_t%2Cnnp_size%2Cnnp_padding%2Cnnp_size%2Cnnp_size%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cpointer%2Cptr.csize_t%2Cnnp_activation%2Cpointer%2Cpthreadpool_t%2Cptr.nnp_profile" title="nnp_convolution_inference(algorithm: nnp_convolution_algorithm;
    transform_strategy: nnp_convolution_transform_strategy;
                          input_channels: csize_t; output_channels: csize_t;
                          input_size: nnp_size; input_padding: nnp_padding;
                          kernel_size: nnp_size; output_subsampling: nnp_size;
                          input: ptr cfloat; kernel: ptr cfloat;
                          bias: ptr cfloat; output: ptr cfloat;
                          workspace_buffer: pointer;
                          workspace_size: ptr csize_t;
                          activation: nnp_activation;
                          activation_parameters: pointer;
                          threadpool: pthreadpool_t; profile: ptr nnp_profile): nnp_status">nnp_convolution_inference(algorithm: nnp_convolution_algorithm;
    transform_strategy: nnp_convolution_transform_strategy;
                          input_channels: csize_t; output_channels: csize_t;
                          input_size: nnp_size; input_padding: nnp_padding;
                          kernel_size: nnp_size; output_subsampling: nnp_size;
                          input: ptr cfloat; kernel: ptr cfloat;
                          bias: ptr cfloat; output: ptr cfloat;
                          workspace_buffer: pointer;
                          workspace_size: ptr csize_t;
                          activation: nnp_activation;
                          activation_parameters: pointer;
                          threadpool: pthreadpool_t; profile: ptr nnp_profile): nnp_status</a></li>

</ul>
<ul class="simple nested-toc-section">nnp_convolution_input_gradient
  <li><a class="reference" href="#nnp_convolution_input_gradient%2Cnnp_convolution_algorithm%2Ccsize_t%2Ccsize_t%2Ccsize_t%2Cnnp_size%2Cnnp_padding%2Cnnp_size%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cpointer%2Cptr.csize_t%2Cnnp_activation%2Cpointer%2Cpthreadpool_t%2Cptr.nnp_profile" title="nnp_convolution_input_gradient(algorithm: nnp_convolution_algorithm;
                               batch_size: csize_t; input_channels: csize_t;
                               output_channels: csize_t; input_size: nnp_size;
                               input_padding: nnp_padding;
                               kernel_size: nnp_size; grad_output: ptr cfloat;
                               kernel: ptr cfloat; grad_input: ptr cfloat;
                               workspace_buffer: pointer = nil;
                               workspace_size: ptr csize_t = nil; activation: nnp_activation = nnp_activation_identity;
                               activation_parameters: pointer = nil;
                               threadpool: pthreadpool_t = nil;
                               profile: ptr nnp_profile = nil): nnp_status">nnp_convolution_input_gradient(algorithm: nnp_convolution_algorithm;
                               batch_size: csize_t; input_channels: csize_t;
                               output_channels: csize_t; input_size: nnp_size;
                               input_padding: nnp_padding;
                               kernel_size: nnp_size; grad_output: ptr cfloat;
                               kernel: ptr cfloat; grad_input: ptr cfloat;
                               workspace_buffer: pointer = nil;
                               workspace_size: ptr csize_t = nil; activation: nnp_activation = nnp_activation_identity;
                               activation_parameters: pointer = nil;
                               threadpool: pthreadpool_t = nil;
                               profile: ptr nnp_profile = nil): nnp_status</a></li>

</ul>
<ul class="simple nested-toc-section">nnp_convolution_kernel_gradient
  <li><a class="reference" href="#nnp_convolution_kernel_gradient%2Cnnp_convolution_algorithm%2Ccsize_t%2Ccsize_t%2Ccsize_t%2Cnnp_size%2Cnnp_padding%2Cnnp_size%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cpointer%2Cptr.csize_t%2Cnnp_activation%2Cpointer%2Cpthreadpool_t%2Cptr.nnp_profile" title="nnp_convolution_kernel_gradient(algorithm: nnp_convolution_algorithm;
                                batch_size: csize_t; input_channels: csize_t;
                                output_channels: csize_t; input_size: nnp_size;
                                input_padding: nnp_padding;
                                kernel_size: nnp_size; input: ptr cfloat;
                                grad_output: ptr cfloat;
                                grad_kernel: ptr cfloat;
                                workspace_buffer: pointer = nil;
                                workspace_size: ptr csize_t = nil; activation: nnp_activation = nnp_activation_identity;
                                activation_parameters: pointer = nil;
                                threadpool: pthreadpool_t = nil;
                                profile: ptr nnp_profile = nil): nnp_status">nnp_convolution_kernel_gradient(algorithm: nnp_convolution_algorithm;
                                batch_size: csize_t; input_channels: csize_t;
                                output_channels: csize_t; input_size: nnp_size;
                                input_padding: nnp_padding;
                                kernel_size: nnp_size; input: ptr cfloat;
                                grad_output: ptr cfloat;
                                grad_kernel: ptr cfloat;
                                workspace_buffer: pointer = nil;
                                workspace_size: ptr csize_t = nil; activation: nnp_activation = nnp_activation_identity;
                                activation_parameters: pointer = nil;
                                threadpool: pthreadpool_t = nil;
                                profile: ptr nnp_profile = nil): nnp_status</a></li>

</ul>
<ul class="simple nested-toc-section">nnp_convolution_output
  <li><a class="reference" href="#nnp_convolution_output%2Cnnp_convolution_algorithm%2Ccsize_t%2Ccsize_t%2Ccsize_t%2Cnnp_size%2Cnnp_padding%2Cnnp_size%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cpointer%2Cptr.csize_t%2Cnnp_activation%2Cpointer%2Cpthreadpool_t%2Cptr.nnp_profile" title="nnp_convolution_output(algorithm: nnp_convolution_algorithm;
                       batch_size: csize_t; input_channels: csize_t;
                       output_channels: csize_t; input_size: nnp_size;
                       input_padding: nnp_padding; kernel_size: nnp_size;
                       input: ptr cfloat; kernel: ptr cfloat; bias: ptr cfloat;
                       output: ptr cfloat; workspace_buffer: pointer = nil;
                       workspace_size: ptr csize_t = nil;
                       activation: nnp_activation = nnp_activation_identity;
                       activation_parameters: pointer = nil;
                       threadpool: pthreadpool_t = nil;
                       profile: ptr nnp_profile = nil): nnp_status">nnp_convolution_output(algorithm: nnp_convolution_algorithm;
                       batch_size: csize_t; input_channels: csize_t;
                       output_channels: csize_t; input_size: nnp_size;
                       input_padding: nnp_padding; kernel_size: nnp_size;
                       input: ptr cfloat; kernel: ptr cfloat; bias: ptr cfloat;
                       output: ptr cfloat; workspace_buffer: pointer = nil;
                       workspace_size: ptr csize_t = nil;
                       activation: nnp_activation = nnp_activation_identity;
                       activation_parameters: pointer = nil;
                       threadpool: pthreadpool_t = nil;
                       profile: ptr nnp_profile = nil): nnp_status</a></li>

</ul>
<ul class="simple nested-toc-section">nnp_deinitialize
  <li><a class="reference" href="#nnp_deinitialize" title="nnp_deinitialize(): nnp_status">nnp_deinitialize(): nnp_status</a></li>

</ul>
<ul class="simple nested-toc-section">nnp_fully_connected_inference
  <li><a class="reference" href="#nnp_fully_connected_inference%2Ccsize_t%2Ccsize_t%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cpthreadpool_t" title="nnp_fully_connected_inference(input_channels: csize_t; output_channels: csize_t;
                              input: ptr cfloat; kernel: ptr cfloat;
                              output: ptr cfloat; threadpool: pthreadpool_t): nnp_status">nnp_fully_connected_inference(input_channels: csize_t; output_channels: csize_t;
                              input: ptr cfloat; kernel: ptr cfloat;
                              output: ptr cfloat; threadpool: pthreadpool_t): nnp_status</a></li>

</ul>
<ul class="simple nested-toc-section">nnp_fully_connected_inference_f16f32
  <li><a class="reference" href="#nnp_fully_connected_inference_f16f32%2Ccsize_t%2Ccsize_t%2Cptr.cfloat%2Cpointer%2Cptr.cfloat%2Cpthreadpool_t" title="nnp_fully_connected_inference_f16f32(input_channels: csize_t;
                                     output_channels: csize_t;
                                     input: ptr cfloat; kernel: pointer;
                                     output: ptr cfloat;
                                     threadpool: pthreadpool_t): nnp_status">nnp_fully_connected_inference_f16f32(input_channels: csize_t;
                                     output_channels: csize_t;
                                     input: ptr cfloat; kernel: pointer;
                                     output: ptr cfloat;
                                     threadpool: pthreadpool_t): nnp_status</a></li>

</ul>
<ul class="simple nested-toc-section">nnp_fully_connected_output
  <li><a class="reference" href="#nnp_fully_connected_output%2Ccsize_t%2Ccsize_t%2Ccsize_t%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cpthreadpool_t%2Cptr.nnp_profile" title="nnp_fully_connected_output(batch_size: csize_t; input_channels: csize_t;
                           output_channels: csize_t; input: ptr cfloat;
                           kernel: ptr cfloat; output: ptr cfloat;
                           threadpool: pthreadpool_t; profile: ptr nnp_profile): nnp_status">nnp_fully_connected_output(batch_size: csize_t; input_channels: csize_t;
                           output_channels: csize_t; input: ptr cfloat;
                           kernel: ptr cfloat; output: ptr cfloat;
                           threadpool: pthreadpool_t; profile: ptr nnp_profile): nnp_status</a></li>

</ul>
<ul class="simple nested-toc-section">nnp_initialize
  <li><a class="reference" href="#nnp_initialize" title="nnp_initialize(): nnp_status">nnp_initialize(): nnp_status</a></li>

</ul>
<ul class="simple nested-toc-section">nnp_max_pooling_output
  <li><a class="reference" href="#nnp_max_pooling_output%2Ccsize_t%2Ccsize_t%2Cnnp_size%2Cnnp_padding%2Cnnp_size%2Cnnp_size%2Cptr.cfloat%2Cptr.cfloat%2Cpthreadpool_t" title="nnp_max_pooling_output(batch_size: csize_t; channels: csize_t;
                       input_size: nnp_size; input_padding: nnp_padding;
                       pooling_size: nnp_size; pooling_stride: nnp_size;
                       input: ptr cfloat; output: ptr cfloat;
                       threadpool: pthreadpool_t): nnp_status">nnp_max_pooling_output(batch_size: csize_t; channels: csize_t;
                       input_size: nnp_size; input_padding: nnp_padding;
                       pooling_size: nnp_size; pooling_stride: nnp_size;
                       input: ptr cfloat; output: ptr cfloat;
                       threadpool: pthreadpool_t): nnp_status</a></li>

</ul>
<ul class="simple nested-toc-section">nnp_relu_input_gradient
  <li><a class="reference" href="#nnp_relu_input_gradient%2Ccsize_t%2Ccsize_t%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Ccfloat%2Cpthreadpool_t" title="nnp_relu_input_gradient(batch_size: csize_t; channels: csize_t;
                        grad_output: ptr cfloat; input: ptr cfloat;
                        grad_input: ptr cfloat; negative_slope: cfloat;
                        threadpool: pthreadpool_t): nnp_status">nnp_relu_input_gradient(batch_size: csize_t; channels: csize_t;
                        grad_output: ptr cfloat; input: ptr cfloat;
                        grad_input: ptr cfloat; negative_slope: cfloat;
                        threadpool: pthreadpool_t): nnp_status</a></li>

</ul>
<ul class="simple nested-toc-section">nnp_relu_output
  <li><a class="reference" href="#nnp_relu_output%2Ccsize_t%2Ccsize_t%2Cptr.cfloat%2Cptr.cfloat%2Ccfloat%2Cpthreadpool_t" title="nnp_relu_output(batch_size: csize_t; channels: csize_t; input: ptr cfloat;
                output: ptr cfloat; negative_slope: cfloat;
                threadpool: pthreadpool_t): nnp_status">nnp_relu_output(batch_size: csize_t; channels: csize_t; input: ptr cfloat;
                output: ptr cfloat; negative_slope: cfloat;
                threadpool: pthreadpool_t): nnp_status</a></li>

</ul>
<ul class="simple nested-toc-section">nnp_softmax_output
  <li><a class="reference" href="#nnp_softmax_output%2Ccsize_t%2Ccsize_t%2Cptr.cfloat%2Cptr.cfloat%2Cpthreadpool_t" title="nnp_softmax_output(batch_size: csize_t; channels: csize_t; input: ptr cfloat;
                   output: ptr cfloat; threadpool: pthreadpool_t): nnp_status">nnp_softmax_output(batch_size: csize_t; channels: csize_t; input: ptr cfloat;
                   output: ptr cfloat; threadpool: pthreadpool_t): nnp_status</a></li>

</ul>

    </ul>
  </details>
</li>

</ul>

  </div>
  <div class="nine columns" id="content">
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L1"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L1" class="link-seesrc" target="_blank" >Edit</a>

    <div id="tocRoot"></div>
    
    <p class="module-desc">@brief Status code for any NNPACK function call. @brief Activation applied applied after a convolutional or fully-connected layer. @brief Algorithm for computing convolutional layers. For backward compatibility@brief Size of images, kernels, and pooling filters in NNPACK. @brief Padding of images in NNPACK. @brief Profiling information about time spent in different phases of a function call. @brief Computes output of a 2D convolutional layer from input and kernel tensors. @details This function targets training of convolutional neural networks and performs forward propagation. It is optimized for moderate minibatch sizes (64-128) and can be inefficient on a small minibatch. For minibatch size 1, use nnp_convolution_inference for optimal performance. @param algorithm The type of algorithm to use for convolution. Possible values are:<ul class="simple"><li>nnp_convolution_algorithm_auto    -- let the function choose the algorithm.</li>
<li>nnp_convolution_algorithm_ft8x8   -- tiled convolution based on 2D Fourier transform with 8x8 blocks. Supports kernels up to 8x8.</li>
<li>nnp_convolution_algorithm_ft16x16 -- tiled convolution based on 2D Fourier transform with 16x16 blocks. Supports kernels up to 16x16.</li>
<li>nnp_convolution_algorithm_wt8x8   -- tiled convolution based on 2D Winograd transform F(3x3, 6x6). Supports only 3x3 kernels.</li>
</ul>
<p>@param batch_size The number of images on the input and output of the convolutional layer. @param input_channels The number of channels (AKA features, dimensions) in the input images. @param output_channels The number of channels (AKA features, dimensions) in the output images. @param input_size Size of input images, excluding implicit zero-padding. @param input_padding Implicit zero-padding of input images. @param kernel_size Kernel size. @param<a class="reference internal" href="#in">in</a>  input  A 4D tensor input<a class="reference internal" href="#input_channels">batch_size</a><a class="reference internal" href="#input_size.width">input_size.height</a>. @param<a class="reference internal" href="#in">in</a>  kernel A 4D tensor kernel<a class="reference internal" href="#input_channels">output_channels</a><a class="reference internal" href="#kernel_size.width">kernel_size.height</a>. @param<a class="reference internal" href="#in">in</a>  bias   A 1D array bias<a class="reference internal" href="#output_channels">output_channels</a>. @param<a class="reference internal" href="#out">out</a> output A 4D tensor output<a class="reference internal" href="#output_channels">batch_size</a><a class="reference internal" href="#output_size.width">output_size.height</a> where output_size.height = (input_padding.top + input_size.height + input_padding.bottom) - (kernel_size.height - 1) output_size.width  = (input_padding.left + input_size.width + input_padding.right) - (kernel_size.width - 1) @param threadpool A thread pool for parallelization of the computation. If threadpool is NULL, the computation would run on the caller thread without parallelization. @param<a class="reference internal" href="#out">out</a> profile An optional pointer to profiling structure. If provided, the structure would record time spent in different phases of the computation. </p>
@brief Computes gradient of input of a 2D convolutional layer from gradient of output and kernel tensors. @details This function targets training of convolutional neural networks and performs backward propagation. It is optimized for moderate minibatch sizes (64-128) and can be inefficient on a small minibatch. @param algorithm The type of algorithm to use for convolution. Possible values are:<ul class="simple"><li>nnp_convolution_algorithm_auto    -- let the function choose the algorithm.</li>
<li>nnp_convolution_algorithm_ft8x8   -- tiled convolution based on 2D Fourier transform with 8x8 blocks. Supports kernels up to 8x8.</li>
<li>nnp_convolution_algorithm_ft16x16 -- tiled convolution based on 2D Fourier transform with 16x16 blocks. Supports kernels up to 16x16.</li>
<li>nnp_convolution_algorithm_wt8x8   -- tiled convolution based on 2D Winograd transform F(3x3, 6x6). Supports only 3x3 kernels.</li>
</ul>
<p>@param batch_size The number of images (and their gradients) on the input and output of the convolutional layer. @param input_channels The number of channels (AKA features, dimensions) in the input images (and gradients). @param output_channels The number of channels (AKA features, dimensions) in the output images (and gradients). @param input_size Size of input images and their gradients, excluding implicit zero-padding. @param input_padding Implicit zero-padding of input images. @param kernel_size Kernel size. @param<a class="reference internal" href="#in">in</a>  grad_output A 4D tensor grad_output<a class="reference internal" href="#output_channels">batch_size</a><a class="reference internal" href="#output_size.width">output_size.height</a> where output_size.height = (input_padding.top + input_size.height + input_padding.bottom) - (kernel_size.height - 1) output_size.width  = (input_padding.left + input_size.width + input_padding.right) - (kernel_size.width - 1) @param<a class="reference internal" href="#in">in</a>  kernel      A 4D tensor kernel<a class="reference internal" href="#input_channels">output_channels</a><a class="reference internal" href="#kernel_size.width">kernel_size.height</a>. @param<a class="reference internal" href="#out">out</a> grad_input  A 4D tensor grad_input<a class="reference internal" href="#input_channels">batch_size</a><a class="reference internal" href="#input_size.width">input_size.height</a>. @param threadpool A thread pool for parallelization of the computation. If threadpool is NULL, the computation would run on the caller thread without parallelization. @param<a class="reference internal" href="#out">out</a> profile An optional pointer to profiling structure. If provided, the structure would record time spent in different phases of the computation. </p>
@brief Computes gradient of kernel of a 2D convolutional layer from gradient of output and input tensors. @details This function targets training of convolutional neural networks and performs backward propagation. It is optimized for moderate minibatch sizes (64-128) and can be inefficient on a small minibatch. @param algorithm The type of algorithm to use for convolution. Possible values are:<ul class="simple"><li>nnp_convolution_algorithm_auto    -- let the function choose the algorithm.</li>
<li>nnp_convolution_algorithm_ft8x8   -- tiled convolution based on 2D Fourier transform with 8x8 blocks. Supports kernels up to 8x8.</li>
<li>nnp_convolution_algorithm_ft16x16 -- tiled convolution based on 2D Fourier transform with 16x16 blocks. Supports kernels up to 16x16.</li>
</ul>
<p>@param batch_size The number of images (and their gradients) on the input and output of the convolutional layer. @param input_channels The number of channels (AKA features, dimensions) in the input images. @param output_channels The number of channels (AKA features, dimensions) in the output images (and gradients). @param input_size Size of input images and their gradients, excluding implicit zero-padding. @param input_padding Implicit zero-padding of input images. @param kernel_size Kernel size. @param<a class="reference internal" href="#in">in</a>  input       A 4D tensor input<a class="reference internal" href="#input_channels">batch_size</a><a class="reference internal" href="#input_size.width">input_size.height</a>. @param<a class="reference internal" href="#in">in</a>  grad_output A 4D tensor grad_output<a class="reference internal" href="#output_channels">batch_size</a><a class="reference internal" href="#output_size.width">output_size.height</a> where output_size.height = (input_padding.top + input_size.height + input_padding.bottom) - (kernel_size.height - 1) output_size.width  = (input_padding.left + input_size.width + input_padding.right) - (kernel_size.width - 1) @param<a class="reference internal" href="#out">out</a> grad_kernel A 4D tensor grad_kernel<a class="reference internal" href="#input_channels">output_channels</a><a class="reference internal" href="#kernel_size.width">kernel_size.height</a>. @param threadpool A thread pool for parallelization of the computation. If threadpool is NULL, the computation would run on the caller thread without parallelization. @param<a class="reference internal" href="#out">out</a> profile An optional pointer to profiling structure. If provided, the structure would record time spent in different phases of the computation. </p>
@brief Computes output of a 2D convolutional layer for a single input image and a kernel tensor. @details This function targets prediction with convolutional neural networks and performs forward propagation. @param algorithm The type of algorithm to use for convolution. Possible values are:<ul class="simple"><li>nnp_convolution_algorithm_auto    -- let the function choose the algorithm.</li>
<li>nnp_convolution_algorithm_ft8x8   -- tiled convolution based on 2D Fourier transform with 8x8 blocks. Supports kernels up to 8x8.</li>
<li>nnp_convolution_algorithm_ft16x16 -- tiled convolution based on 2D Fourier transform with 16x16 blocks. Supports kernels up to 16x16.</li>
<li>nnp_convolution_algorithm_wt8x8   -- tiled convolution based on 2D Winograd transform F(3x3, 6x6). Supports only 3x3 kernels.</li>
</ul>
<p>@param transform_strategy A strategy that guides computation of kernel transforms coefficients. Possible values are:</p>
<ul class="simple"><li>nnp_convolution_transform_strategy_block_based -- do multiplication-accumulations on blocks of transformed coefficients.</li>
<li>nnp_convolution_transform_strategy_tuple_based -- do multiplication-accumulations on tuples of transformed coefficients.</li>
</ul>
<p>@param input_channels The number of channels (AKA features, dimensions) in the input image. @param output_channels The number of channels (AKA features, dimensions) in the output image. @param input_size Size of input image, excluding implicit zero-padding. @param input_padding Implicit zero-padding of input image. @param kernel_size Kernel size. @param output_subsampling Subsample region for output, also known as convolution stride. @param<a class="reference internal" href="#in">in</a>  input  A 3D tensor input<a class="reference internal" href="#input_size.height">input_channels</a><a class="reference internal" href="#input_size.width">input_size.width</a>. @param<a class="reference internal" href="#in">in</a>  kernel A 4D tensor kernel<a class="reference internal" href="#input_channels">output_channels</a><a class="reference internal" href="#kernel_size.width">kernel_size.height</a>. @param<a class="reference internal" href="#in">in</a>  bias   A 1D array bias<a class="reference internal" href="#output_channels">output_channels</a>. @param<a class="reference internal" href="#out">out</a> output A 3D tensor output<a class="reference internal" href="#output_size.height">output_channels</a><a class="reference internal" href="#output_size.width">output_size.width</a> where output_size.height = (input_padding.top + input_size.height + input_padding.bottom) - (kernel_size.height - 1) output_size.width  = (input_padding.left + input_size.width + input_padding.right) - (kernel_size.width - 1) @param<a class="reference internal" href="#in">in</a> workspace_buffer Buffer for scratch memory used during computation. Buffer must be aligned on 64 bytes. If workspace_buffer is NULL and workspace_size is non-NULL, NNPACK would store the size of required workspace memory at the workspace_size location, and exit without computations. If workspace_buffer is NULL and workspace_size is NULL, NNPACK would allocate memory before and deallocate after this computation, potentially at significant runtime cost. @param<a class="reference internal" href="#in,out">in,out</a> workspace_size Pointer to the size of workspace buffer. If workspace_buffer is NULL, NNPACK will write the size of required scratch memory to the location specified by this pointer. If workspace_buffer is non-NULL, NNPACK expects workspace_size to specify the size of the buffer, in bytes. If workspace_size is NULL, workspace_buffer must be NULL as well. In this case NNPACK would allocate memory before and deallocate after this computation, potentially at significant runtime cost. @param threadpool A thread pool for parallelization of the computation. If threadpool is NULL, the computation would run on the caller thread without parallelization. @param<a class="reference internal" href="#out">out</a> profile An optional pointer to profiling structure. If provided, the structure would record time spent in different phases of the computation. </p>
@brief Computes output of a fully connected layer from input and kernel matrices. @details This function targets training of convolutional neural networks and performs forward propagation. It is optimized for moderate minibatch sizes (64-128) and can be inefficient on a small minibatch. For minibatch size 1, use nnp_fully_connected_inference for optimal performance. @param batch_size The number of vectors on the input and output of the fully connected layer. @param input_channels The number of channels (AKA features, dimensions) in the input matrix. @param output_channels The number of channels (AKA features, dimensions) in the output matrix. @param<a class="reference internal" href="#in">in</a>  input  A 2D matrix input<a class="reference internal" href="#input_channels">batch_size</a>. @param<a class="reference internal" href="#in">in</a>  kernel A 2D matrix kernel<a class="reference internal" href="#input_channels">output_channels</a>. @param<a class="reference internal" href="#out">out</a> output A 2D matrix output<a class="reference internal" href="#output_channels">batch_size</a>. @param threadpool A thread pool for parallelization of the computation. If threadpool is NULL, the computation would run on the caller thread without parallelization. @brief Computes output of a fully connected layer for a single input vector and a kernel matrix. @details This function targets prediction with convolutional neural networks and performs forward propagation. @param input_channels The number of channels (AKA features, dimensions) in the input vector. @param output_channels The number of channels (AKA features, dimensions) in the output vector. @param<a class="reference internal" href="#in">in</a>  input  A 1D array input<a class="reference internal" href="#input_channels">input_channels</a> of FP32 elements. @param<a class="reference internal" href="#in">in</a>  kernel A 2D matrix kernel<a class="reference internal" href="#input_channels">output_channels</a> of FP32 elements. @param<a class="reference internal" href="#out">out</a> output A 1D array output<a class="reference internal" href="#output_channels">output_channels</a> of FP32 elements. @param threadpool A thread pool for parallelization of the computation. If threadpool is NULL, the computation would run on the caller thread without parallelization. @brief Computes output of a fully connected layer for a single input vector and a kernel matrix. @details This function targets prediction with convolutional neural networks and performs forward propagation. @param input_channels The number of channels (AKA features, dimensions) in the input vector. @param output_channels The number of channels (AKA features, dimensions) in the output vector. @param<a class="reference internal" href="#in">in</a>  input  A 1D array input<a class="reference internal" href="#input_channels">input_channels</a> of FP32 elements. @param<a class="reference internal" href="#in">in</a>  kernel A 2D matrix kernel<a class="reference internal" href="#input_channels">output_channels</a> of FP16 (ARM alternative format) elements. @param<a class="reference internal" href="#out">out</a> output A 1D array output<a class="reference internal" href="#output_channels">output_channels</a> of FP32 elements. @param threadpool A thread pool for parallelization of the computation. If threadpool is NULL, the computation would run on the caller thread without parallelization. @brief Computes output of a max-pooling layer for an input tensor. @details This function targets both prediction and training of convolutional neural networks and performs forward propagation. Is is optimized for both large and small minibatch sizes. @param batch_size The number of images on the input and output of the max-pooling layer. @param channels   The number of channels (AKA features, dimensions) in both input and output images. @param input_size Size of input images, excluding implicit zero-padding. @param input_padding Implicit padding of input images. The padding pixels are ignored by the pooling filter, but affect the output size. @param pooling_size   Size of the pooling filter. Only 2x2 filter are currently supported. @param pooling_stride Stride of the pooling filter. Only 2x2 strides are currently supported. @param<a class="reference internal" href="#in">in</a>  input  A 4D tensor input<a class="reference internal" href="#channels">batch_size</a><a class="reference internal" href="#input_size.width">input_size.height</a>. @param<a class="reference internal" href="#out">out</a> output A 4D tensor output<a class="reference internal" href="#channels">batch_size</a><a class="reference internal" href="#output_size.width">output_size.height</a> where output_size.height = ceil( (input_padding.top + input_size.height + input_padding.bottom - pooling_size.height) / pooling_stride.height) + 1 output_size.width = ceil( (input_padding.left + input_size.width + input_padding.right - pooling_size.width) / pooling_stride.width) + 1 @param threadpool A thread pool for parallelization of the computation. If threadpool is NULL, the computation would run on the caller thread without parallelization. @brief Computes output of a softmax layer for an input matrix. @details This function targets both prediction and training of convolutional neural networks and performs forward propagation. Is is optimized for both large and small minibatch sizes. @param batch_size The number of vectors on the input and output of the softmax layer. @param channels   The number of channels (AKA features, dimensions) in both input and output vectors. @param<a class="reference internal" href="#in">in</a>  input  A 2D matrix input<a class="reference internal" href="#channels">batch_size</a>. @param<a class="reference internal" href="#out">out</a> output A 2D matrix output<a class="reference internal" href="#channels">batch_size</a>. @param threadpool A thread pool for parallelization of the computation. If threadpool is NULL, the computation would run on the caller thread without parallelization. @brief Computes output of a rectified linear unit (ReLU) layer for an input matrix. @details This function targets both prediction and training of convolutional neural networks and performs forward propagation. Is is optimized for both large and small minibatch sizes. @param batch_size The number of vectors on the input and output of the ReLU layer. @param channels   The number of channels (AKA features, dimensions) in both input and output matrices. @param<a class="reference internal" href="#in">in</a>  input  A 2D matrix input<a class="reference internal" href="#channels">batch_size</a>. @param<a class="reference internal" href="#out">out</a> output A 2D matrix output<a class="reference internal" href="#channels">batch_size</a>. @param threadpool A thread pool for parallelization of the computation. If threadpool is NULL, the computation would run on the caller thread without parallelization. @brief Computes gradient of input of a rectified linear unit (ReLU) layer from gradient of output and input matrices. @details This function targets training of convolutional neural networks and performs backward propagation. Is is optimized for both large and small minibatch sizes. @param batch_size The number of vectors on the input and output of the ReLU layer. @param channels   The number of channels (AKA features, dimensions) in both input and output matrices. @param<a class="reference internal" href="#in">in</a>  input  A 2D matrix input<a class="reference internal" href="#channels">batch_size</a>. @param<a class="reference internal" href="#out">out</a> output A 2D matrix output<a class="reference internal" href="#channels">batch_size</a>. @param threadpool A thread pool for parallelization of the computation. If threadpool is NULL, the computation would run on the caller thread without parallelization. </p>
    <div class="section" id="6">
  <h1><a class="toc-backref" href="#6">Imports</a></h1>
  <dl class="item">
    <a class="reference external" href="std_version_types.html">std_version_types</a>
  </dl>
</div>
<div class="section" id="7">
  <h1><a class="toc-backref" href="#7">Types</a></h1>
  <dl class="item">
    <div id="nnp_activation">
  <dt><pre><a href="nnpack.html#nnp_activation"><span class="Identifier">nnp_activation</span></a> {.<span class="Identifier">size</span><span class="Other">:</span> <span class="DecNumber">4</span>.} <span class="Other">=</span> <span class="Keyword">enum</span>
  <span class="Identifier">nnp_activation_identity</span> <span class="Other">=</span> <span class="DecNumber">0</span><span class="Other">,</span> <span class="Comment">## * ReLU activation f(x) := max(0, x)</span>
  <span class="Identifier">nnp_activation_relu</span> <span class="Other">=</span> <span class="DecNumber">1</span></pre></dt>
  <dd>
    
    <ul class="simple"><li>Identity activation f(x) := x, i.e. no transformation</li>
</ul>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L72"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L72" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="nnp_convolution_algorithm">
  <dt><pre><a href="nnpack.html#nnp_convolution_algorithm"><span class="Identifier">nnp_convolution_algorithm</span></a> {.<span class="Identifier">size</span><span class="Other">:</span> <span class="DecNumber">4</span>.} <span class="Other">=</span> <span class="Keyword">enum</span>
  <span class="Identifier">nnp_convolution_algorithm_auto</span> <span class="Other">=</span> <span class="DecNumber">0</span><span class="Other">,</span> <span class="Comment">## * Tiled convolution based on 2D Fourier transform with 8x8 blocks. Supports kernels up to 8x8.</span>
  <span class="Identifier">nnp_convolution_algorithm_ft8x8</span> <span class="Other">=</span> <span class="DecNumber">1</span><span class="Other">,</span> <span class="Comment">## * Tiled convolution based on 2D Fourier transform with 16x16 blocks. Supports kernels up to 16x16.</span>
  <span class="Identifier">nnp_convolution_algorithm_ft16x16</span> <span class="Other">=</span> <span class="DecNumber">2</span><span class="Other">,</span> <span class="Comment">## * Tiled convolution based on 2D Winograd transform F(3x3, 6x6) with 8x8 blocks. Supports only 3x3 kernels.</span>
  <span class="Identifier">nnp_convolution_algorithm_wt8x8</span> <span class="Other">=</span> <span class="DecNumber">3</span><span class="Other">,</span> <span class="Comment">## * Direct convolution via implicit GEMM.</span>
  <span class="Identifier">nnp_convolution_algorithm_implicit_gemm</span> <span class="Other">=</span> <span class="DecNumber">4</span><span class="Other">,</span> <span class="Comment">## * Direct convolution implementation.</span>
  <span class="Identifier">nnp_convolution_algorithm_direct</span> <span class="Other">=</span> <span class="DecNumber">5</span><span class="Other">,</span> <span class="Comment">## *</span>
                                         <span class="Comment">##  Tiled convolution based on 2D Winograd transform F(3x3, 6x6) with 8x8 blocks in FP16.</span>
                                         <span class="Comment">##  Supports only 3x3 kernels. Implemented only for new ARM processors (with NEON-HP),</span>
                                         <span class="Comment">##  on non-supported processors falls back to nnp_convolution_algorithm_wt8x8.</span>
                                         <span class="Comment">## </span>
  <span class="Identifier">nnp_convolution_algorithm_wt8x8_fp16</span> <span class="Other">=</span> <span class="DecNumber">6</span></pre></dt>
  <dd>
    
    <ul class="simple"><li>Let NNPACK choose the algorithm depending on layer parameters</li>
</ul>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L82"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L82" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="nnp_convolution_transform_strategy">
  <dt><pre><a href="nnpack.html#nnp_convolution_transform_strategy"><span class="Identifier">nnp_convolution_transform_strategy</span></a> {.<span class="Identifier">size</span><span class="Other">:</span> <span class="DecNumber">4</span>.} <span class="Other">=</span> <span class="Keyword">enum</span>
  <span class="Identifier">nnp_convolution_transform_strategy_compute</span> <span class="Other">=</span> <span class="DecNumber">1</span><span class="Other">,</span>
  <span class="Identifier">nnp_convolution_transform_strategy_precompute</span> <span class="Other">=</span> <span class="DecNumber">2</span><span class="Other">,</span>
  <span class="Identifier">nnp_convolution_transform_strategy_reuse</span> <span class="Other">=</span> <span class="DecNumber">3</span></pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L97"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L97" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="nnp_padding">
  <dt><pre><a href="nnpack.html#nnp_padding"><span class="Identifier">nnp_padding</span></a> {.<span class="Identifier">bycopy</span>.} <span class="Other">=</span> <span class="Keyword">object</span>
  <span class="Identifier">top</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">csize_t</span>              <span class="Comment">## * Padding above the image data</span>
                             <span class="Comment">## * Padding on the right of image data</span>
  <span class="Identifier">right</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">csize_t</span>            <span class="Comment">## * Padding below the image data</span>
  <span class="Identifier">bottom</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">csize_t</span>           <span class="Comment">## * Padding on the left of image data</span>
  <span class="Identifier">left</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">csize_t</span></pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L124"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L124" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="nnp_profile">
  <dt><pre><a href="nnpack.html#nnp_profile"><span class="Identifier">nnp_profile</span></a> {.<span class="Identifier">bycopy</span>.} <span class="Other">=</span> <span class="Keyword">object</span>
  <span class="Identifier">total</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">cdouble</span>            <span class="Comment">## * Time spent inside the function call, in seconds.</span>
                             <span class="Comment">## * Time spend on transformation of the input or input gradient tensor, in seconds.</span>
  <span class="Identifier">input_transform</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">cdouble</span>  <span class="Comment">## * Time spend on transformation of the kernel or kernel gradient tensor, in seconds.</span>
  <span class="Identifier">kernel_transform</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">cdouble</span> <span class="Comment">## * Time spend on transformation of the output or output gradient tensor, in seconds.</span>
  <span class="Identifier">output_transform</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">cdouble</span> <span class="Comment">## * Time spend on multiplication-accumulation of transformed coefficients, in seconds.</span>
  <span class="Identifier">block_multiplication</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">cdouble</span></pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L136"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L136" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="nnp_size">
  <dt><pre><a href="nnpack.html#nnp_size"><span class="Identifier">nnp_size</span></a> {.<span class="Identifier">bycopy</span>.} <span class="Other">=</span> <span class="Keyword">object</span>
  <span class="Identifier">width</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">csize_t</span> <span class="Comment">## * Width (horizontal size) of an image, kernel, or pooling filter.</span>
                  <span class="Comment">## * Height (vertical size) of an image, kernel, or pooling filter.</span>
  <span class="Identifier">height</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">csize_t</span></pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L114"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L114" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="nnp_status">
  <dt><pre><a href="nnpack.html#nnp_status"><span class="Identifier">nnp_status</span></a> {.<span class="Identifier">size</span><span class="Other">:</span> <span class="DecNumber">4</span>.} <span class="Other">=</span> <span class="Keyword">enum</span>
  <span class="Identifier">nnp_status_success</span> <span class="Other">=</span> <span class="DecNumber">0</span><span class="Other">,</span>   <span class="Comment">## * NNPACK function was called with batch_size == 0.</span>
  <span class="Identifier">nnp_status_invalid_batch_size</span> <span class="Other">=</span> <span class="DecNumber">2</span><span class="Other">,</span> <span class="Comment">## * NNPACK function was called with channels == 0.</span>
  <span class="Identifier">nnp_status_invalid_channels</span> <span class="Other">=</span> <span class="DecNumber">3</span><span class="Other">,</span> <span class="Comment">## * NNPACK function was called with input_channels == 0.</span>
  <span class="Identifier">nnp_status_invalid_input_channels</span> <span class="Other">=</span> <span class="DecNumber">4</span><span class="Other">,</span> <span class="Comment">## * NNPACK function was called with output_channels == 0.</span>
  <span class="Identifier">nnp_status_invalid_output_channels</span> <span class="Other">=</span> <span class="DecNumber">5</span><span class="Other">,</span> <span class="Comment">## * NNPACK function was called with input_size.height == 0 or input_size.width == 0</span>
  <span class="Identifier">nnp_status_invalid_input_size</span> <span class="Other">=</span> <span class="DecNumber">10</span><span class="Other">,</span> <span class="Comment">## * NNPACK function was called with input_stride.height == 0 or input_stride.width == 0</span>
  <span class="Identifier">nnp_status_invalid_input_stride</span> <span class="Other">=</span> <span class="DecNumber">11</span><span class="Other">,</span> <span class="Comment">## * NNPACK function was called with input_padding not less than respective kernel (or pooling) size, i.e.:</span>
                                         <span class="Comment">## </span>
                                         <span class="Comment">##   - input_padding.left   &gt;= kernel_size.width  (&gt;= pooling_size.width)</span>
                                         <span class="Comment">##   - input_padding.right  &gt;= kernel_size.width  (&gt;= pooling_size.width)</span>
                                         <span class="Comment">##   - input_padding.top    &gt;= kernel_size.height (&gt;= pooling_size.height)</span>
                                         <span class="Comment">##   - input_padding.bottom &gt;= kernel_size.height (&gt;= pooling_size.height)</span>
                                         <span class="Comment">## </span>
  <span class="Identifier">nnp_status_invalid_input_padding</span> <span class="Other">=</span> <span class="DecNumber">12</span><span class="Other">,</span> <span class="Comment">## * NNPACK function was called with kernel_size.height == 0 or kernel_size.width == 0</span>
  <span class="Identifier">nnp_status_invalid_kernel_size</span> <span class="Other">=</span> <span class="DecNumber">13</span><span class="Other">,</span> <span class="Comment">## * NNPACK function was called with pooling_size.height == 0 or pooling_size.width == 0</span>
  <span class="Identifier">nnp_status_invalid_pooling_size</span> <span class="Other">=</span> <span class="DecNumber">14</span><span class="Other">,</span> <span class="Comment">## * NNPACK function was called with pooling_stride.height == 0 or pooling_stride.width == 0</span>
  <span class="Identifier">nnp_status_invalid_pooling_stride</span> <span class="Other">=</span> <span class="DecNumber">15</span><span class="Other">,</span> <span class="Comment">## * NNPACK function was called with convolution algorithm not in nnp_convolution_algorithm enumeration</span>
  <span class="Identifier">nnp_status_invalid_algorithm</span> <span class="Other">=</span> <span class="DecNumber">16</span><span class="Other">,</span> <span class="Comment">## * NNPACK function was called with convolution transform strategy not in nnp_convolution_transform_strategy enum</span>
  <span class="Identifier">nnp_status_invalid_transform_strategy</span> <span class="Other">=</span> <span class="DecNumber">17</span><span class="Other">,</span> <span class="Comment">## * NNPACK function was called with output_subsampling.height == 0 or output_subsampling.width == 0</span>
  <span class="Identifier">nnp_status_unsupported_input_size</span> <span class="Other">=</span> <span class="DecNumber">20</span><span class="Other">,</span> <span class="Comment">## * NNPACK does not support the particular input stride for the function</span>
  <span class="Identifier">nnp_status_unsupported_input_stride</span> <span class="Other">=</span> <span class="DecNumber">21</span><span class="Other">,</span> <span class="Comment">## * NNPACK does not support the particular input padding for the function</span>
  <span class="Identifier">nnp_status_unsupported_input_padding</span> <span class="Other">=</span> <span class="DecNumber">22</span><span class="Other">,</span> <span class="Comment">## * NNPACK does not support the particular kernel size for the function</span>
  <span class="Identifier">nnp_status_unsupported_kernel_size</span> <span class="Other">=</span> <span class="DecNumber">23</span><span class="Other">,</span> <span class="Comment">## * NNPACK does not support the particular pooling size for the function</span>
  <span class="Identifier">nnp_status_unsupported_pooling_size</span> <span class="Other">=</span> <span class="DecNumber">24</span><span class="Other">,</span> <span class="Comment">## * NNPACK does not support the particular pooling stride for the function</span>
  <span class="Identifier">nnp_status_unsupported_pooling_stride</span> <span class="Other">=</span> <span class="DecNumber">25</span><span class="Other">,</span> <span class="Comment">## * NNPACK does not support the particular convolution algorithm for the function</span>
  <span class="Identifier">nnp_status_unsupported_algorithm</span> <span class="Other">=</span> <span class="DecNumber">26</span><span class="Other">,</span> <span class="Comment">## * NNPACK does not support the particular convolution transform strategy for the algorithm</span>
  <span class="Identifier">nnp_status_unsupported_transform_strategy</span> <span class="Other">=</span> <span class="DecNumber">27</span><span class="Other">,</span> <span class="Comment">## * NNPACK does not support the particular activation function for the function</span>
  <span class="Identifier">nnp_status_unsupported_activation</span> <span class="Other">=</span> <span class="DecNumber">28</span><span class="Other">,</span> <span class="Comment">## * NNPACK does not support the particular activation function parameters for the function</span>
  <span class="Identifier">nnp_status_unsupported_activation_parameters</span> <span class="Other">=</span> <span class="DecNumber">29</span><span class="Other">,</span> <span class="Comment">## * NNPACK function was called before the library was initialized</span>
  <span class="Identifier">nnp_status_uninitialized</span> <span class="Other">=</span> <span class="DecNumber">50</span><span class="Other">,</span> <span class="Comment">## * NNPACK does not implement this function for the host CPU</span>
  <span class="Identifier">nnp_status_unsupported_hardware</span> <span class="Other">=</span> <span class="DecNumber">51</span><span class="Other">,</span> <span class="Comment">## * NNPACK failed to allocate memory for temporary buffers</span>
  <span class="Identifier">nnp_status_out_of_memory</span> <span class="Other">=</span> <span class="DecNumber">52</span><span class="Other">,</span> <span class="Comment">## * Scratch space buffer is too small</span>
  <span class="Identifier">nnp_status_insufficient_buffer</span> <span class="Other">=</span> <span class="DecNumber">53</span><span class="Other">,</span> <span class="Comment">## * Scratch space buffer is not properly aligned</span>
  <span class="Identifier">nnp_status_misaligned_buffer</span> <span class="Other">=</span> <span class="DecNumber">54</span></pre></dt>
  <dd>
    
    <ul class="simple"><li>The call succeeded, and all output arguments now contain valid data.</li>
</ul>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L24"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L24" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="pthreadpool_t">
  <dt><pre><a href="nnpack.html#pthreadpool_t"><span class="Identifier">pthreadpool_t</span></a> <span class="Other">=</span> <span class="Identifier">pointer</span></pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L60"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L60" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

  </dl>
</div>
<div class="section" id="10">
  <h1><a class="toc-backref" href="#10">Consts</a></h1>
  <dl class="item">
    <div id="nnp_convolution_transform_strategy_block_based">
  <dt><pre><a href="nnpack.html#nnp_convolution_transform_strategy_block_based"><span class="Identifier">nnp_convolution_transform_strategy_block_based</span></a> <span class="Other">=</span> <span class="DecNumber">nnp_convolution_transform_strategy_compute</span></pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L106"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L106" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="nnp_convolution_transform_strategy_tuple_based">
  <dt><pre><a href="nnpack.html#nnp_convolution_transform_strategy_tuple_based"><span class="Identifier">nnp_convolution_transform_strategy_tuple_based</span></a> <span class="Other">=</span> <span class="DecNumber">nnp_convolution_transform_strategy_compute</span></pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L107"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L107" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="nnp_status_invalid_activation">
  <dt><pre><a href="nnpack.html#nnp_status_invalid_activation"><span class="Identifier">nnp_status_invalid_activation</span></a> <span class="Other">=</span> <span class="DecNumber">nnp_status_invalid_pooling_size</span></pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L64"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L64" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="nnp_status_invalid_activation_parameters">
  <dt><pre><a href="nnpack.html#nnp_status_invalid_activation_parameters"><span class="Identifier">nnp_status_invalid_activation_parameters</span></a> <span class="Other">=</span> <span class="DecNumber">nnp_status_invalid_pooling_stride</span></pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L65"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L65" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="nnp_status_invalid_output_subsampling">
  <dt><pre><a href="nnpack.html#nnp_status_invalid_output_subsampling"><span class="Identifier">nnp_status_invalid_output_subsampling</span></a> <span class="Other">=</span> <span class="DecNumber">nnp_status_invalid_kernel_size</span></pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L63"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L63" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

  </dl>
</div>
<div class="section" id="12">
  <h1><a class="toc-backref" href="#12">Procs</a></h1>
  <dl class="item">
    <div id="nnp_convolution_inference-procs-all">
  <div id="nnp_convolution_inference,nnp_convolution_algorithm,nnp_convolution_transform_strategy,csize_t,csize_t,nnp_size,nnp_padding,nnp_size,nnp_size,ptr.cfloat,ptr.cfloat,ptr.cfloat,ptr.cfloat,pointer,ptr.csize_t,nnp_activation,pointer,pthreadpool_t,ptr.nnp_profile">
  <dt><pre><span class="Keyword">proc</span> <a href="#nnp_convolution_inference%2Cnnp_convolution_algorithm%2Cnnp_convolution_transform_strategy%2Ccsize_t%2Ccsize_t%2Cnnp_size%2Cnnp_padding%2Cnnp_size%2Cnnp_size%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cpointer%2Cptr.csize_t%2Cnnp_activation%2Cpointer%2Cpthreadpool_t%2Cptr.nnp_profile"><span class="Identifier">nnp_convolution_inference</span></a><span class="Other">(</span><span class="Identifier">algorithm</span><span class="Other">:</span> <a href="nnpack.html#nnp_convolution_algorithm"><span class="Identifier">nnp_convolution_algorithm</span></a><span class="Other">;</span>
    <span class="Identifier">transform_strategy</span><span class="Other">:</span> <a href="nnpack.html#nnp_convolution_transform_strategy"><span class="Identifier">nnp_convolution_transform_strategy</span></a><span class="Other">;</span>
                               <span class="Identifier">input_channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
                               <span class="Identifier">output_channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span> <span class="Identifier">input_size</span><span class="Other">:</span> <a href="nnpack.html#nnp_size"><span class="Identifier">nnp_size</span></a><span class="Other">;</span>
                               <span class="Identifier">input_padding</span><span class="Other">:</span> <a href="nnpack.html#nnp_padding"><span class="Identifier">nnp_padding</span></a><span class="Other">;</span>
                               <span class="Identifier">kernel_size</span><span class="Other">:</span> <a href="nnpack.html#nnp_size"><span class="Identifier">nnp_size</span></a><span class="Other">;</span>
                               <span class="Identifier">output_subsampling</span><span class="Other">:</span> <a href="nnpack.html#nnp_size"><span class="Identifier">nnp_size</span></a><span class="Other">;</span> <span class="Identifier">input</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                               <span class="Identifier">kernel</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span> <span class="Identifier">bias</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                               <span class="Identifier">output</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span> <span class="Identifier">workspace_buffer</span><span class="Other">:</span> <span class="Identifier">pointer</span><span class="Other">;</span>
                               <span class="Identifier">workspace_size</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
                               <span class="Identifier">activation</span><span class="Other">:</span> <a href="nnpack.html#nnp_activation"><span class="Identifier">nnp_activation</span></a><span class="Other">;</span>
                               <span class="Identifier">activation_parameters</span><span class="Other">:</span> <span class="Identifier">pointer</span><span class="Other">;</span>
                               <span class="Identifier">threadpool</span><span class="Other">:</span> <a href="nnpack.html#pthreadpool_t"><span class="Identifier">pthreadpool_t</span></a><span class="Other">;</span>
                               <span class="Identifier">profile</span><span class="Other">:</span> <span class="Keyword">ptr</span> <a href="nnpack.html#nnp_profile"><span class="Identifier">nnp_profile</span></a><span class="Other">)</span><span class="Other">:</span> <a href="nnpack.html#nnp_status"><span class="Identifier">nnp_status</span></a> {.<span class="Identifier">cdecl</span><span class="Other">,</span>
    <span class="Identifier">importc</span><span class="Other">:</span> <span class="StringLit">&quot;nnp_convolution_inference&quot;</span><span class="Other">,</span> <span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L342"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L342" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="nnp_convolution_input_gradient-procs-all">
  <div id="nnp_convolution_input_gradient,nnp_convolution_algorithm,csize_t,csize_t,csize_t,nnp_size,nnp_padding,nnp_size,ptr.cfloat,ptr.cfloat,ptr.cfloat,pointer,ptr.csize_t,nnp_activation,pointer,pthreadpool_t,ptr.nnp_profile">
  <dt><pre><span class="Keyword">proc</span> <a href="#nnp_convolution_input_gradient%2Cnnp_convolution_algorithm%2Ccsize_t%2Ccsize_t%2Ccsize_t%2Cnnp_size%2Cnnp_padding%2Cnnp_size%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cpointer%2Cptr.csize_t%2Cnnp_activation%2Cpointer%2Cpthreadpool_t%2Cptr.nnp_profile"><span class="Identifier">nnp_convolution_input_gradient</span></a><span class="Other">(</span><span class="Identifier">algorithm</span><span class="Other">:</span> <a href="nnpack.html#nnp_convolution_algorithm"><span class="Identifier">nnp_convolution_algorithm</span></a><span class="Other">;</span>
                                    <span class="Identifier">batch_size</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
                                    <span class="Identifier">input_channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
                                    <span class="Identifier">output_channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
                                    <span class="Identifier">input_size</span><span class="Other">:</span> <a href="nnpack.html#nnp_size"><span class="Identifier">nnp_size</span></a><span class="Other">;</span>
                                    <span class="Identifier">input_padding</span><span class="Other">:</span> <a href="nnpack.html#nnp_padding"><span class="Identifier">nnp_padding</span></a><span class="Other">;</span>
                                    <span class="Identifier">kernel_size</span><span class="Other">:</span> <a href="nnpack.html#nnp_size"><span class="Identifier">nnp_size</span></a><span class="Other">;</span>
                                    <span class="Identifier">grad_output</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span> <span class="Identifier">kernel</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                                    <span class="Identifier">grad_input</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                                    <span class="Identifier">workspace_buffer</span><span class="Other">:</span> <span class="Identifier">pointer</span> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">;</span>
                                    <span class="Identifier">workspace_size</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">csize_t</span> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">;</span>
    <span class="Identifier">activation</span><span class="Other">:</span> <a href="nnpack.html#nnp_activation"><span class="Identifier">nnp_activation</span></a> <span class="Other">=</span> <span class="Identifier">nnp_activation_identity</span><span class="Other">;</span>
                                    <span class="Identifier">activation_parameters</span><span class="Other">:</span> <span class="Identifier">pointer</span> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">;</span>
                                    <span class="Identifier">threadpool</span><span class="Other">:</span> <a href="nnpack.html#pthreadpool_t"><span class="Identifier">pthreadpool_t</span></a> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">;</span>
                                    <span class="Identifier">profile</span><span class="Other">:</span> <span class="Keyword">ptr</span> <a href="nnpack.html#nnp_profile"><span class="Identifier">nnp_profile</span></a> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">)</span><span class="Other">:</span> <a href="nnpack.html#nnp_status"><span class="Identifier">nnp_status</span></a> {.
    <span class="Identifier">cdecl</span><span class="Other">,</span> <span class="Identifier">importc</span><span class="Other">:</span> <span class="StringLit">&quot;nnp_convolution_input_gradient&quot;</span><span class="Other">,</span> <span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span>
    <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L226"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L226" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="nnp_convolution_kernel_gradient-procs-all">
  <div id="nnp_convolution_kernel_gradient,nnp_convolution_algorithm,csize_t,csize_t,csize_t,nnp_size,nnp_padding,nnp_size,ptr.cfloat,ptr.cfloat,ptr.cfloat,pointer,ptr.csize_t,nnp_activation,pointer,pthreadpool_t,ptr.nnp_profile">
  <dt><pre><span class="Keyword">proc</span> <a href="#nnp_convolution_kernel_gradient%2Cnnp_convolution_algorithm%2Ccsize_t%2Ccsize_t%2Ccsize_t%2Cnnp_size%2Cnnp_padding%2Cnnp_size%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cpointer%2Cptr.csize_t%2Cnnp_activation%2Cpointer%2Cpthreadpool_t%2Cptr.nnp_profile"><span class="Identifier">nnp_convolution_kernel_gradient</span></a><span class="Other">(</span><span class="Identifier">algorithm</span><span class="Other">:</span> <a href="nnpack.html#nnp_convolution_algorithm"><span class="Identifier">nnp_convolution_algorithm</span></a><span class="Other">;</span>
                                     <span class="Identifier">batch_size</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
                                     <span class="Identifier">input_channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
                                     <span class="Identifier">output_channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
                                     <span class="Identifier">input_size</span><span class="Other">:</span> <a href="nnpack.html#nnp_size"><span class="Identifier">nnp_size</span></a><span class="Other">;</span>
                                     <span class="Identifier">input_padding</span><span class="Other">:</span> <a href="nnpack.html#nnp_padding"><span class="Identifier">nnp_padding</span></a><span class="Other">;</span>
                                     <span class="Identifier">kernel_size</span><span class="Other">:</span> <a href="nnpack.html#nnp_size"><span class="Identifier">nnp_size</span></a><span class="Other">;</span> <span class="Identifier">input</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                                     <span class="Identifier">grad_output</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                                     <span class="Identifier">grad_kernel</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                                     <span class="Identifier">workspace_buffer</span><span class="Other">:</span> <span class="Identifier">pointer</span> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">;</span>
                                     <span class="Identifier">workspace_size</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">csize_t</span> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">;</span>
    <span class="Identifier">activation</span><span class="Other">:</span> <a href="nnpack.html#nnp_activation"><span class="Identifier">nnp_activation</span></a> <span class="Other">=</span> <span class="Identifier">nnp_activation_identity</span><span class="Other">;</span>
                                     <span class="Identifier">activation_parameters</span><span class="Other">:</span> <span class="Identifier">pointer</span> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">;</span>
                                     <span class="Identifier">threadpool</span><span class="Other">:</span> <a href="nnpack.html#pthreadpool_t"><span class="Identifier">pthreadpool_t</span></a> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">;</span>
                                     <span class="Identifier">profile</span><span class="Other">:</span> <span class="Keyword">ptr</span> <a href="nnpack.html#nnp_profile"><span class="Identifier">nnp_profile</span></a> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">)</span><span class="Other">:</span> <a href="nnpack.html#nnp_status"><span class="Identifier">nnp_status</span></a> {.
    <span class="Identifier">cdecl</span><span class="Other">,</span> <span class="Identifier">importc</span><span class="Other">:</span> <span class="StringLit">&quot;nnp_convolution_kernel_gradient&quot;</span><span class="Other">,</span> <span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span>
    <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L273"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L273" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="nnp_convolution_output-procs-all">
  <div id="nnp_convolution_output,nnp_convolution_algorithm,csize_t,csize_t,csize_t,nnp_size,nnp_padding,nnp_size,ptr.cfloat,ptr.cfloat,ptr.cfloat,ptr.cfloat,pointer,ptr.csize_t,nnp_activation,pointer,pthreadpool_t,ptr.nnp_profile">
  <dt><pre><span class="Keyword">proc</span> <a href="#nnp_convolution_output%2Cnnp_convolution_algorithm%2Ccsize_t%2Ccsize_t%2Ccsize_t%2Cnnp_size%2Cnnp_padding%2Cnnp_size%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cpointer%2Cptr.csize_t%2Cnnp_activation%2Cpointer%2Cpthreadpool_t%2Cptr.nnp_profile"><span class="Identifier">nnp_convolution_output</span></a><span class="Other">(</span><span class="Identifier">algorithm</span><span class="Other">:</span> <a href="nnpack.html#nnp_convolution_algorithm"><span class="Identifier">nnp_convolution_algorithm</span></a><span class="Other">;</span>
                            <span class="Identifier">batch_size</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span> <span class="Identifier">input_channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
                            <span class="Identifier">output_channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span> <span class="Identifier">input_size</span><span class="Other">:</span> <a href="nnpack.html#nnp_size"><span class="Identifier">nnp_size</span></a><span class="Other">;</span>
                            <span class="Identifier">input_padding</span><span class="Other">:</span> <a href="nnpack.html#nnp_padding"><span class="Identifier">nnp_padding</span></a><span class="Other">;</span> <span class="Identifier">kernel_size</span><span class="Other">:</span> <a href="nnpack.html#nnp_size"><span class="Identifier">nnp_size</span></a><span class="Other">;</span>
                            <span class="Identifier">input</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span> <span class="Identifier">kernel</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                            <span class="Identifier">bias</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span> <span class="Identifier">output</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                            <span class="Identifier">workspace_buffer</span><span class="Other">:</span> <span class="Identifier">pointer</span> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">;</span>
                            <span class="Identifier">workspace_size</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">csize_t</span> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">;</span> <span class="Identifier">activation</span><span class="Other">:</span> <a href="nnpack.html#nnp_activation"><span class="Identifier">nnp_activation</span></a> <span class="Other">=</span> <span class="Identifier">nnp_activation_identity</span><span class="Other">;</span>
                            <span class="Identifier">activation_parameters</span><span class="Other">:</span> <span class="Identifier">pointer</span> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">;</span>
                            <span class="Identifier">threadpool</span><span class="Other">:</span> <a href="nnpack.html#pthreadpool_t"><span class="Identifier">pthreadpool_t</span></a> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">;</span>
                            <span class="Identifier">profile</span><span class="Other">:</span> <span class="Keyword">ptr</span> <a href="nnpack.html#nnp_profile"><span class="Identifier">nnp_profile</span></a> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">)</span><span class="Other">:</span> <a href="nnpack.html#nnp_status"><span class="Identifier">nnp_status</span></a> {.<span class="Identifier">cdecl</span><span class="Other">,</span>
    <span class="Identifier">importc</span><span class="Other">:</span> <span class="StringLit">&quot;nnp_convolution_output&quot;</span><span class="Other">,</span> <span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L182"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L182" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="nnp_deinitialize-procs-all">
  <div id="nnp_deinitialize">
  <dt><pre><span class="Keyword">proc</span> <a href="#nnp_deinitialize"><span class="Identifier">nnp_deinitialize</span></a><span class="Other">(</span><span class="Other">)</span><span class="Other">:</span> <a href="nnpack.html#nnp_status"><span class="Identifier">nnp_status</span></a> {.<span class="Identifier">cdecl</span><span class="Other">,</span> <span class="Identifier">importc</span><span class="Other">:</span> <span class="StringLit">&quot;nnp_deinitialize&quot;</span><span class="Other">,</span>
                                      <span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L146"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L146" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="nnp_fully_connected_inference-procs-all">
  <div id="nnp_fully_connected_inference,csize_t,csize_t,ptr.cfloat,ptr.cfloat,ptr.cfloat,pthreadpool_t">
  <dt><pre><span class="Keyword">proc</span> <a href="#nnp_fully_connected_inference%2Ccsize_t%2Ccsize_t%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cpthreadpool_t"><span class="Identifier">nnp_fully_connected_inference</span></a><span class="Other">(</span><span class="Identifier">input_channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
                                   <span class="Identifier">output_channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span> <span class="Identifier">input</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                                   <span class="Identifier">kernel</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span> <span class="Identifier">output</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                                   <span class="Identifier">threadpool</span><span class="Other">:</span> <a href="nnpack.html#pthreadpool_t"><span class="Identifier">pthreadpool_t</span></a><span class="Other">)</span><span class="Other">:</span> <a href="nnpack.html#nnp_status"><span class="Identifier">nnp_status</span></a> {.
    <span class="Identifier">cdecl</span><span class="Other">,</span> <span class="Identifier">importc</span><span class="Other">:</span> <span class="StringLit">&quot;nnp_fully_connected_inference&quot;</span><span class="Other">,</span> <span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span>
    <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L387"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L387" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="nnp_fully_connected_inference_f16f32-procs-all">
  <div id="nnp_fully_connected_inference_f16f32,csize_t,csize_t,ptr.cfloat,pointer,ptr.cfloat,pthreadpool_t">
  <dt><pre><span class="Keyword">proc</span> <a href="#nnp_fully_connected_inference_f16f32%2Ccsize_t%2Ccsize_t%2Cptr.cfloat%2Cpointer%2Cptr.cfloat%2Cpthreadpool_t"><span class="Identifier">nnp_fully_connected_inference_f16f32</span></a><span class="Other">(</span><span class="Identifier">input_channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
    <span class="Identifier">output_channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span> <span class="Identifier">input</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span> <span class="Identifier">kernel</span><span class="Other">:</span> <span class="Identifier">pointer</span><span class="Other">;</span>
    <span class="Identifier">output</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span> <span class="Identifier">threadpool</span><span class="Other">:</span> <a href="nnpack.html#pthreadpool_t"><span class="Identifier">pthreadpool_t</span></a><span class="Other">)</span><span class="Other">:</span> <a href="nnpack.html#nnp_status"><span class="Identifier">nnp_status</span></a> {.<span class="Identifier">cdecl</span><span class="Other">,</span>
    <span class="Identifier">importc</span><span class="Other">:</span> <span class="StringLit">&quot;nnp_fully_connected_inference_f16f32&quot;</span><span class="Other">,</span> <span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span>
    <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L403"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L403" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="nnp_fully_connected_output-procs-all">
  <div id="nnp_fully_connected_output,csize_t,csize_t,csize_t,ptr.cfloat,ptr.cfloat,ptr.cfloat,pthreadpool_t,ptr.nnp_profile">
  <dt><pre><span class="Keyword">proc</span> <a href="#nnp_fully_connected_output%2Ccsize_t%2Ccsize_t%2Ccsize_t%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Cpthreadpool_t%2Cptr.nnp_profile"><span class="Identifier">nnp_fully_connected_output</span></a><span class="Other">(</span><span class="Identifier">batch_size</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span> <span class="Identifier">input_channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
                                <span class="Identifier">output_channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span> <span class="Identifier">input</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                                <span class="Identifier">kernel</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span> <span class="Identifier">output</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                                <span class="Identifier">threadpool</span><span class="Other">:</span> <a href="nnpack.html#pthreadpool_t"><span class="Identifier">pthreadpool_t</span></a><span class="Other">;</span>
                                <span class="Identifier">profile</span><span class="Other">:</span> <span class="Keyword">ptr</span> <a href="nnpack.html#nnp_profile"><span class="Identifier">nnp_profile</span></a><span class="Other">)</span><span class="Other">:</span> <a href="nnpack.html#nnp_status"><span class="Identifier">nnp_status</span></a> {.<span class="Identifier">cdecl</span><span class="Other">,</span>
    <span class="Identifier">importc</span><span class="Other">:</span> <span class="StringLit">&quot;nnp_fully_connected_output&quot;</span><span class="Other">,</span> <span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L369"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L369" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="nnp_initialize-procs-all">
  <div id="nnp_initialize">
  <dt><pre><span class="Keyword">proc</span> <a href="#nnp_initialize"><span class="Identifier">nnp_initialize</span></a><span class="Other">(</span><span class="Other">)</span><span class="Other">:</span> <a href="nnpack.html#nnp_status"><span class="Identifier">nnp_status</span></a> {.<span class="Identifier">cdecl</span><span class="Other">,</span> <span class="Identifier">importc</span><span class="Other">:</span> <span class="StringLit">&quot;nnp_initialize&quot;</span><span class="Other">,</span>
                                    <span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L145"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L145" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="nnp_max_pooling_output-procs-all">
  <div id="nnp_max_pooling_output,csize_t,csize_t,nnp_size,nnp_padding,nnp_size,nnp_size,ptr.cfloat,ptr.cfloat,pthreadpool_t">
  <dt><pre><span class="Keyword">proc</span> <a href="#nnp_max_pooling_output%2Ccsize_t%2Ccsize_t%2Cnnp_size%2Cnnp_padding%2Cnnp_size%2Cnnp_size%2Cptr.cfloat%2Cptr.cfloat%2Cpthreadpool_t"><span class="Identifier">nnp_max_pooling_output</span></a><span class="Other">(</span><span class="Identifier">batch_size</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span> <span class="Identifier">channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
                            <span class="Identifier">input_size</span><span class="Other">:</span> <a href="nnpack.html#nnp_size"><span class="Identifier">nnp_size</span></a><span class="Other">;</span> <span class="Identifier">input_padding</span><span class="Other">:</span> <a href="nnpack.html#nnp_padding"><span class="Identifier">nnp_padding</span></a><span class="Other">;</span>
                            <span class="Identifier">pooling_size</span><span class="Other">:</span> <a href="nnpack.html#nnp_size"><span class="Identifier">nnp_size</span></a><span class="Other">;</span> <span class="Identifier">pooling_stride</span><span class="Other">:</span> <a href="nnpack.html#nnp_size"><span class="Identifier">nnp_size</span></a><span class="Other">;</span>
                            <span class="Identifier">input</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span> <span class="Identifier">output</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                            <span class="Identifier">threadpool</span><span class="Other">:</span> <a href="nnpack.html#pthreadpool_t"><span class="Identifier">pthreadpool_t</span></a><span class="Other">)</span><span class="Other">:</span> <a href="nnpack.html#nnp_status"><span class="Identifier">nnp_status</span></a> {.<span class="Identifier">cdecl</span><span class="Other">,</span>
    <span class="Identifier">importc</span><span class="Other">:</span> <span class="StringLit">&quot;nnp_max_pooling_output&quot;</span><span class="Other">,</span> <span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L430"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L430" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="nnp_relu_input_gradient-procs-all">
  <div id="nnp_relu_input_gradient,csize_t,csize_t,ptr.cfloat,ptr.cfloat,ptr.cfloat,cfloat,pthreadpool_t">
  <dt><pre><span class="Keyword">proc</span> <a href="#nnp_relu_input_gradient%2Ccsize_t%2Ccsize_t%2Cptr.cfloat%2Cptr.cfloat%2Cptr.cfloat%2Ccfloat%2Cpthreadpool_t"><span class="Identifier">nnp_relu_input_gradient</span></a><span class="Other">(</span><span class="Identifier">batch_size</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span> <span class="Identifier">channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
                             <span class="Identifier">grad_output</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span> <span class="Identifier">input</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                             <span class="Identifier">grad_input</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span> <span class="Identifier">negative_slope</span><span class="Other">:</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                             <span class="Identifier">threadpool</span><span class="Other">:</span> <a href="nnpack.html#pthreadpool_t"><span class="Identifier">pthreadpool_t</span></a><span class="Other">)</span><span class="Other">:</span> <a href="nnpack.html#nnp_status"><span class="Identifier">nnp_status</span></a> {.<span class="Identifier">cdecl</span><span class="Other">,</span>
    <span class="Identifier">importc</span><span class="Other">:</span> <span class="StringLit">&quot;nnp_relu_input_gradient&quot;</span><span class="Other">,</span> <span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L479"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L479" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="nnp_relu_output-procs-all">
  <div id="nnp_relu_output,csize_t,csize_t,ptr.cfloat,ptr.cfloat,cfloat,pthreadpool_t">
  <dt><pre><span class="Keyword">proc</span> <a href="#nnp_relu_output%2Ccsize_t%2Ccsize_t%2Cptr.cfloat%2Cptr.cfloat%2Ccfloat%2Cpthreadpool_t"><span class="Identifier">nnp_relu_output</span></a><span class="Other">(</span><span class="Identifier">batch_size</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span> <span class="Identifier">channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span> <span class="Identifier">input</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                     <span class="Identifier">output</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span> <span class="Identifier">negative_slope</span><span class="Other">:</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                     <span class="Identifier">threadpool</span><span class="Other">:</span> <a href="nnpack.html#pthreadpool_t"><span class="Identifier">pthreadpool_t</span></a><span class="Other">)</span><span class="Other">:</span> <a href="nnpack.html#nnp_status"><span class="Identifier">nnp_status</span></a> {.<span class="Identifier">cdecl</span><span class="Other">,</span>
    <span class="Identifier">importc</span><span class="Other">:</span> <span class="StringLit">&quot;nnp_relu_output&quot;</span><span class="Other">,</span> <span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L463"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L463" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="nnp_softmax_output-procs-all">
  <div id="nnp_softmax_output,csize_t,csize_t,ptr.cfloat,ptr.cfloat,pthreadpool_t">
  <dt><pre><span class="Keyword">proc</span> <a href="#nnp_softmax_output%2Ccsize_t%2Ccsize_t%2Cptr.cfloat%2Cptr.cfloat%2Cpthreadpool_t"><span class="Identifier">nnp_softmax_output</span></a><span class="Other">(</span><span class="Identifier">batch_size</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span> <span class="Identifier">channels</span><span class="Other">:</span> <span class="Identifier">csize_t</span><span class="Other">;</span>
                        <span class="Identifier">input</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span> <span class="Identifier">output</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">cfloat</span><span class="Other">;</span>
                        <span class="Identifier">threadpool</span><span class="Other">:</span> <a href="nnpack.html#pthreadpool_t"><span class="Identifier">pthreadpool_t</span></a><span class="Other">)</span><span class="Other">:</span> <a href="nnpack.html#nnp_status"><span class="Identifier">nnp_status</span></a> {.<span class="Identifier">cdecl</span><span class="Other">,</span>
    <span class="Identifier">importc</span><span class="Other">:</span> <span class="StringLit">&quot;nnp_softmax_output&quot;</span><span class="Other">,</span> <span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L448"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/nn_primitives/backend/nnpack.nim#L448" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>

  </dl>
</div>

  </div>
</div>

    <div class="row">
      <div class="twelve-columns footer">
        <span class="nim-sprite"></span>
        <br/>
        <small style="color: var(--hint);">Made with Nim. Generated: 2024-05-12 14:00:39 UTC</small>
      </div>
    </div>
  </div>
</div>

<header>
  <a class="pagetitle" href="index.html">Arraymancer</a>
  <span>
    <a href="#">Technical reference</a>
    <ul class="monospace" style="padding-bottom: 15px; padding-top: 10px;">
      <span>
      <li>
        <a href="#">Core tensor API</a>
        <ul class="monospace">
          <li><a href="accessors.html">accessors</a></li>
<li><a href="accessors_macros_read.html">accessors_macros_read</a></li>
<li><a href="accessors_macros_syntax.html">accessors_macros_syntax</a></li>
<li><a href="accessors_macros_write.html">accessors_macros_write</a></li>
<li><a href="aggregate.html">aggregate</a></li>
<li><a href="algorithms.html">algorithms</a></li>
<li><a href="blas_l3_gemm.html">blas_l3_gemm</a></li>
<li><a href="complex.html">complex</a></li>
<li><a href="cublas.html">cublas</a></li>
<li><a href="cuda.html">cuda</a></li>
<li><a href="cuda_global_state.html">cuda_global_state</a></li>
<li><a href="data_structure.html">data_structure</a></li>
<li><a href="display.html">display</a></li>
<li><a href="display_cuda.html">display_cuda</a></li>
<li><a href="einsum.html">einsum</a></li>
<li><a href="exporting.html">exporting</a></li>
<li><a href="filling_data.html">filling_data</a></li>
<li><a href="higher_order_applymap.html">higher_order_applymap</a></li>
<li><a href="higher_order_foldreduce.html">higher_order_foldreduce</a></li>
<li><a href="incl_accessors_cuda.html">incl_accessors_cuda</a></li>
<li><a href="incl_higher_order_cuda.html">incl_higher_order_cuda</a></li>
<li><a href="incl_kernels_cuda.html">incl_kernels_cuda</a></li>
<li><a href="init_copy_cpu.html">init_copy_cpu</a></li>
<li><a href="init_copy_cuda.html">init_copy_cuda</a></li>
<li><a href="init_cpu.html">init_cpu</a></li>
<li><a href="init_cuda.html">init_cuda</a></li>
<li><a href="init_opencl.html">init_opencl</a></li>
<li><a href="lapack.html">lapack</a></li>
<li><a href="math_functions.html">math_functions</a></li>
<li><a href="memory_optimization_hints.html">memory_optimization_hints</a></li>
<li><a href="naive_l2_gemv.html">naive_l2_gemv</a></li>
<li><a href="opencl_backend.html">opencl_backend</a></li>
<li><a href="opencl_global_state.html">opencl_global_state</a></li>
<li><a href="openmp.html">openmp</a></li>
<li><a href="operators_blas_l1.html">operators_blas_l1</a></li>
<li><a href="operators_blas_l1_cuda.html">operators_blas_l1_cuda</a></li>
<li><a href="operators_blas_l1_opencl.html">operators_blas_l1_opencl</a></li>
<li><a href="operators_blas_l2l3.html">operators_blas_l2l3</a></li>
<li><a href="operators_blas_l2l3_cuda.html">operators_blas_l2l3_cuda</a></li>
<li><a href="operators_blas_l2l3_opencl.html">operators_blas_l2l3_opencl</a></li>
<li><a href="operators_broadcasted.html">operators_broadcasted</a></li>
<li><a href="operators_broadcasted_cuda.html">operators_broadcasted_cuda</a></li>
<li><a href="operators_broadcasted_opencl.html">operators_broadcasted_opencl</a></li>
<li><a href="operators_comparison.html">operators_comparison</a></li>
<li><a href="operators_logical.html">operators_logical</a></li>
<li><a href="optim_ops_fusion.html">optim_ops_fusion</a></li>
<li><a href="p_accessors.html">p_accessors</a></li>
<li><a href="p_accessors_macros_desugar.html">p_accessors_macros_desugar</a></li>
<li><a href="p_accessors_macros_read.html">p_accessors_macros_read</a></li>
<li><a href="p_accessors_macros_write.html">p_accessors_macros_write</a></li>
<li><a href="p_checks.html">p_checks</a></li>
<li><a href="p_complex.html">p_complex</a></li>
<li><a href="p_display.html">p_display</a></li>
<li><a href="p_empty_tensors.html">p_empty_tensors</a></li>
<li><a href="p_init_cuda.html">p_init_cuda</a></li>
<li><a href="p_init_opencl.html">p_init_opencl</a></li>
<li><a href="p_kernels_interface_cuda.html">p_kernels_interface_cuda</a></li>
<li><a href="p_kernels_interface_opencl.html">p_kernels_interface_opencl</a></li>
<li><a href="p_operator_blas_l2l3.html">p_operator_blas_l2l3</a></li>
<li><a href="p_shapeshifting.html">p_shapeshifting</a></li>
<li><a href="selectors.html">selectors</a></li>
<li><a href="shapeshifting.html">shapeshifting</a></li>
<li><a href="shapeshifting_cuda.html">shapeshifting_cuda</a></li>
<li><a href="shapeshifting_opencl.html">shapeshifting_opencl</a></li>
<li><a href="syntactic_sugar.html">syntactic_sugar</a></li>
<li><a href="tensor_cuda.html">tensor_cuda</a></li>
<li><a href="tensor_opencl.html">tensor_opencl</a></li>
<li><a href="ufunc.html">ufunc</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Neural network API</a>
        <ul class="monospace">
          <li><a href="conv2D.html">Layers: Convolution 2D</a></li>
<li><a href="cross_entropy_losses.html">Loss: Cross-Entropy losses</a></li>
<li><a href="embedding.html">Layers: Embedding</a></li>
<li><a href="flatten.html">flatten</a></li>
<li><a href="gcn.html">gcn</a></li>
<li><a href="gru.html">Layers: GRU (Gated Linear Unit)</a></li>
<li><a href="init.html">Layers: Initializations</a></li>
<li><a href="linear.html">Layers: Linear/Dense</a></li>
<li><a href="maxpool2D.html">Layers: Maxpool 2D</a></li>
<li><a href="mean_square_error_loss.html">Loss: Mean Square Error</a></li>
<li><a href="nn_dsl.html">Neural network: Declaration</a></li>
<li><a href="optimizers.html">Optimizers</a></li>
<li><a href="relu.html">Activation: Relu (Rectified linear Unit)</a></li>
<li><a href="sigmoid.html">Activation: Sigmoid</a></li>
<li><a href="softmax.html">Softmax</a></li>
<li><a href="tanh.html">Activation: Tanh</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Linear algebra, stats, ML</a>
        <ul class="monospace">
          <li><a href="accuracy_score.html">Accuracy score</a></li>
<li><a href="algebra.html">algebra</a></li>
<li><a href="auxiliary_blas.html">auxiliary_blas</a></li>
<li><a href="auxiliary_lapack.html">auxiliary_lapack</a></li>
<li><a href="common_error_functions.html">Common errors, MAE and MSE (L1, L2 loss)</a></li>
<li><a href="dbscan.html">dbscan</a></li>
<li><a href="decomposition.html">Eigenvalue decomposition</a></li>
<li><a href="decomposition_lapack.html">decomposition_lapack</a></li>
<li><a href="decomposition_rand.html">Randomized Truncated SVD</a></li>
<li><a href="distributions.html">distributions</a></li>
<li><a href="init_colmajor.html">init_colmajor</a></li>
<li><a href="kde.html">kde</a></li>
<li><a href="kmeans.html">K-Means</a></li>
<li><a href="least_squares.html">Least squares solver</a></li>
<li><a href="least_squares_lapack.html">least_squares_lapack</a></li>
<li><a href="linear_systems.html">Linear systems solver</a></li>
<li><a href="overload.html">overload</a></li>
<li><a href="pca.html">Principal Component Analysis (PCA)</a></li>
<li><a href="solve_lapack.html">solve_lapack</a></li>
<li><a href="special_matrices.html">Special linear algebra matrices</a></li>
<li><a href="stats.html">Statistics</a></li>
<li><a href="triangular.html">triangular</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">IO & Datasets</a>
        <ul class="monospace">
          <li><a href="imdb.html">IMDB</a></li>
<li><a href="io_csv.html">CSV reading and writing</a></li>
<li><a href="io_hdf5.html">HDF5 files reading and writing</a></li>
<li><a href="io_image.html">Images reading and writing</a></li>
<li><a href="io_npy.html">Numpy files reading and writing</a></li>
<li><a href="io_stream_readers.html">io_stream_readers</a></li>
<li><a href="mnist.html">MNIST</a></li>
<li><a href="util.html">util</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Autograd</a>
        <ul class="monospace">
          <li><a href="autograd_common.html">Data structure</a></li>
<li><a href="gates_basic.html">Basic operations</a></li>
<li><a href="gates_blas.html">Linear algebra operations</a></li>
<li><a href="gates_hadamard.html">Hadamard product (elementwise matrix multiply)</a></li>
<li><a href="gates_reduce.html">Reduction operations</a></li>
<li><a href="gates_shapeshifting_concat_split.html">Concatenation, stacking, splitting, chunking operations</a></li>
<li><a href="gates_shapeshifting_views.html">Linear algebra operations</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Neuralnet primitives</a>
        <ul class="monospace">
          <li><a href="conv.html">conv</a></li>
<li><a href="cudnn.html">cudnn</a></li>
<li><a href="cudnn_conv_interface.html">cudnn_conv_interface</a></li>
<li><a href="nnp_activation.html">Activations</a></li>
<li><a href="nnp_conv2d_cudnn.html">Convolution 2D - CuDNN</a></li>
<li><a href="nnp_convolution.html">Convolution 2D</a></li>
<li><a href="nnp_embedding.html">Embeddings</a></li>
<li><a href="nnp_gru.html">Gated Recurrent Unit (GRU)</a></li>
<li><a href="nnp_linear.html">Linear / Dense layer</a></li>
<li><a href="nnp_maxpooling.html">Maxpooling</a></li>
<li><a href="nnp_numerical_gradient.html">Numerical gradient</a></li>
<li><a href="nnp_sigmoid_cross_entropy.html">Sigmoid Cross-Entropy loss</a></li>
<li><a href="nnp_softmax.html">Softmax</a></li>
<li><a href="nnp_softmax_cross_entropy.html">Softmax Cross-Entropy loss</a></li>
<li><a href="nnpack.html">nnpack</a></li>
<li><a href="nnpack_interface.html">nnpack_interface</a></li>
<li><a href="p_activation.html">p_activation</a></li>
<li><a href="p_logsumexp.html">p_logsumexp</a></li>
<li><a href="p_nnp_checks.html">p_nnp_checks</a></li>
<li><a href="p_nnp_types.html">p_nnp_types</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Other docs</a>
        <ul class="monospace">
          <li><a href="align_unroller.html">align_unroller</a></li>
<li><a href="ast_utils.html">ast_utils</a></li>
<li><a href="compiler_optim_hints.html">compiler_optim_hints</a></li>
<li><a href="cpuinfo_x86.html">cpuinfo_x86</a></li>
<li><a href="datatypes.html">datatypes</a></li>
<li><a href="deprecate.html">deprecate</a></li>
<li><a href="dynamic_stack_arrays.html">dynamic_stack_arrays</a></li>
<li><a href="foreach.html">foreach</a></li>
<li><a href="foreach_common.html">foreach_common</a></li>
<li><a href="foreach_staged.html">foreach_staged</a></li>
<li><a href="functional.html">functional</a></li>
<li><a href="gemm.html">gemm</a></li>
<li><a href="gemm_packing.html">gemm_packing</a></li>
<li><a href="gemm_prepacked.html">gemm_prepacked</a></li>
<li><a href="gemm_tiling.html">gemm_tiling</a></li>
<li><a href="gemm_ukernel_avx.html">gemm_ukernel_avx</a></li>
<li><a href="gemm_ukernel_avx2.html">gemm_ukernel_avx2</a></li>
<li><a href="gemm_ukernel_avx512.html">gemm_ukernel_avx512</a></li>
<li><a href="gemm_ukernel_avx_fma.html">gemm_ukernel_avx_fma</a></li>
<li><a href="gemm_ukernel_dispatch.html">gemm_ukernel_dispatch</a></li>
<li><a href="gemm_ukernel_generator.html">gemm_ukernel_generator</a></li>
<li><a href="gemm_ukernel_generic.html">gemm_ukernel_generic</a></li>
<li><a href="gemm_ukernel_sse.html">gemm_ukernel_sse</a></li>
<li><a href="gemm_ukernel_sse2.html">gemm_ukernel_sse2</a></li>
<li><a href="gemm_ukernel_sse4_1.html">gemm_ukernel_sse4_1</a></li>
<li><a href="gemm_utils.html">gemm_utils</a></li>
<li><a href="global_config.html">global_config</a></li>
<li><a href="initialization.html">initialization</a></li>
<li><a href="math_ops_fusion.html">math_ops_fusion</a></li>
<li><a href="memory.html">memory</a></li>
<li><a href="nested_containers.html">nested_containers</a></li>
<li><a href="openmp.html">openmp</a></li>
<li><a href="sequninit.html">sequninit</a></li>
<li><a href="simd.html">simd</a></li>
<li><a href="tokenizers.html">tokenizers</a></li>
        </ul>
      </li>
      </span>
    </ul>
  </span>
  <span>
    <a href="#">Tutorial</a>
    <ul class="monospace">
      <li><a href="tuto.first_steps.html">First steps</a></li>
      <li><a href="tuto.slicing.html">Taking a slice of a tensor</a></li>
      <li><a href="tuto.linear_algebra.html">Matrix & vectors operations</a></li>
      <li><a href="tuto.broadcasting.html">Broadcasted operations</a></li>
      <li><a href="tuto.shapeshifting.html">Transposing, Reshaping, Permuting, Concatenating</a></li>
      <li><a href="tuto.map_reduce.html">Map & Reduce</a></li>
      <li><a href="tuto.iterators.html">Basic iterators</a></li>
    </ul>
  </span>
  <span>
    <a href="#">Spellbook (How-To&apos;s)</a>
    <ul class="monospace">
      <li><a href="howto.type_conversion.html">How to convert a Tensor type?</a></li>
      <li><a href="howto.ufunc.html">How to create a new universal function?</a></li>
      <li><a href="howto.perceptron.html">How to create a multilayer perceptron?</a></li>
    </ul>
  </span>
  <span>
    <a href="#">Under the hood</a>
    <ul class="monospace">
      <li><a href="uth.speed.html">How Arraymancer achieves its speed?</a></li>
      <li><a href="uth.copy_semantics.html">Why does `=` share data by default aka reference semantics?</a></li>
      <li><a href="uth.opencl_cuda_nim.html">Working with OpenCL and Cuda in Nim</a></li>
    </ul>
  </span>
</header>
</body>
</html>
