<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!--  This file is generated by Nim. -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Favicon -->
<link rel="shortcut icon" href="data:image/x-icon;base64,AAABAAEAEBAAAAEAIABoBAAAFgAAACgAAAAQAAAAIAAAAAEAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AAAAAAUAAAAF////AP///wD///8A////AP///wD///8A////AP///wD///8A////AAAAAAIAAABbAAAAlQAAAKIAAACbAAAAmwAAAKIAAACVAAAAWwAAAAL///8A////AP///wD///8A////AAAAABQAAADAAAAAYwAAAA3///8A////AP///wD///8AAAAADQAAAGMAAADAAAAAFP///wD///8A////AP///wAAAACdAAAAOv///wD///8A////AP///wD///8A////AP///wD///8AAAAAOgAAAJ3///8A////AP///wAAAAAnAAAAcP///wAAAAAoAAAASv///wD///8A////AP///wAAAABKAAAAKP///wAAAABwAAAAJ////wD///8AAAAAgQAAABwAAACIAAAAkAAAAJMAAACtAAAAFQAAABUAAACtAAAAkwAAAJAAAACIAAAAHAAAAIH///8A////AAAAAKQAAACrAAAAaP///wD///8AAAAARQAAANIAAADSAAAARf///wD///8AAAAAaAAAAKsAAACk////AAAAADMAAACcAAAAnQAAABj///8A////AP///wAAAAAYAAAAGP///wD///8A////AAAAABgAAACdAAAAnAAAADMAAAB1AAAAwwAAAP8AAADpAAAAsQAAAE4AAAAb////AP///wAAAAAbAAAATgAAALEAAADpAAAA/wAAAMMAAAB1AAAAtwAAAOkAAAD/AAAA/wAAAP8AAADvAAAA3gAAAN4AAADeAAAA3gAAAO8AAAD/AAAA/wAAAP8AAADpAAAAtwAAAGUAAAA/AAAA3wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAADfAAAAPwAAAGX///8A////AAAAAEgAAADtAAAAvwAAAL0AAADGAAAA7wAAAO8AAADGAAAAvQAAAL8AAADtAAAASP///wD///8A////AP///wD///8AAAAAO////wD///8A////AAAAAIcAAACH////AP///wD///8AAAAAO////wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A//8AAP//AAD4HwAA7/cAAN/7AAD//wAAoYUAAJ55AACf+QAAh+EAAAAAAADAAwAA4AcAAP5/AAD//wAA//8AAA=="/>
<link rel="icon" type="image/png" sizes="32x32" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABmJLR0QA/wD/AP+gvaeTAAAACXBIWXMAAA3XAAAN1wFCKJt4AAAAB3RJTUUH4QQQEwksSS9ZWwAAAk1JREFUWMPtll2ITVEUx39nn/O7Y5qR8f05wtCUUr6ZIS++8pEnkZInPImneaCQ5METNdOkeFBKUhMPRIkHKfEuUZSUlGlKPN2TrgfncpvmnntnmlEyq1Z7t89/rf9a6+y99oZxGZf/XeIq61EdtgKXgdXA0xrYAvBjOIF1AI9zvjcC74BSpndrJPkBWDScTF8Aa4E3wDlgHbASaANmVqlcCnwHvgDvgVfAJ+AikAAvgfVZwLnSVZHZaOuKoQi3ZOMi4NkYkpe1p4J7A8BpYAD49hfIy/oqG0+hLomiKP2L5L+1ubn5115S+3OAn4EnwBlgMzCjyt6ZAnQCJ4A7wOs88iRJHvw50HoujuPBoCKwHWiosy8MdfZnAdcHk8dxXFJ3VQbQlCTJvRBCGdRbD4M6uc5glpY3eAihpN5S5w12diSEcCCEcKUO4ljdr15T76ur1FDDLIQQ3qv71EdDOe3Kxj3leRXyk+pxdWnFWod6Wt2bY3de3aSuUHcPBVimHs7mK9WrmeOF6lR1o9qnzskh2ar2qm1qizpfXaPeVGdlmGN5pb09qMxz1Xb1kLqgzn1RyH7JUXW52lr5e/Kqi9qpto7V1atuUzfnARrV7jEib1T76gG2qxdGmXyiekkt1GswPTtek0aBfJp6YySGBfWg2tPQ0FAYgf1stUfdmdcjarbYJEniKIq6gY/Aw+zWHAC+p2labGpqiorFYgGYCEzN7oQdQClN07O1/EfDyGgC0ALMBdYAi4FyK+4H3gLPsxfR1zRNi+NP7nH5J+QntnXe5B5mpfQAAAAASUVORK5CYII=">

<!-- Google fonts -->
<link href='https://fonts.googleapis.com/css?family=Lato:400,600,900' rel='stylesheet' type='text/css'/>
<link href='https://fonts.googleapis.com/css?family=Source+Code+Pro:400,500,600' rel='stylesheet' type='text/css'/>

<!-- CSS -->
<title>src/arraymancer/tensor/aggregate</title>
<link rel="stylesheet" type="text/css" href="nimdoc.out.css">

<script type="text/javascript" src="dochack.js"></script>

<script type="text/javascript">
function main() {
  var pragmaDots = document.getElementsByClassName("pragmadots");
  for (var i = 0; i < pragmaDots.length; i++) {
    pragmaDots[i].onclick = function(event) {
      // Hide tease
      event.target.parentNode.style.display = "none";
      // Show actual
      event.target.parentNode.nextElementSibling.style.display = "inline";
    }
  }

  const toggleSwitch = document.querySelector('.theme-switch input[type="checkbox"]');
  function switchTheme(e) {
      if (e.target.checked) {
          document.documentElement.setAttribute('data-theme', 'dark');
          localStorage.setItem('theme', 'dark');
      } else {
          document.documentElement.setAttribute('data-theme', 'light');
          localStorage.setItem('theme', 'light');
      }
  }

  toggleSwitch.addEventListener('change', switchTheme, false);


  if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
    document.documentElement.setAttribute('data-theme', "dark");
    toggleSwitch.checked = true;
  } else if (window.matchMedia && window.matchMedia('(prefers-color-scheme: light)').matches) {
    document.documentElement.setAttribute('data-theme', "light");
    toggleSwitch.checked = false;
  } else {
    const currentTheme = localStorage.getItem('theme') ? localStorage.getItem('theme') : null;
    if (currentTheme) {
      document.documentElement.setAttribute('data-theme', currentTheme);

      if (currentTheme === 'dark') {
        toggleSwitch.checked = true;
      }
    }
  }
}
</script>

</head>

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Arraymancer - src/arraymancer/tensor/aggregate</title>

<link href="docutils.css" rel="stylesheet" type="text/css"/>
<link href="nav.css" rel="stylesheet" type="text/css"/>

<link href='http://fonts.googleapis.com/css?family=Raleway:400,600,900' rel='stylesheet' type='text/css'/>
<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:400,500,600' rel='stylesheet' type='text/css'/>

<a href="https://github.com/mratsim/arraymancer"><img style="position: fixed; top: 0; right: 0; border: 0; z-index: 10;" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_gray_6d6d6d.png?resize=150%2C150" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png"></a>

<body onload="main()">
<div class="document" id="documentId">
  <div class="container">
    <h1 class="title">src/arraymancer/tensor/aggregate</h1>
    <div class="row">
  <div class="three columns">
    <div class="theme-select-wrapper">
      <label for="theme-select">Theme:&nbsp;</label>
      <select id="theme-select" onchange="setTheme(this.value)">
        <option value="auto">ðŸŒ— Match OS</option>
        <option value="dark">ðŸŒ‘ Dark</option>
        <option value="light">ðŸŒ• Light</option>
      </select>
    </div>
    <div id="global-links">
      <ul class="simple">
        <li><a id="indexLink" href="theindex.html">Index</a></li>
      </ul>
    </div>
    <div id="searchInputDiv">
      Search: <input type="search" id="searchInput" onkeyup="search()"/>
    </div>
    <div>
      Group by:
      <select onchange="groupBy(this.value)">
        <option value="section">Section</option>
        <option value="type">Type</option>
      </select>
    </div>
    <ul class="simple simple-toc" id="toc-list">
  <li>
  <a class="reference reference-toplevel" href="#6" id="56">Imports</a>
</li>
<li>
  <details open>
    <summary><a class="reference reference-toplevel" href="#12" id="62">Procs</a></summary>
    <ul class="simple simple-toc-section">
      <ul class="simple nested-toc-section">all
  <li><a class="reference" href="#all%2CTensor%5BT%5D" title="all[T](t: Tensor[T]): bool">all[T](t: Tensor[T]): bool</a></li>

</ul>
<ul class="simple nested-toc-section">any
  <li><a class="reference" href="#any%2CTensor%5BT%5D" title="any[T](t: Tensor[T]): bool">any[T](t: Tensor[T]): bool</a></li>

</ul>
<ul class="simple nested-toc-section">argmax
  <li><a class="reference" href="#argmax%2CTensor%5BT%5D%2Cint" title="argmax[T](arg: Tensor[T]; axis: int): Tensor[int]">argmax[T](arg: Tensor[T]; axis: int): Tensor[int]</a></li>

</ul>
<ul class="simple nested-toc-section">argmax_max
  <li><a class="reference" href="#argmax_max%2CTensor%5BT%3A%20SomeNumber%5D%2Cint" title="argmax_max[T: SomeNumber](arg: Tensor[T]; axis: int): tuple[
    indices: Tensor[int], maxes: Tensor[T]]">argmax_max[T: SomeNumber](arg: Tensor[T]; axis: int): tuple[
    indices: Tensor[int], maxes: Tensor[T]]</a></li>

</ul>
<ul class="simple nested-toc-section">argmin
  <li><a class="reference" href="#argmin%2CTensor%5BT%5D%2Cint" title="argmin[T](arg: Tensor[T]; axis: int): Tensor[int]">argmin[T](arg: Tensor[T]; axis: int): Tensor[int]</a></li>

</ul>
<ul class="simple nested-toc-section">argmin_min
  <li><a class="reference" href="#argmin_min%2CTensor%5BT%3A%20SomeNumber%5D%2Cint" title="argmin_min[T: SomeNumber](arg: Tensor[T]; axis: int): tuple[
    indices: Tensor[int], mins: Tensor[T]]">argmin_min[T: SomeNumber](arg: Tensor[T]; axis: int): tuple[
    indices: Tensor[int], mins: Tensor[T]]</a></li>

</ul>
<ul class="simple nested-toc-section">cumprod
  <li><a class="reference" href="#cumprod%2CTensor%5BT%5D%2Cint" title="cumprod[T](arg: Tensor[T]; axis: int = 0): Tensor[T]">cumprod[T](arg: Tensor[T]; axis: int = 0): Tensor[T]</a></li>

</ul>
<ul class="simple nested-toc-section">cumsum
  <li><a class="reference" href="#cumsum%2CTensor%5BT%5D%2Cint" title="cumsum[T](arg: Tensor[T]; axis: int = 0): Tensor[T]">cumsum[T](arg: Tensor[T]; axis: int = 0): Tensor[T]</a></li>

</ul>
<ul class="simple nested-toc-section">diff_discrete
  <li><a class="reference" href="#diff_discrete%2CTensor%5BT%5D%2Cint%2Cint" title="diff_discrete[T](arg: Tensor[T]; n = 1; axis: int = -1): Tensor[T]">diff_discrete[T](arg: Tensor[T]; n = 1; axis: int = -1): Tensor[T]</a></li>

</ul>
<ul class="simple nested-toc-section">iqr
  <li><a class="reference" href="#iqr%2CTensor%5BT%5D" title="iqr[T](arg: Tensor[T]): float">iqr[T](arg: Tensor[T]): float</a></li>

</ul>
<ul class="simple nested-toc-section">max
  <li><a class="reference" href="#max%2CTensor%5BT%5D" title="max[T](arg: Tensor[T]): T">max[T](arg: Tensor[T]): T</a></li>
<li><a class="reference" href="#max%2CTensor%5BT%5D%2Cint" title="max[T](arg: Tensor[T]; axis: int): Tensor[T]">max[T](arg: Tensor[T]; axis: int): Tensor[T]</a></li>

</ul>
<ul class="simple nested-toc-section">mean
  <li><a class="reference" href="#mean%2CTensor%5BT%3A%20Complex%5Bsystem.float32%5D%20or%20Complex%5Bsystem.float64%5D%5D" title="mean[T: Complex[float32] or Complex[float64]](arg: Tensor[T]): T">mean[T: Complex[float32] or Complex[float64]](arg: Tensor[T]): T</a></li>
<li><a class="reference" href="#mean%2CTensor%5BT%3A%20Complex%5Bsystem.float32%5D%20or%20Complex%5Bsystem.float64%5D%5D%2Cint" title="mean[T: Complex[float32] or Complex[float64]](arg: Tensor[T]; axis: int): Tensor[
    T]">mean[T: Complex[float32] or Complex[float64]](arg: Tensor[T]; axis: int): Tensor[
    T]</a></li>
<li><a class="reference" href="#mean%2CTensor%5BT%3A%20SomeFloat%5D" title="mean[T: SomeFloat](arg: Tensor[T]): T">mean[T: SomeFloat](arg: Tensor[T]): T</a></li>
<li><a class="reference" href="#mean%2CTensor%5BT%3A%20SomeFloat%5D%2Cint" title="mean[T: SomeFloat](arg: Tensor[T]; axis: int): Tensor[T]">mean[T: SomeFloat](arg: Tensor[T]; axis: int): Tensor[T]</a></li>
<li><a class="reference" href="#mean%2CTensor%5BT%3A%20SomeInteger%5D" title="mean[T: SomeInteger](arg: Tensor[T]): T">mean[T: SomeInteger](arg: Tensor[T]): T</a></li>
<li><a class="reference" href="#mean%2CTensor%5BT%3A%20SomeInteger%5D%2Cint" title="mean[T: SomeInteger](arg: Tensor[T]; axis: int): Tensor[T]">mean[T: SomeInteger](arg: Tensor[T]; axis: int): Tensor[T]</a></li>

</ul>
<ul class="simple nested-toc-section">median
  <li><a class="reference" href="#median%2CTensor%5BT%5D" title="median[T](arg: Tensor[T]; isSorted = false): float">median[T](arg: Tensor[T]; isSorted = false): float</a></li>

</ul>
<ul class="simple nested-toc-section">min
  <li><a class="reference" href="#min%2CTensor%5BT%5D" title="min[T](arg: Tensor[T]): T">min[T](arg: Tensor[T]): T</a></li>
<li><a class="reference" href="#min%2CTensor%5BT%5D%2Cint" title="min[T](arg: Tensor[T]; axis: int): Tensor[T]">min[T](arg: Tensor[T]; axis: int): Tensor[T]</a></li>

</ul>
<ul class="simple nested-toc-section">nonzero
  <li><a class="reference" href="#nonzero%2CTensor%5BT%5D" title="nonzero[T](arg: Tensor[T]): Tensor[int]">nonzero[T](arg: Tensor[T]): Tensor[int]</a></li>

</ul>
<ul class="simple nested-toc-section">percentile
  <li><a class="reference" href="#percentile%2CTensor%5BT%5D%2Cint" title="percentile[T](arg: Tensor[T]; p: int; isSorted = false): float">percentile[T](arg: Tensor[T]; p: int; isSorted = false): float</a></li>

</ul>
<ul class="simple nested-toc-section">product
  <li><a class="reference" href="#product%2CTensor%5BT%5D" title="product[T](arg: Tensor[T]): T">product[T](arg: Tensor[T]): T</a></li>
<li><a class="reference" href="#product%2CTensor%5BT%5D%2Cint" title="product[T](arg: Tensor[T]; axis: int): Tensor[T]">product[T](arg: Tensor[T]; axis: int): Tensor[T]</a></li>

</ul>
<ul class="simple nested-toc-section">std
  <li><a class="reference" href="#std%2CTensor%5BT%3A%20SomeFloat%5D" title="std[T: SomeFloat](arg: Tensor[T]): T">std[T: SomeFloat](arg: Tensor[T]): T</a></li>
<li><a class="reference" href="#std%2CTensor%5BT%3A%20SomeFloat%5D%2Cint" title="std[T: SomeFloat](arg: Tensor[T]; axis: int): Tensor[T]">std[T: SomeFloat](arg: Tensor[T]; axis: int): Tensor[T]</a></li>

</ul>
<ul class="simple nested-toc-section">sum
  <li><a class="reference" href="#sum%2CTensor%5BT%5D" title="sum[T](arg: Tensor[T]): T">sum[T](arg: Tensor[T]): T</a></li>
<li><a class="reference" href="#sum%2CTensor%5BT%5D%2Cint" title="sum[T](arg: Tensor[T]; axis: int): Tensor[T]">sum[T](arg: Tensor[T]; axis: int): Tensor[T]</a></li>

</ul>
<ul class="simple nested-toc-section">unwrap_period
  <li><a class="reference" href="#unwrap_period%2CTensor%5BT%3A%20SomeNumber%5D%2CT%2Cint%2CT" title="unwrap_period[T: SomeNumber](t: Tensor[T]; discont: T = -1; axis = -1;
                             period: T = default(T)): Tensor[T]">unwrap_period[T: SomeNumber](t: Tensor[T]; discont: T = -1; axis = -1;
                             period: T = default(T)): Tensor[T]</a></li>

</ul>
<ul class="simple nested-toc-section">variance
  <li><a class="reference" href="#variance%2CTensor%5BT%3A%20SomeFloat%5D" title="variance[T: SomeFloat](arg: Tensor[T]): T">variance[T: SomeFloat](arg: Tensor[T]): T</a></li>
<li><a class="reference" href="#variance%2CTensor%5BT%3A%20SomeFloat%5D%2Cint" title="variance[T: SomeFloat](arg: Tensor[T]; axis: int): Tensor[T]">variance[T: SomeFloat](arg: Tensor[T]; axis: int): Tensor[T]</a></li>

</ul>

    </ul>
  </details>
</li>

</ul>

  </div>
  <div class="nine columns" id="content">
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L1"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L1" class="link-seesrc" target="_blank" >Edit</a>

    <div id="tocRoot"></div>
    
    <p class="module-desc"></p>
    <div class="section" id="6">
  <h1><a class="toc-backref" href="#6">Imports</a></h1>
  <dl class="item">
    <a class="reference external" href="data_structure.html">data_structure</a>, <a class="reference external" href="init_cpu.html">init_cpu</a>, <a class="reference external" href="higher_order_foldreduce.html">higher_order_foldreduce</a>, <a class="reference external" href="operators_broadcasted.html">operators_broadcasted</a>, <a class="reference external" href="operators_comparison.html">operators_comparison</a>, <a class="reference external" href="higher_order_applymap.html">higher_order_applymap</a>, <a class="reference external" href="math_functions.html">math_functions</a>, <a class="reference external" href="accessors.html">accessors</a>, <a class="reference external" href="accessors_macros_syntax.html">accessors_macros_syntax</a>, <a class="reference external" href="algorithms.html">algorithms</a>, <a class="reference external" href="p_empty_tensors.html">p_empty_tensors</a>, <a class="reference external" href="complex.html">complex</a>
  </dl>
</div>
<div class="section" id="12">
  <h1><a class="toc-backref" href="#12">Procs</a></h1>
  <dl class="item">
    <div id="all-procs-all">
  <div id="all,Tensor[T]">
  <dt><pre><span class="Keyword">func</span> <a href="#all%2CTensor%5BT%5D"><span class="Identifier">all</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">bool</span></pre></dt>
  <dd>
    
    <p>Returns true if all of the items in the input tensor are true or non-zero</p>
<p>Input:</p>
<ul class="simple"><li>A tensor</li>
</ul>
<p>Returns:</p>
<ul class="simple"><li>True if at least one element is not zero</li>
</ul>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L525"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L525" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="any-procs-all">
  <div id="any,Tensor[T]">
  <dt><pre><span class="Keyword">func</span> <a href="#any%2CTensor%5BT%5D"><span class="Identifier">any</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">bool</span></pre></dt>
  <dd>
    
    <p>Returns true if any of the items in the input tensor is true or non-zero</p>
<p>Input:</p>
<ul class="simple"><li>A tensor</li>
</ul>
<p>Returns:</p>
<ul class="simple"><li>True if at least one element is not zero</li>
</ul>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L543"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L543" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="argmax-procs-all">
  <div id="argmax,Tensor[T],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#argmax%2CTensor%5BT%5D%2Cint"><span class="Identifier">argmax</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span> {.<span class="Identifier">inline</span>.}</pre></dt>
  <dd>
    
    <p>Returns the index of the maximum along an axis</p>
<p>Input:</p>
<ul class="simple"><li>A tensor</li>
<li>An axis (int)</li>
</ul>
<p>Returns:</p>
<ul class="simple"><li>A tensor of index of the maximums along this axis</li>
</ul>
<p>Example: .. code:: nim let a = [<a class="reference internal" href="#0, 4, 7">0, 4, 7</a>, <a class="reference internal" href="#1, 9, 5">1, 9, 5</a>, <a class="reference internal" href="#3, 4, 1">3, 4, 1</a>].toTensor assert argmax(a, 0) == [<a class="reference internal" href="#2, 1, 0">2, 1, 0</a>].toTensor assert argmax(a, 1) == [<a class="reference internal" href="#2">2</a>, <a class="reference internal" href="#1">1</a>, <a class="reference internal" href="#1">1</a>].toTensor</p>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L195"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L195" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="argmax_max-procs-all">
  <div id="argmax_max,Tensor[T: SomeNumber],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#argmax_max%2CTensor%5BT%3A%20SomeNumber%5D%2Cint"><span class="Identifier">argmax_max</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Keyword">tuple</span><span class="Other">[</span>
    <span class="Identifier">indices</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">maxes</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">]</span> {.<span class="Identifier">noinit</span>.}</pre></dt>
  <dd>
    
    <p>Returns (indices, maxes) along an axis</p>
<p>Input:</p>
<ul class="simple"><li>A tensor</li>
<li>An axis (int)</li>
</ul>
<p>Returns:</p>
<ul class="simple"><li>A tuple of tensors (indices, maxes) along this axis</li>
</ul>
<p>Example: .. code:: nim let a = [<a class="reference internal" href="#0, 4, 7">0, 4, 7</a>, <a class="reference internal" href="#1, 9, 5">1, 9, 5</a>, <a class="reference internal" href="#3, 4, 1">3, 4, 1</a>].toTensor assert argmax(a, 0).indices == [<a class="reference internal" href="#2, 1, 0">2, 1, 0</a>].toTensor assert argmax(a, 1).indices == [<a class="reference internal" href="#2">2</a>, <a class="reference internal" href="#1">1</a>, <a class="reference internal" href="#1">1</a>].toTensor</p>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L159"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L159" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="argmin-procs-all">
  <div id="argmin,Tensor[T],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#argmin%2CTensor%5BT%5D%2Cint"><span class="Identifier">argmin</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span> {.<span class="Identifier">inline</span>.}</pre></dt>
  <dd>
    
    <p>Returns the index of the minimum along an axis</p>
<p>Input:</p>
<ul class="simple"><li>A tensor</li>
<li>An axis (int)</li>
</ul>
<p>Returns:</p>
<ul class="simple"><li>A tensor of index of the minimums along this axis</li>
</ul>
<p>Example: .. code:: nim let a = [<a class="reference internal" href="#0, 4, 7">0, 4, 7</a>, <a class="reference internal" href="#1, 9, 5">1, 9, 5</a>, <a class="reference internal" href="#3, 4, 1">3, 4, 1</a>].toTensor assert argmin(a, 0) == [<a class="reference internal" href="#2, 1, 0">2, 1, 0</a>].toTensor assert argmin(a, 1) == [<a class="reference internal" href="#2">2</a>, <a class="reference internal" href="#1">1</a>, <a class="reference internal" href="#1">1</a>].toTensor</p>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L252"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L252" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="argmin_min-procs-all">
  <div id="argmin_min,Tensor[T: SomeNumber],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#argmin_min%2CTensor%5BT%3A%20SomeNumber%5D%2Cint"><span class="Identifier">argmin_min</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Keyword">tuple</span><span class="Other">[</span>
    <span class="Identifier">indices</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">mins</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">]</span> {.<span class="Identifier">noinit</span>.}</pre></dt>
  <dd>
    
    <p>Returns (indices, mins) along an axis</p>
<p>Input:</p>
<ul class="simple"><li>A tensor</li>
<li>An axis (int)</li>
</ul>
<p>Returns:</p>
<ul class="simple"><li>A tuple of tensors (indices, min) along this axis</li>
</ul>
<p>Example: .. code:: nim let a = [<a class="reference internal" href="#0, 4, 7">0, 4, 7</a>, <a class="reference internal" href="#1, 9, 5">1, 9, 5</a>, <a class="reference internal" href="#3, 4, 1">3, 4, 1</a>].toTensor assert argmin(a, 0).indices == [<a class="reference internal" href="#0, 0, 2">0, 0, 2</a>].toTensor assert argmin(a, 1).indices == [<a class="reference internal" href="#0">0</a>, <a class="reference internal" href="#0">0</a>, <a class="reference internal" href="#2">2</a>].toTensor</p>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L216"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L216" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="cumprod-procs-all">
  <div id="cumprod,Tensor[T],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#cumprod%2CTensor%5BT%5D%2Cint"><span class="Identifier">cumprod</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span> <span class="Other">=</span> <span class="DecNumber">0</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span></pre></dt>
  <dd>
    
    Calculates the cumulative sum of a rank-n Tensor. Inputs:<ul class="simple"><li>t: a rank-n tensor to cumulatively sum</li>
<li>axis: int</li>
</ul>
<p>Returns:</p>
<ul class="simple"><li>A tensor cumulatively summed at axis, that is, add each value to</li>
</ul>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L329"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L329" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="cumsum-procs-all">
  <div id="cumsum,Tensor[T],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#cumsum%2CTensor%5BT%5D%2Cint"><span class="Identifier">cumsum</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span> <span class="Other">=</span> <span class="DecNumber">0</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span></pre></dt>
  <dd>
    
    Calculates the cumulative sum of a rank-n Tensor. Inputs:<ul class="simple"><li>t: a rank-n tensor to cumulatively sum</li>
<li>axis: int</li>
</ul>
<p>Returns:</p>
<ul class="simple"><li>A tensor cumulatively summed at axis, that is, add each value to</li>
</ul>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L313"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L313" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="diff_discrete-procs-all">
  <div id="diff_discrete,Tensor[T],int,int">
  <dt><pre><span class="Keyword">proc</span> <a href="#diff_discrete%2CTensor%5BT%5D%2Cint%2Cint"><span class="Identifier">diff_discrete</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">n</span> <span class="Other">=</span> <span class="DecNumber">1</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span> <span class="Other">=</span> <span class="DecNumber">-1</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span></pre></dt>
  <dd>
    
    <p>Calculate the n-th discrete difference along the given axis.</p>
<p>The first difference is given by <tt class="docutils literal"><span class="pre"><span class="Keyword">out</span><span class="Punctuation">[</span><span class="Identifier">i</span><span class="Punctuation">]</span> <span class="Operator">=</span> <span class="Identifier">a</span><span class="Punctuation">[</span><span class="Identifier">i</span><span class="Operator">+</span><span class="DecNumber">1</span><span class="Punctuation">]</span> <span class="Operator">-</span> <span class="Identifier">a</span><span class="Punctuation">[</span><span class="Identifier">i</span><span class="Punctuation">]</span></span></tt> along the given axis. Higher differences are calculated by using diff recursively.</p>
<p>Input:</p>
<ul class="simple"><li>A tensor</li>
<li>n: The number of times values are differenced. If zero, the input is returned as-is.</li>
<li>axis: The axis along which the difference is taken, default is the last axis.</li>
</ul>
<p>Returns:</p>
<ul class="simple"><li>A tensor with the n-th discrete difference along the given axis. It's size along that axis will be reduced by one.</li>
<li>The code in this function is heavily based upon and equivalent</li>
</ul>
<p>to numpy's <tt class="docutils literal"><span class="pre"><span class="Identifier">diff</span><span class="Punctuation">(</span><span class="Punctuation">)</span></span></tt> function.</p>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L345"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L345" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="iqr-procs-all">
  <div id="iqr,Tensor[T]">
  <dt><pre><span class="Keyword">proc</span> <a href="#iqr%2CTensor%5BT%5D"><span class="Identifier">iqr</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">float</span></pre></dt>
  <dd>
    
    <p>Returns the interquartile range of the 1D tensor <tt class="docutils literal"><span class="pre"><span class="Identifier">t</span></span></tt>.</p>
<p>The interquartile range (IQR) is the distance between the 25th and 75th percentile</p>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L304"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L304" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="max-procs-all">
  <div id="max,Tensor[T]">
  <dt><pre><span class="Keyword">proc</span> <a href="#max%2CTensor%5BT%5D"><span class="Identifier">max</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span></pre></dt>
  <dd>
    
    Compute the max of all elements
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L103"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L103" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="max,Tensor[T],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#max%2CTensor%5BT%5D%2Cint"><span class="Identifier">max</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> {.<span class="Identifier">noinit</span>.}</pre></dt>
  <dd>
    
    Compute the max along an axis
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L108"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L108" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="mean-procs-all">
  <div id="mean,Tensor[T: Complex[system.float32] or Complex[system.float64]]">
  <dt><pre><span class="Keyword">proc</span> <a href="#mean%2CTensor%5BT%3A%20Complex%5Bsystem.float32%5D%20or%20Complex%5Bsystem.float64%5D%5D"><span class="Identifier">mean</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">Complex</span><span class="Other">[</span><span class="Identifier">float32</span><span class="Other">]</span> <span class="Keyword">or</span> <span class="Identifier">Complex</span><span class="Other">[</span><span class="Identifier">float64</span><span class="Other">]</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span> {.<span class="Identifier">inline</span>.}</pre></dt>
  <dd>
    
    Compute the mean of all elements
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L75"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L75" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="mean,Tensor[T: Complex[system.float32] or Complex[system.float64]],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#mean%2CTensor%5BT%3A%20Complex%5Bsystem.float32%5D%20or%20Complex%5Bsystem.float64%5D%5D%2Cint"><span class="Identifier">mean</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">Complex</span><span class="Other">[</span><span class="Identifier">float32</span><span class="Other">]</span> <span class="Keyword">or</span> <span class="Identifier">Complex</span><span class="Other">[</span><span class="Identifier">float64</span><span class="Other">]</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span>
    <span class="Identifier">T</span><span class="Other">]</span> {.<span class="Identifier">noinit</span><span class="Other">,</span> <span class="Identifier">inline</span>.}</pre></dt>
  <dd>
    
    Compute the mean along an axis
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L85"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L85" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="mean,Tensor[T: SomeFloat]">
  <dt><pre><span class="Keyword">proc</span> <a href="#mean%2CTensor%5BT%3A%20SomeFloat%5D"><span class="Identifier">mean</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeFloat</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span> {.<span class="Identifier">inline</span>.}</pre></dt>
  <dd>
    
    Compute the mean of all elements
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L71"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L71" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="mean,Tensor[T: SomeFloat],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#mean%2CTensor%5BT%3A%20SomeFloat%5D%2Cint"><span class="Identifier">mean</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeFloat</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> {.<span class="Identifier">noinit</span><span class="Other">,</span> <span class="Identifier">inline</span>.}</pre></dt>
  <dd>
    
    Compute the mean along an axis
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L80"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L80" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="mean,Tensor[T: SomeInteger]">
  <dt><pre><span class="Keyword">proc</span> <a href="#mean%2CTensor%5BT%3A%20SomeInteger%5D"><span class="Identifier">mean</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeInteger</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span> {.<span class="Identifier">inline</span>.}</pre></dt>
  <dd>
    
    <p>Compute the mean of all elements</p>
<p>Warning âš : Since input is integer, output will also be integer (using integer division)</p>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L58"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L58" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="mean,Tensor[T: SomeInteger],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#mean%2CTensor%5BT%3A%20SomeInteger%5D%2Cint"><span class="Identifier">mean</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeInteger</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> {.<span class="Identifier">noinit</span><span class="Other">,</span> <span class="Identifier">inline</span>.}</pre></dt>
  <dd>
    
    <p>Compute the mean along an axis</p>
<p>Warning âš : Since input is integer, output will also be integer (using integer division)</p>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L64"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L64" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="median-procs-all">
  <div id="median,Tensor[T]">
  <dt><pre><span class="Keyword">proc</span> <a href="#median%2CTensor%5BT%5D"><span class="Identifier">median</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">isSorted</span> <span class="Other">=</span> <span class="Identifier">false</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">float</span> {.<span class="Identifier">inline</span>.}</pre></dt>
  <dd>
    
    Compute the median of all elements (same as <tt class="docutils literal"><span class="pre"><span class="Identifier">arg</span><span class="Operator">.</span><span class="Identifier">percentile</span><span class="Punctuation">(</span><span class="DecNumber">50</span><span class="Punctuation">)</span></span></tt>)
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L300"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L300" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="min-procs-all">
  <div id="min,Tensor[T]">
  <dt><pre><span class="Keyword">proc</span> <a href="#min%2CTensor%5BT%5D"><span class="Identifier">min</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span></pre></dt>
  <dd>
    
    Compute the min of all elements
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L91"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L91" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="min,Tensor[T],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#min%2CTensor%5BT%5D%2Cint"><span class="Identifier">min</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> {.<span class="Identifier">noinit</span>.}</pre></dt>
  <dd>
    
    Compute the min along an axis
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L96"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L96" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="nonzero-procs-all">
  <div id="nonzero,Tensor[T]">
  <dt><pre><span class="Keyword">proc</span> <a href="#nonzero%2CTensor%5BT%5D"><span class="Identifier">nonzero</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span></pre></dt>
  <dd>
    
    <p>Returns the indices, which are non zero as a <tt class="docutils literal"><span class="pre"><span class="Identifier">Tensor</span><span class="Punctuation">[</span><span class="Identifier">int</span><span class="Punctuation">]</span></span></tt>.</p>
<p>The resulting tensor is 2 dimensional and has one element for each dimension in <tt class="docutils literal"><span class="pre">t</span></tt>. Each of those elements contains the indicies along the corresponding axis (element 0 == axis 0), which are non zero.</p>
<p>Input:</p>
<ul class="simple"><li>A tensor</li>
</ul>
<p>Returns:</p>
<ul class="simple"><li>A 2D tensor with N elements, where N is the rank of <tt class="docutils literal"><span class="pre">t</span></tt></li>
</ul>
<p>Example: .. code:: nim let a = [<a class="reference internal" href="#3, 0, 0">3, 0, 0</a>, <a class="reference internal" href="#0, 4, 0">0, 4, 0</a>, <a class="reference internal" href="#5, 6, 0">5, 6, 0</a>].toTensor() assert a.nonzero == [<a class="reference internal" href="#0, 1, 2, 2">0, 1, 2, 2</a>, <a class="reference internal" href="#0, 1, 0, 1">0, 1, 0, 1</a>].toTensor #                    ^-- indices.. ^ ..for  axis 0 #                                  âˆŸ-- indices for axis 1 # axis 0: <a class="reference internal" href="#0, 1, 2, 2">0, 1, 2, 2</a> refers to: # - 0 -&gt; 3 in row 0 # - 1 -&gt; 4 in row 1 # - 2 -&gt; 5 in row 2 # - 2 -&gt; 6 in row 2 # axis 1: <a class="reference internal" href="#0, 1, 0, 1">0, 1, 0, 1</a> refers to: # - 0 -&gt; 3 in col 0 # - 1 -&gt; 4 in col 1 # - 0 -&gt; 5 in col 0 # - 1 -&gt; 6 in col 1</p>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L463"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L463" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="percentile-procs-all">
  <div id="percentile,Tensor[T],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#percentile%2CTensor%5BT%5D%2Cint"><span class="Identifier">percentile</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">p</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">;</span> <span class="Identifier">isSorted</span> <span class="Other">=</span> <span class="Identifier">false</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">float</span></pre></dt>
  <dd>
    
    <p>statistical percentile value of <tt class="docutils literal"><span class="pre">t</span></tt>, where <tt class="docutils literal"><span class="pre">p</span></tt> percentile value is between <tt class="docutils literal"><span class="pre">0</span></tt> and <tt class="docutils literal"><span class="pre">100</span></tt> inclusively, and <tt class="docutils literal"><span class="pre">p=0</span></tt> gives the min value, <tt class="docutils literal"><span class="pre">p=100</span></tt> gives the max value and <tt class="docutils literal"><span class="pre">p=50</span></tt> gives the median value.</p>
<p>If the input percentile does not match an element of <tt class="docutils literal"><span class="pre"><span class="Identifier">t</span></span></tt> exactly the result is the linear interpolation between the neighbors.</p>
<p><tt class="docutils literal"><span class="pre">t</span></tt> does not need to be sorted, because <tt class="docutils literal"><span class="pre">percentile</span></tt> sorts a copy of the data itself. If <tt class="docutils literal"><span class="pre">isSorted</span></tt> is <tt class="docutils literal"><span class="pre">true</span></tt> however, no sorting is done.</p>

    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L273"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L273" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="product-procs-all">
  <div id="product,Tensor[T]">
  <dt><pre><span class="Keyword">proc</span> <a href="#product%2CTensor%5BT%5D"><span class="Identifier">product</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span></pre></dt>
  <dd>
    
    Compute the product of all elements
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L47"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L47" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="product,Tensor[T],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#product%2CTensor%5BT%5D%2Cint"><span class="Identifier">product</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> {.<span class="Identifier">noinit</span>.}</pre></dt>
  <dd>
    
    Compute the product along an axis
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L52"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L52" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="std-procs-all">
  <div id="std,Tensor[T: SomeFloat]">
  <dt><pre><span class="Keyword">proc</span> <a href="#std%2CTensor%5BT%3A%20SomeFloat%5D"><span class="Identifier">std</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeFloat</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span> {.<span class="Identifier">inline</span>.}</pre></dt>
  <dd>
    
    Compute the standard deviation of all elements The normalization is by the (n-1), like in the formal definition
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L148"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L148" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="std,Tensor[T: SomeFloat],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#std%2CTensor%5BT%3A%20SomeFloat%5D%2Cint"><span class="Identifier">std</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeFloat</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> {.<span class="Identifier">noinit</span><span class="Other">,</span> <span class="Identifier">inline</span>.}</pre></dt>
  <dd>
    
    Compute the standard deviation of all elements The normalization is by the (n-1), like in the formal definition
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L153"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L153" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="sum-procs-all">
  <div id="sum,Tensor[T]">
  <dt><pre><span class="Keyword">proc</span> <a href="#sum%2CTensor%5BT%5D"><span class="Identifier">sum</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span></pre></dt>
  <dd>
    
    Compute the sum of all elements
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L36"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L36" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="sum,Tensor[T],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#sum%2CTensor%5BT%5D%2Cint"><span class="Identifier">sum</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> {.<span class="Identifier">noinit</span>.}</pre></dt>
  <dd>
    
    Compute the sum of all elements along an axis
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L41"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L41" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="unwrap_period-procs-all">
  <div id="unwrap_period,Tensor[T: SomeNumber],T,int,T">
  <dt><pre><span class="Keyword">proc</span> <a href="#unwrap_period%2CTensor%5BT%3A%20SomeNumber%5D%2CT%2Cint%2CT"><span class="Identifier">unwrap_period</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">discont</span><span class="Other">:</span> <span class="Identifier">T</span> <span class="Other">=</span> <span class="DecNumber">-1</span><span class="Other">;</span> <span class="Identifier">axis</span> <span class="Other">=</span> <span class="DecNumber">-1</span><span class="Other">;</span>
                                  <span class="Identifier">period</span><span class="Other">:</span> <span class="Identifier">T</span> <span class="Other">=</span> <span class="Identifier">default</span><span class="Other">(</span><span class="Identifier">T</span><span class="Other">)</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> {.<span class="Identifier">noinit</span>.}</pre></dt>
  <dd>
    
    
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L386"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L386" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>
<div id="variance-procs-all">
  <div id="variance,Tensor[T: SomeFloat]">
  <dt><pre><span class="Keyword">proc</span> <a href="#variance%2CTensor%5BT%3A%20SomeFloat%5D"><span class="Identifier">variance</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeFloat</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span></pre></dt>
  <dd>
    
    Compute the sample variance of all elements The normalization is by (n-1), also known as Bessel's correction, which partially correct the bias of estimating a population variance from a sample of this population.
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L115"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L115" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>
<div id="variance,Tensor[T: SomeFloat],int">
  <dt><pre><span class="Keyword">proc</span> <a href="#variance%2CTensor%5BT%3A%20SomeFloat%5D%2Cint"><span class="Identifier">variance</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeFloat</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">arg</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <a href="datatypes.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> {.<span class="Identifier">noinit</span>.}</pre></dt>
  <dd>
    
    Compute the variance of all elements The normalization is by the (n-1), like in the formal definition
    &nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/master/src/arraymancer/tensor/aggregate.nim#L131"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/arraymancer/tensor/aggregate.nim#L131" class="link-seesrc" target="_blank" >Edit</a>

  </dd>
</div>

</div>

  </dl>
</div>

  </div>
</div>

    <div class="row">
      <div class="twelve-columns footer">
        <span class="nim-sprite"></span>
        <br/>
        <small style="color: var(--hint);">Made with Nim. Generated: 2024-05-12 14:00:14 UTC</small>
      </div>
    </div>
  </div>
</div>

<header>
  <a class="pagetitle" href="index.html">Arraymancer</a>
  <span>
    <a href="#">Technical reference</a>
    <ul class="monospace" style="padding-bottom: 15px; padding-top: 10px;">
      <span>
      <li>
        <a href="#">Core tensor API</a>
        <ul class="monospace">
          <li><a href="accessors.html">accessors</a></li>
<li><a href="accessors_macros_read.html">accessors_macros_read</a></li>
<li><a href="accessors_macros_syntax.html">accessors_macros_syntax</a></li>
<li><a href="accessors_macros_write.html">accessors_macros_write</a></li>
<li><a href="aggregate.html">aggregate</a></li>
<li><a href="algorithms.html">algorithms</a></li>
<li><a href="blas_l3_gemm.html">blas_l3_gemm</a></li>
<li><a href="complex.html">complex</a></li>
<li><a href="cublas.html">cublas</a></li>
<li><a href="cuda.html">cuda</a></li>
<li><a href="cuda_global_state.html">cuda_global_state</a></li>
<li><a href="data_structure.html">data_structure</a></li>
<li><a href="display.html">display</a></li>
<li><a href="display_cuda.html">display_cuda</a></li>
<li><a href="einsum.html">einsum</a></li>
<li><a href="exporting.html">exporting</a></li>
<li><a href="filling_data.html">filling_data</a></li>
<li><a href="higher_order_applymap.html">higher_order_applymap</a></li>
<li><a href="higher_order_foldreduce.html">higher_order_foldreduce</a></li>
<li><a href="incl_accessors_cuda.html">incl_accessors_cuda</a></li>
<li><a href="incl_higher_order_cuda.html">incl_higher_order_cuda</a></li>
<li><a href="incl_kernels_cuda.html">incl_kernels_cuda</a></li>
<li><a href="init_copy_cpu.html">init_copy_cpu</a></li>
<li><a href="init_copy_cuda.html">init_copy_cuda</a></li>
<li><a href="init_cpu.html">init_cpu</a></li>
<li><a href="init_cuda.html">init_cuda</a></li>
<li><a href="init_opencl.html">init_opencl</a></li>
<li><a href="lapack.html">lapack</a></li>
<li><a href="math_functions.html">math_functions</a></li>
<li><a href="memory_optimization_hints.html">memory_optimization_hints</a></li>
<li><a href="naive_l2_gemv.html">naive_l2_gemv</a></li>
<li><a href="opencl_backend.html">opencl_backend</a></li>
<li><a href="opencl_global_state.html">opencl_global_state</a></li>
<li><a href="openmp.html">openmp</a></li>
<li><a href="operators_blas_l1.html">operators_blas_l1</a></li>
<li><a href="operators_blas_l1_cuda.html">operators_blas_l1_cuda</a></li>
<li><a href="operators_blas_l1_opencl.html">operators_blas_l1_opencl</a></li>
<li><a href="operators_blas_l2l3.html">operators_blas_l2l3</a></li>
<li><a href="operators_blas_l2l3_cuda.html">operators_blas_l2l3_cuda</a></li>
<li><a href="operators_blas_l2l3_opencl.html">operators_blas_l2l3_opencl</a></li>
<li><a href="operators_broadcasted.html">operators_broadcasted</a></li>
<li><a href="operators_broadcasted_cuda.html">operators_broadcasted_cuda</a></li>
<li><a href="operators_broadcasted_opencl.html">operators_broadcasted_opencl</a></li>
<li><a href="operators_comparison.html">operators_comparison</a></li>
<li><a href="operators_logical.html">operators_logical</a></li>
<li><a href="optim_ops_fusion.html">optim_ops_fusion</a></li>
<li><a href="p_accessors.html">p_accessors</a></li>
<li><a href="p_accessors_macros_desugar.html">p_accessors_macros_desugar</a></li>
<li><a href="p_accessors_macros_read.html">p_accessors_macros_read</a></li>
<li><a href="p_accessors_macros_write.html">p_accessors_macros_write</a></li>
<li><a href="p_checks.html">p_checks</a></li>
<li><a href="p_complex.html">p_complex</a></li>
<li><a href="p_display.html">p_display</a></li>
<li><a href="p_empty_tensors.html">p_empty_tensors</a></li>
<li><a href="p_init_cuda.html">p_init_cuda</a></li>
<li><a href="p_init_opencl.html">p_init_opencl</a></li>
<li><a href="p_kernels_interface_cuda.html">p_kernels_interface_cuda</a></li>
<li><a href="p_kernels_interface_opencl.html">p_kernels_interface_opencl</a></li>
<li><a href="p_operator_blas_l2l3.html">p_operator_blas_l2l3</a></li>
<li><a href="p_shapeshifting.html">p_shapeshifting</a></li>
<li><a href="selectors.html">selectors</a></li>
<li><a href="shapeshifting.html">shapeshifting</a></li>
<li><a href="shapeshifting_cuda.html">shapeshifting_cuda</a></li>
<li><a href="shapeshifting_opencl.html">shapeshifting_opencl</a></li>
<li><a href="syntactic_sugar.html">syntactic_sugar</a></li>
<li><a href="tensor_cuda.html">tensor_cuda</a></li>
<li><a href="tensor_opencl.html">tensor_opencl</a></li>
<li><a href="ufunc.html">ufunc</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Neural network API</a>
        <ul class="monospace">
          <li><a href="conv2D.html">Layers: Convolution 2D</a></li>
<li><a href="cross_entropy_losses.html">Loss: Cross-Entropy losses</a></li>
<li><a href="embedding.html">Layers: Embedding</a></li>
<li><a href="flatten.html">flatten</a></li>
<li><a href="gcn.html">gcn</a></li>
<li><a href="gru.html">Layers: GRU (Gated Linear Unit)</a></li>
<li><a href="init.html">Layers: Initializations</a></li>
<li><a href="linear.html">Layers: Linear/Dense</a></li>
<li><a href="maxpool2D.html">Layers: Maxpool 2D</a></li>
<li><a href="mean_square_error_loss.html">Loss: Mean Square Error</a></li>
<li><a href="nn_dsl.html">Neural network: Declaration</a></li>
<li><a href="optimizers.html">Optimizers</a></li>
<li><a href="relu.html">Activation: Relu (Rectified linear Unit)</a></li>
<li><a href="sigmoid.html">Activation: Sigmoid</a></li>
<li><a href="softmax.html">Softmax</a></li>
<li><a href="tanh.html">Activation: Tanh</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Linear algebra, stats, ML</a>
        <ul class="monospace">
          <li><a href="accuracy_score.html">Accuracy score</a></li>
<li><a href="algebra.html">algebra</a></li>
<li><a href="auxiliary_blas.html">auxiliary_blas</a></li>
<li><a href="auxiliary_lapack.html">auxiliary_lapack</a></li>
<li><a href="common_error_functions.html">Common errors, MAE and MSE (L1, L2 loss)</a></li>
<li><a href="dbscan.html">dbscan</a></li>
<li><a href="decomposition.html">Eigenvalue decomposition</a></li>
<li><a href="decomposition_lapack.html">decomposition_lapack</a></li>
<li><a href="decomposition_rand.html">Randomized Truncated SVD</a></li>
<li><a href="distributions.html">distributions</a></li>
<li><a href="init_colmajor.html">init_colmajor</a></li>
<li><a href="kde.html">kde</a></li>
<li><a href="kmeans.html">K-Means</a></li>
<li><a href="least_squares.html">Least squares solver</a></li>
<li><a href="least_squares_lapack.html">least_squares_lapack</a></li>
<li><a href="linear_systems.html">Linear systems solver</a></li>
<li><a href="overload.html">overload</a></li>
<li><a href="pca.html">Principal Component Analysis (PCA)</a></li>
<li><a href="solve_lapack.html">solve_lapack</a></li>
<li><a href="special_matrices.html">Special linear algebra matrices</a></li>
<li><a href="stats.html">Statistics</a></li>
<li><a href="triangular.html">triangular</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">IO & Datasets</a>
        <ul class="monospace">
          <li><a href="imdb.html">IMDB</a></li>
<li><a href="io_csv.html">CSV reading and writing</a></li>
<li><a href="io_hdf5.html">HDF5 files reading and writing</a></li>
<li><a href="io_image.html">Images reading and writing</a></li>
<li><a href="io_npy.html">Numpy files reading and writing</a></li>
<li><a href="io_stream_readers.html">io_stream_readers</a></li>
<li><a href="mnist.html">MNIST</a></li>
<li><a href="util.html">util</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Autograd</a>
        <ul class="monospace">
          <li><a href="autograd_common.html">Data structure</a></li>
<li><a href="gates_basic.html">Basic operations</a></li>
<li><a href="gates_blas.html">Linear algebra operations</a></li>
<li><a href="gates_hadamard.html">Hadamard product (elementwise matrix multiply)</a></li>
<li><a href="gates_reduce.html">Reduction operations</a></li>
<li><a href="gates_shapeshifting_concat_split.html">Concatenation, stacking, splitting, chunking operations</a></li>
<li><a href="gates_shapeshifting_views.html">Linear algebra operations</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Neuralnet primitives</a>
        <ul class="monospace">
          <li><a href="conv.html">conv</a></li>
<li><a href="cudnn.html">cudnn</a></li>
<li><a href="cudnn_conv_interface.html">cudnn_conv_interface</a></li>
<li><a href="nnp_activation.html">Activations</a></li>
<li><a href="nnp_conv2d_cudnn.html">Convolution 2D - CuDNN</a></li>
<li><a href="nnp_convolution.html">Convolution 2D</a></li>
<li><a href="nnp_embedding.html">Embeddings</a></li>
<li><a href="nnp_gru.html">Gated Recurrent Unit (GRU)</a></li>
<li><a href="nnp_linear.html">Linear / Dense layer</a></li>
<li><a href="nnp_maxpooling.html">Maxpooling</a></li>
<li><a href="nnp_numerical_gradient.html">Numerical gradient</a></li>
<li><a href="nnp_sigmoid_cross_entropy.html">Sigmoid Cross-Entropy loss</a></li>
<li><a href="nnp_softmax.html">Softmax</a></li>
<li><a href="nnp_softmax_cross_entropy.html">Softmax Cross-Entropy loss</a></li>
<li><a href="nnpack.html">nnpack</a></li>
<li><a href="nnpack_interface.html">nnpack_interface</a></li>
<li><a href="p_activation.html">p_activation</a></li>
<li><a href="p_logsumexp.html">p_logsumexp</a></li>
<li><a href="p_nnp_checks.html">p_nnp_checks</a></li>
<li><a href="p_nnp_types.html">p_nnp_types</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Other docs</a>
        <ul class="monospace">
          <li><a href="align_unroller.html">align_unroller</a></li>
<li><a href="ast_utils.html">ast_utils</a></li>
<li><a href="compiler_optim_hints.html">compiler_optim_hints</a></li>
<li><a href="cpuinfo_x86.html">cpuinfo_x86</a></li>
<li><a href="datatypes.html">datatypes</a></li>
<li><a href="deprecate.html">deprecate</a></li>
<li><a href="dynamic_stack_arrays.html">dynamic_stack_arrays</a></li>
<li><a href="foreach.html">foreach</a></li>
<li><a href="foreach_common.html">foreach_common</a></li>
<li><a href="foreach_staged.html">foreach_staged</a></li>
<li><a href="functional.html">functional</a></li>
<li><a href="gemm.html">gemm</a></li>
<li><a href="gemm_packing.html">gemm_packing</a></li>
<li><a href="gemm_prepacked.html">gemm_prepacked</a></li>
<li><a href="gemm_tiling.html">gemm_tiling</a></li>
<li><a href="gemm_ukernel_avx.html">gemm_ukernel_avx</a></li>
<li><a href="gemm_ukernel_avx2.html">gemm_ukernel_avx2</a></li>
<li><a href="gemm_ukernel_avx512.html">gemm_ukernel_avx512</a></li>
<li><a href="gemm_ukernel_avx_fma.html">gemm_ukernel_avx_fma</a></li>
<li><a href="gemm_ukernel_dispatch.html">gemm_ukernel_dispatch</a></li>
<li><a href="gemm_ukernel_generator.html">gemm_ukernel_generator</a></li>
<li><a href="gemm_ukernel_generic.html">gemm_ukernel_generic</a></li>
<li><a href="gemm_ukernel_sse.html">gemm_ukernel_sse</a></li>
<li><a href="gemm_ukernel_sse2.html">gemm_ukernel_sse2</a></li>
<li><a href="gemm_ukernel_sse4_1.html">gemm_ukernel_sse4_1</a></li>
<li><a href="gemm_utils.html">gemm_utils</a></li>
<li><a href="global_config.html">global_config</a></li>
<li><a href="initialization.html">initialization</a></li>
<li><a href="math_ops_fusion.html">math_ops_fusion</a></li>
<li><a href="memory.html">memory</a></li>
<li><a href="nested_containers.html">nested_containers</a></li>
<li><a href="openmp.html">openmp</a></li>
<li><a href="sequninit.html">sequninit</a></li>
<li><a href="simd.html">simd</a></li>
<li><a href="tokenizers.html">tokenizers</a></li>
        </ul>
      </li>
      </span>
    </ul>
  </span>
  <span>
    <a href="#">Tutorial</a>
    <ul class="monospace">
      <li><a href="tuto.first_steps.html">First steps</a></li>
      <li><a href="tuto.slicing.html">Taking a slice of a tensor</a></li>
      <li><a href="tuto.linear_algebra.html">Matrix & vectors operations</a></li>
      <li><a href="tuto.broadcasting.html">Broadcasted operations</a></li>
      <li><a href="tuto.shapeshifting.html">Transposing, Reshaping, Permuting, Concatenating</a></li>
      <li><a href="tuto.map_reduce.html">Map & Reduce</a></li>
      <li><a href="tuto.iterators.html">Basic iterators</a></li>
    </ul>
  </span>
  <span>
    <a href="#">Spellbook (How-To&apos;s)</a>
    <ul class="monospace">
      <li><a href="howto.type_conversion.html">How to convert a Tensor type?</a></li>
      <li><a href="howto.ufunc.html">How to create a new universal function?</a></li>
      <li><a href="howto.perceptron.html">How to create a multilayer perceptron?</a></li>
    </ul>
  </span>
  <span>
    <a href="#">Under the hood</a>
    <ul class="monospace">
      <li><a href="uth.speed.html">How Arraymancer achieves its speed?</a></li>
      <li><a href="uth.copy_semantics.html">Why does `=` share data by default aka reference semantics?</a></li>
      <li><a href="uth.opencl_cuda_nim.html">Working with OpenCL and Cuda in Nim</a></li>
    </ul>
  </span>
</header>
</body>
</html>
