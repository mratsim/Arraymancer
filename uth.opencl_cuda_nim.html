<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!--  This file is generated by Nim. -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Favicon -->
<link rel="shortcut icon" href="data:image/x-icon;base64,AAABAAEAEBAAAAEAIABoBAAAFgAAACgAAAAQAAAAIAAAAAEAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AAAAAAUAAAAF////AP///wD///8A////AP///wD///8A////AP///wD///8A////AAAAAAIAAABbAAAAlQAAAKIAAACbAAAAmwAAAKIAAACVAAAAWwAAAAL///8A////AP///wD///8A////AAAAABQAAADAAAAAYwAAAA3///8A////AP///wD///8AAAAADQAAAGMAAADAAAAAFP///wD///8A////AP///wAAAACdAAAAOv///wD///8A////AP///wD///8A////AP///wD///8AAAAAOgAAAJ3///8A////AP///wAAAAAnAAAAcP///wAAAAAoAAAASv///wD///8A////AP///wAAAABKAAAAKP///wAAAABwAAAAJ////wD///8AAAAAgQAAABwAAACIAAAAkAAAAJMAAACtAAAAFQAAABUAAACtAAAAkwAAAJAAAACIAAAAHAAAAIH///8A////AAAAAKQAAACrAAAAaP///wD///8AAAAARQAAANIAAADSAAAARf///wD///8AAAAAaAAAAKsAAACk////AAAAADMAAACcAAAAnQAAABj///8A////AP///wAAAAAYAAAAGP///wD///8A////AAAAABgAAACdAAAAnAAAADMAAAB1AAAAwwAAAP8AAADpAAAAsQAAAE4AAAAb////AP///wAAAAAbAAAATgAAALEAAADpAAAA/wAAAMMAAAB1AAAAtwAAAOkAAAD/AAAA/wAAAP8AAADvAAAA3gAAAN4AAADeAAAA3gAAAO8AAAD/AAAA/wAAAP8AAADpAAAAtwAAAGUAAAA/AAAA3wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAADfAAAAPwAAAGX///8A////AAAAAEgAAADtAAAAvwAAAL0AAADGAAAA7wAAAO8AAADGAAAAvQAAAL8AAADtAAAASP///wD///8A////AP///wD///8AAAAAO////wD///8A////AAAAAIcAAACH////AP///wD///8AAAAAO////wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A//8AAP//AAD4HwAA7/cAAN/7AAD//wAAoYUAAJ55AACf+QAAh+EAAAAAAADAAwAA4AcAAP5/AAD//wAA//8AAA=="/>
<link rel="icon" type="image/png" sizes="32x32" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABmJLR0QA/wD/AP+gvaeTAAAACXBIWXMAAA3XAAAN1wFCKJt4AAAAB3RJTUUH4QQQEwksSS9ZWwAAAk1JREFUWMPtll2ITVEUx39nn/O7Y5qR8f05wtCUUr6ZIS++8pEnkZInPImneaCQ5METNdOkeFBKUhMPRIkHKfEuUZSUlGlKPN2TrgfncpvmnntnmlEyq1Z7t89/rf9a6+y99oZxGZf/XeIq61EdtgKXgdXA0xrYAvBjOIF1AI9zvjcC74BSpndrJPkBWDScTF8Aa4E3wDlgHbASaANmVqlcCnwHvgDvgVfAJ+AikAAvgfVZwLnSVZHZaOuKoQi3ZOMi4NkYkpe1p4J7A8BpYAD49hfIy/oqG0+hLomiKP2L5L+1ubn5115S+3OAn4EnwBlgMzCjyt6ZAnQCJ4A7wOs88iRJHvw50HoujuPBoCKwHWiosy8MdfZnAdcHk8dxXFJ3VQbQlCTJvRBCGdRbD4M6uc5glpY3eAihpN5S5w12diSEcCCEcKUO4ljdr15T76ur1FDDLIQQ3qv71EdDOe3Kxj3leRXyk+pxdWnFWod6Wt2bY3de3aSuUHcPBVimHs7mK9WrmeOF6lR1o9qnzskh2ar2qm1qizpfXaPeVGdlmGN5pb09qMxz1Xb1kLqgzn1RyH7JUXW52lr5e/Kqi9qpto7V1atuUzfnARrV7jEib1T76gG2qxdGmXyiekkt1GswPTtek0aBfJp6YySGBfWg2tPQ0FAYgf1stUfdmdcjarbYJEniKIq6gY/Aw+zWHAC+p2labGpqiorFYgGYCEzN7oQdQClN07O1/EfDyGgC0ALMBdYAi4FyK+4H3gLPsxfR1zRNi+NP7nH5J+QntnXe5B5mpfQAAAAASUVORK5CYII=">

<!-- Google fonts -->
<link href='https://fonts.googleapis.com/css?family=Lato:400,600,900' rel='stylesheet' type='text/css'/>
<link href='https://fonts.googleapis.com/css?family=Source+Code+Pro:400,500,600' rel='stylesheet' type='text/css'/>

<!-- CSS -->
<title>Working with OpenCL and Cuda in Nim</title>
<link rel="stylesheet" type="text/css" href="nimdoc.out.css">

<script type="text/javascript" src="dochack.js"></script>

<script type="text/javascript">
function main() {
  var pragmaDots = document.getElementsByClassName("pragmadots");
  for (var i = 0; i < pragmaDots.length; i++) {
    pragmaDots[i].onclick = function(event) {
      // Hide tease
      event.target.parentNode.style.display = "none";
      // Show actual
      event.target.parentNode.nextElementSibling.style.display = "inline";
    }
  }

  const toggleSwitch = document.querySelector('.theme-switch input[type="checkbox"]');
  function switchTheme(e) {
      if (e.target.checked) {
          document.documentElement.setAttribute('data-theme', 'dark');
          localStorage.setItem('theme', 'dark');
      } else {
          document.documentElement.setAttribute('data-theme', 'light');
          localStorage.setItem('theme', 'light');
      }
  }

  toggleSwitch.addEventListener('change', switchTheme, false);


  if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
    document.documentElement.setAttribute('data-theme', "dark");
    toggleSwitch.checked = true;
  } else if (window.matchMedia && window.matchMedia('(prefers-color-scheme: light)').matches) {
    document.documentElement.setAttribute('data-theme', "light");
    toggleSwitch.checked = false;
  } else {
    const currentTheme = localStorage.getItem('theme') ? localStorage.getItem('theme') : null;
    if (currentTheme) {
      document.documentElement.setAttribute('data-theme', currentTheme);

      if (currentTheme === 'dark') {
        toggleSwitch.checked = true;
      }
    }
  }
}
</script>

</head>

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Arraymancer - Working with OpenCL and Cuda in Nim</title>

<link href="docutils.css" rel="stylesheet" type="text/css"/>
<link href="nav.css" rel="stylesheet" type="text/css"/>

<link href='http://fonts.googleapis.com/css?family=Raleway:400,600,900' rel='stylesheet' type='text/css'/>
<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:400,500,600' rel='stylesheet' type='text/css'/>

<a href="https://github.com/mratsim/arraymancer"><img style="position: fixed; top: 0; right: 0; border: 0; z-index: 10;" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_gray_6d6d6d.png?resize=150%2C150" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png"></a>

<body onload="main()">
<div class="document" id="documentId">
  <div class="container">
    <h1 class="title">Working with OpenCL and Cuda in Nim</h1>
    <p><em>Date: May 6, 2018, by Mamy André-Ratsimbazafy</em></p>
<p>Arraymancer is a tensor library I’m writing from the ground up in Nim. Cuda support was added in v0.3 last December, I just released the new v0.4 with OpenCL support.</p>
<p>I’d like to share a bit of my experience on working in OpenCL through Nim. First of all, you have to know that none of the big guys (Google Tensorflow, Facebook PyTorch, Apache/Amazon MxNet, Microsoft CNTK or even Intel/AMD) has first class OpenCL support.</p>
<p>Why? Probably because Nvidia is providing superb tools and documentation for frameworks developers. Also Cuda can leerage a few C++ facilities like generics and function objects that I use heavily for generic code.</p>
<p>For example in Nim+Cuda I define element-wise functions like the following and pass it to a higher-order function that will apply it element-wise on 3 tensors:</p>
<pre class="listing"><span class="Comment"># Binary op</span>
<span class="Comment"># Does C[i] = A[i] `op` B[i]</span>
<span class="Keyword">template</span> <span class="Identifier">cuda_binary_op</span><span class="Punctuation">(</span><span class="Identifier">op_name</span><span class="Punctuation">,</span> <span class="Identifier">op_symbol</span><span class="Punctuation">:</span> <span class="Identifier">string</span><span class="Punctuation">)</span><span class="Operator">=</span>
  <span class="Punctuation">{</span><span class="Operator">.</span><span class="Identifier">emit</span><span class="Punctuation">:</span><span class="Punctuation">[</span><span class="LongStringLit">&quot;&quot;&quot;
  template&lt;typename T&gt;
  struct &quot;&quot;&quot;</span><span class="Punctuation">,</span><span class="Identifier">op_name</span><span class="Punctuation">,</span><span class="LongStringLit">&quot;&quot;&quot;{
  __device__ __forceinline__ void operator()(
      T *  __restrict__ dst,
      const T *  __restrict__ A,
      const T *  __restrict__ B){
      *dst = __ldg(A)&quot;&quot;&quot;</span><span class="Punctuation">,</span> <span class="Identifier">op_symbol</span><span class="Punctuation">,</span> <span class="LongStringLit">&quot;&quot;&quot; __ldg(B);
      }
  };
  &quot;&quot;&quot;</span><span class="Punctuation">]</span><span class="Operator">.</span><span class="Punctuation">}</span></pre><p>You can see here the advantage of C++: <tt class="docutils literal"><span class="pre">typename T</span></tt> to template over int/float/double and higher-order functions/function object for cleaner code. You can also see that Nim can directly inline C++ code with <tt class="docutils literal"><span class="pre">emit</span></tt> and I even templatize the operation_name.</p>
<p>Now what about OpenCL? Unfortunately C doesn’t offer something similar and requires a lot of boilerplate. The alternative, the C++ official OpenCL API and implementation: SYCL is very experimental and I am not sure how it works on actual GPUs.</p>
<p>However thanks to Nim metaprogramming, squashing the C boilerplate is super easy. Here is an example kernel to do C = A op B</p>
<pre class="listing"><span class="Keyword">template</span> <span class="Identifier">gen_cl_apply3</span><span class="Operator">*</span><span class="Punctuation">(</span><span class="Identifier">kern_name</span><span class="Punctuation">,</span> <span class="Identifier">ctype</span><span class="Punctuation">,</span> <span class="Identifier">op</span><span class="Punctuation">:</span> <span class="Identifier">string</span><span class="Punctuation">)</span><span class="Punctuation">:</span> <span class="Identifier">string</span> <span class="Operator">=</span>
  <span class="Comment">## Generates an OpenCL kernel for an elementwise binary infix operations (like +, -, ...)</span>
  <span class="Comment">## Input:</span>
  <span class="Comment">##   - The C type</span>
  <span class="Comment">##   - The C kernel name (this only helps debugging the C code)</span>
  <span class="Comment">##   - The C operation (+, -, ...)</span>
  
  
  <span class="Identifier">opencl_getIndexOfElementID</span><span class="Punctuation">(</span><span class="Punctuation">)</span> <span class="Operator">&amp;</span> <span class="LongStringLit">&quot;&quot;&quot;
  __kernel
  void &quot;&quot;&quot;</span> <span class="Operator">&amp;</span> <span class="Identifier">kern_name</span> <span class="Operator">&amp;</span>
          <span class="LongStringLit">&quot;&quot;&quot;(const int rank,
              const int len,
              __global const int * restrict dst_shape,
              __global const int * restrict dst_strides,
              const int dst_offset,
              __global       &quot;&quot;&quot;</span> <span class="Operator">&amp;</span> <span class="Identifier">ctype</span> <span class="Operator">&amp;</span> <span class="LongStringLit">&quot;&quot;&quot; * restrict const dst_data,
              __global const int * restrict A_shape,
              __global const int * restrict A_strides,
              const int A_offset,
              __global const &quot;&quot;&quot;</span> <span class="Operator">&amp;</span> <span class="Identifier">ctype</span> <span class="Operator">&amp;</span> <span class="LongStringLit">&quot;&quot;&quot; * restrict const A_data,
              __global const int * restrict B_shape,
              __global const int * restrict B_strides,
              const int B_offset,
              __global const &quot;&quot;&quot;</span> <span class="Operator">&amp;</span> <span class="Identifier">ctype</span> <span class="Operator">&amp;</span> <span class="LongStringLit">&quot;&quot;&quot; * restrict const B_data)
  {
    // Grid-stride loop
    for (int elemID = get_global_id(0);
    elemID &lt; len;
    elemID += get_global_size(0)) {
      const int dst_real_idx = opencl_getIndexOfElementID(rank, dst_shape, dst_strides, dst_offset, elemID);
      const int A_real_idx = opencl_getIndexOfElementID(rank, A_shape, A_strides, A_offset, elemID);
      const int B_real_idx = opencl_getIndexOfElementID(rank, B_shape, B_strides, B_offset, elemID);
      
      dst_data[dst_real_idx] = A_data[A_real_idx] &quot;&quot;&quot;</span> <span class="Operator">&amp;</span> <span class="Identifier">op</span> <span class="Operator">&amp;</span> <span class="LongStringLit">&quot;&quot;&quot; B_data[B_real_idx];
    }
  }
  &quot;&quot;&quot;</span></pre><p>And write a few generic lines of code to deal with the data on the device (especially <tt class="docutils literal"><span class="pre">opencl_getIndexOfElementID</span></tt> which convert <tt class="docutils literal"><span class="pre">foo[1, 2, 3]</span></tt> into <tt class="docutils literal"><span class="pre">foo.data[456]</span></tt> depending on the tensor shape.</p>
<p>Afterwards, all my operations are easily added in one line:</p>
<ul class="simple"><li>kind of function (infix: C = A op B or in-place A += B or A *= B)</li>
<li>Nim type</li>
<li>C type</li>
<li>Nim operator (for operator overloading)</li>
<li>OpenCL kernel name</li>
<li>OpenCL operation</li>
</ul>
<pre class="listing"><span class="Identifier">genClInfixOp</span><span class="Punctuation">(</span><span class="Identifier">float32</span><span class="Punctuation">,</span> <span class="StringLit">&quot;float&quot;</span><span class="Punctuation">,</span> <span class="Punctuation">`</span><span class="Operator">+</span><span class="Punctuation">`</span><span class="Punctuation">,</span> <span class="StringLit">&quot;clAdd&quot;</span><span class="Punctuation">,</span> <span class="StringLit">&quot;+&quot;</span><span class="Punctuation">)</span>
<span class="Identifier">genClInfixOp</span><span class="Punctuation">(</span><span class="Identifier">float64</span><span class="Punctuation">,</span> <span class="StringLit">&quot;double&quot;</span><span class="Punctuation">,</span> <span class="Punctuation">`</span><span class="Operator">+</span><span class="Punctuation">`</span><span class="Punctuation">,</span> <span class="StringLit">&quot;clAdd&quot;</span><span class="Punctuation">,</span> <span class="StringLit">&quot;+&quot;</span><span class="Punctuation">)</span>
<span class="Identifier">genClInfixOp</span><span class="Punctuation">(</span><span class="Identifier">float32</span><span class="Punctuation">,</span> <span class="StringLit">&quot;float&quot;</span><span class="Punctuation">,</span> <span class="Punctuation">`</span><span class="Operator">-</span><span class="Punctuation">`</span><span class="Punctuation">,</span> <span class="StringLit">&quot;clSub&quot;</span><span class="Punctuation">,</span> <span class="StringLit">&quot;-&quot;</span><span class="Punctuation">)</span>
<span class="Identifier">genClInfixOp</span><span class="Punctuation">(</span><span class="Identifier">float64</span><span class="Punctuation">,</span> <span class="StringLit">&quot;double&quot;</span><span class="Punctuation">,</span> <span class="Punctuation">`</span><span class="Operator">-</span><span class="Punctuation">`</span><span class="Punctuation">,</span> <span class="StringLit">&quot;clSub&quot;</span><span class="Punctuation">,</span> <span class="StringLit">&quot;-&quot;</span><span class="Punctuation">)</span>

<span class="Identifier">genClInPlaceOp</span><span class="Punctuation">(</span><span class="Identifier">float32</span><span class="Punctuation">,</span> <span class="StringLit">&quot;float&quot;</span><span class="Punctuation">,</span> <span class="Punctuation">`</span><span class="Operator">+=</span><span class="Punctuation">`</span><span class="Punctuation">,</span> <span class="StringLit">&quot;clAdd&quot;</span><span class="Punctuation">,</span> <span class="StringLit">&quot;+=&quot;</span><span class="Punctuation">)</span>
<span class="Identifier">genClInPlaceOp</span><span class="Punctuation">(</span><span class="Identifier">float64</span><span class="Punctuation">,</span> <span class="StringLit">&quot;double&quot;</span><span class="Punctuation">,</span> <span class="Punctuation">`</span><span class="Operator">+=</span><span class="Punctuation">`</span><span class="Punctuation">,</span> <span class="StringLit">&quot;clAdd&quot;</span><span class="Punctuation">,</span> <span class="StringLit">&quot;+=&quot;</span><span class="Punctuation">)</span>
<span class="Identifier">genClInPlaceOp</span><span class="Punctuation">(</span><span class="Identifier">float32</span><span class="Punctuation">,</span> <span class="StringLit">&quot;float&quot;</span><span class="Punctuation">,</span> <span class="Punctuation">`</span><span class="Operator">-=</span><span class="Punctuation">`</span><span class="Punctuation">,</span> <span class="StringLit">&quot;clSub&quot;</span><span class="Punctuation">,</span> <span class="StringLit">&quot;-=&quot;</span><span class="Punctuation">)</span>
<span class="Identifier">genClInPlaceOp</span><span class="Punctuation">(</span><span class="Identifier">float64</span><span class="Punctuation">,</span> <span class="StringLit">&quot;double&quot;</span><span class="Punctuation">,</span> <span class="Punctuation">`</span><span class="Operator">-=</span><span class="Punctuation">`</span><span class="Punctuation">,</span> <span class="StringLit">&quot;clSub&quot;</span><span class="Punctuation">,</span> <span class="StringLit">&quot;-=&quot;</span><span class="Punctuation">)</span></pre><p>Next steps? Create unary operation higher-order functions and add cos/sin/ln/exp in just 2 lines of code each. Furthermore allow lifting any unary operation to operations on whole tensors with a map function, expose it so that OpenCL tensors are easily customizable.</p>
<p>After using Nim + OpenCL, I actually realized that using C++ function objects was overengineering.</p>
<p>To conclude, at the moment, I am convinced that the best language to work with GPUs is Nim.</p>
<p>Oh, and for those who wants to see real Nim code for neural networks, here is a Fizzbuzz in Nim using neural networks (I didn’t implement it on GPU yet though)</p>
<pre class="listing"><span class="Comment"># A port to Arraymancer of Joel Grus hilarious FizzBuzz in Tensorflow:</span>
<span class="Comment"># http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/</span>

<span class="Comment"># Interviewer: Welcome, can I get you a coffee or anything? Do you need a break?</span>
<span class="Comment"># ...</span>
<span class="Comment"># Interviewer: OK, so I need you to print the numbers from 1 to 100,</span>
<span class="Comment">#              except that if the number is divisible by 3 print &quot;fizz&quot;,</span>
<span class="Comment">#              if it's divisible by 5 print &quot;buzz&quot;, and if it's divisible by 15 print &quot;fizzbuzz&quot;.</span>

<span class="Comment"># Let's start with standard imports</span>
<span class="Keyword">import</span> <span class="Operator">../</span><span class="Identifier">src</span><span class="Operator">/</span><span class="Identifier">arraymancer</span><span class="Punctuation">,</span> <span class="Identifier">math</span><span class="Punctuation">,</span> <span class="Identifier">strformat</span>

<span class="Comment"># We want to input a number and output the correct &quot;fizzbuzz&quot; representation</span>
<span class="Comment"># ideally the input is a represented by a vector of real values between 0 and 1</span>
<span class="Comment"># One way to do that is by using the binary representation of number</span>
<span class="Keyword">func</span> <span class="Identifier">binary_encode</span><span class="Punctuation">(</span><span class="Identifier">i</span><span class="Punctuation">:</span> <span class="Identifier">int</span><span class="Punctuation">,</span> <span class="Identifier">num_digits</span><span class="Punctuation">:</span> <span class="Identifier">int</span><span class="Punctuation">)</span><span class="Punctuation">:</span> <span class="Identifier">Tensor</span><span class="Punctuation">[</span><span class="Identifier">float32</span><span class="Punctuation">]</span> <span class="Operator">=</span>
  <span class="Identifier">result</span> <span class="Operator">=</span> <span class="Identifier">newTensor</span><span class="Punctuation">[</span><span class="Identifier">float32</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="Identifier">num_digits</span><span class="Punctuation">)</span>
  <span class="Keyword">for</span> <span class="Identifier">d</span> <span class="Keyword">in</span> <span class="DecNumber">0</span> <span class="Operator">..&lt;</span> <span class="Identifier">num_digits</span><span class="Punctuation">:</span>
    <span class="Identifier">result</span><span class="Punctuation">[</span><span class="DecNumber">0</span><span class="Punctuation">,</span> <span class="Identifier">d</span><span class="Punctuation">]</span> <span class="Operator">=</span> <span class="Identifier">float32</span><span class="Punctuation">(</span><span class="Identifier">i</span> <span class="Keyword">shr</span> <span class="Identifier">d</span> <span class="Keyword">and</span> <span class="DecNumber">1</span><span class="Punctuation">)</span>

<span class="Comment"># For the input, we distinguishes 4 cases, nothing, fizz, buzz and fizzbuzz.</span>
<span class="Keyword">func</span> <span class="Identifier">fizz_buzz_encode</span><span class="Punctuation">(</span><span class="Identifier">i</span><span class="Punctuation">:</span> <span class="Identifier">int</span><span class="Punctuation">)</span><span class="Punctuation">:</span> <span class="Identifier">int</span> <span class="Operator">=</span>
  <span class="Keyword">if</span>   <span class="Identifier">i</span> <span class="Keyword">mod</span> <span class="DecNumber">15</span> <span class="Operator">==</span> <span class="DecNumber">0</span><span class="Punctuation">:</span> <span class="Keyword">return</span> <span class="DecNumber">3</span> <span class="Comment"># fizzbuzz</span>
  <span class="Keyword">elif</span> <span class="Identifier">i</span> <span class="Keyword">mod</span>  <span class="DecNumber">5</span> <span class="Operator">==</span> <span class="DecNumber">0</span><span class="Punctuation">:</span> <span class="Keyword">return</span> <span class="DecNumber">2</span> <span class="Comment"># buzz</span>
  <span class="Keyword">elif</span> <span class="Identifier">i</span> <span class="Keyword">mod</span>  <span class="DecNumber">3</span> <span class="Operator">==</span> <span class="DecNumber">0</span><span class="Punctuation">:</span> <span class="Keyword">return</span> <span class="DecNumber">1</span> <span class="Comment"># fizz</span>
  <span class="Keyword">else</span>              <span class="Punctuation">:</span> <span class="Keyword">return</span> <span class="DecNumber">0</span>

<span class="Comment"># Next, let's generate training data, we don't want to train on 1..100, that's our test values</span>
<span class="Comment"># We can't tell the neural net the truth values it must discover the logic by itself.</span>
<span class="Comment"># so we use values between 101 and 1024 (2^10)</span>
<span class="Keyword">const</span> <span class="Identifier">NumDigits</span> <span class="Operator">=</span> <span class="DecNumber">10</span>

<span class="Keyword">var</span> <span class="Identifier">x_train</span> <span class="Operator">=</span> <span class="Identifier">newTensor</span><span class="Punctuation">[</span><span class="Identifier">float32</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="DecNumber">2</span><span class="Operator">^</span><span class="Identifier">NumDigits</span> <span class="Operator">-</span> <span class="DecNumber">101</span><span class="Punctuation">,</span> <span class="Identifier">NumDigits</span><span class="Punctuation">)</span>
<span class="Keyword">var</span> <span class="Identifier">y_train</span> <span class="Operator">=</span> <span class="Identifier">newTensor</span><span class="Punctuation">[</span><span class="Identifier">int</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="DecNumber">2</span><span class="Operator">^</span><span class="Identifier">NumDigits</span> <span class="Operator">-</span> <span class="DecNumber">101</span><span class="Punctuation">)</span>

<span class="Keyword">for</span> <span class="Identifier">i</span> <span class="Keyword">in</span> <span class="DecNumber">101</span> <span class="Operator">..&lt;</span> <span class="DecNumber">2</span><span class="Operator">^</span><span class="Identifier">NumDigits</span><span class="Punctuation">:</span>
  <span class="Identifier">x_train</span><span class="Punctuation">[</span><span class="Identifier">i</span> <span class="Operator">-</span> <span class="DecNumber">101</span><span class="Punctuation">,</span> <span class="Identifier">_</span><span class="Punctuation">]</span> <span class="Operator">=</span> <span class="Identifier">binary_encode</span><span class="Punctuation">(</span><span class="Identifier">i</span><span class="Punctuation">,</span> <span class="Identifier">NumDigits</span><span class="Punctuation">)</span>
  <span class="Identifier">y_train</span><span class="Punctuation">[</span><span class="Identifier">i</span> <span class="Operator">-</span> <span class="DecNumber">101</span><span class="Punctuation">]</span> <span class="Operator">=</span> <span class="Identifier">fizz_buzz_encode</span><span class="Punctuation">(</span><span class="Identifier">i</span><span class="Punctuation">)</span>

<span class="Comment"># How many neurons do we need to change a light bulb, sorry do a division? let's pick ...</span>
<span class="Keyword">const</span> <span class="Identifier">NumHidden</span> <span class="Operator">=</span> <span class="DecNumber">100</span>

<span class="Comment"># Let's setup our neural network context, variables and model</span>
<span class="Keyword">let</span>
  <span class="Identifier">ctx</span> <span class="Operator">=</span> <span class="Identifier">newContext</span> <span class="Identifier">Tensor</span><span class="Punctuation">[</span><span class="Identifier">float32</span><span class="Punctuation">]</span>
  <span class="Identifier">X</span>   <span class="Operator">=</span> <span class="Identifier">ctx</span><span class="Operator">.</span><span class="Identifier">variable</span> <span class="Identifier">x_train</span>

<span class="Identifier">network</span> <span class="Identifier">ctx</span><span class="Punctuation">,</span> <span class="Identifier">FizzBuzzNet</span><span class="Punctuation">:</span>
  <span class="Identifier">layers</span><span class="Punctuation">:</span>
    <span class="Identifier">hidden</span><span class="Punctuation">:</span> <span class="Identifier">Linear</span><span class="Punctuation">(</span><span class="Identifier">NumDigits</span><span class="Punctuation">,</span> <span class="Identifier">NumHidden</span><span class="Punctuation">)</span>
    <span class="Identifier">output</span><span class="Punctuation">:</span> <span class="Identifier">Linear</span><span class="Punctuation">(</span><span class="Identifier">NumHidden</span><span class="Punctuation">,</span> <span class="DecNumber">4</span><span class="Punctuation">)</span>
  <span class="Identifier">forward</span> <span class="Identifier">x</span><span class="Punctuation">:</span>
    <span class="Identifier">x</span><span class="Operator">.</span><span class="Identifier">hidden</span><span class="Operator">.</span><span class="Identifier">relu</span><span class="Operator">.</span><span class="Identifier">output</span>

<span class="Keyword">let</span> <span class="Identifier">model</span> <span class="Operator">=</span> <span class="Identifier">ctx</span><span class="Operator">.</span><span class="Identifier">init</span><span class="Punctuation">(</span><span class="Identifier">FizzBuzzNet</span><span class="Punctuation">)</span>
<span class="Keyword">let</span> <span class="Identifier">optim</span> <span class="Operator">=</span> <span class="Identifier">model</span><span class="Operator">.</span><span class="Identifier">optimizer</span><span class="Punctuation">(</span><span class="Identifier">SGD</span><span class="Punctuation">,</span> <span class="FloatNumber">0.05'f32</span><span class="Punctuation">)</span>

<span class="Keyword">func</span> <span class="Identifier">fizz_buzz</span><span class="Punctuation">(</span><span class="Identifier">i</span><span class="Punctuation">:</span> <span class="Identifier">int</span><span class="Punctuation">,</span> <span class="Identifier">prediction</span><span class="Punctuation">:</span> <span class="Identifier">int</span><span class="Punctuation">)</span><span class="Punctuation">:</span> <span class="Identifier">string</span> <span class="Operator">=</span>
  <span class="Punctuation">[</span><span class="Operator">$</span><span class="Identifier">i</span><span class="Punctuation">,</span> <span class="StringLit">&quot;fizz&quot;</span><span class="Punctuation">,</span> <span class="StringLit">&quot;buzz&quot;</span><span class="Punctuation">,</span> <span class="StringLit">&quot;fizzbuzz&quot;</span><span class="Punctuation">]</span><span class="Punctuation">[</span><span class="Identifier">prediction</span><span class="Punctuation">]</span>

<span class="Comment"># Phew, finally ready to train, let's pick the batch size and number of epochs</span>
<span class="Keyword">const</span> <span class="Identifier">BatchSize</span> <span class="Operator">=</span> <span class="DecNumber">128</span>
<span class="Keyword">const</span> <span class="Identifier">Epochs</span>    <span class="Operator">=</span> <span class="DecNumber">2500</span>

<span class="Comment"># And let's start training the network</span>
<span class="Keyword">for</span> <span class="Identifier">epoch</span> <span class="Keyword">in</span> <span class="DecNumber">0</span> <span class="Operator">..&lt;</span> <span class="Identifier">Epochs</span><span class="Punctuation">:</span>
  <span class="Comment"># Here I should probably shuffle the input data.</span>
  <span class="Keyword">for</span> <span class="Identifier">start_batch</span> <span class="Keyword">in</span> <span class="Identifier">countup</span><span class="Punctuation">(</span><span class="DecNumber">0</span><span class="Punctuation">,</span> <span class="Identifier">x_train</span><span class="Operator">.</span><span class="Identifier">shape</span><span class="Punctuation">[</span><span class="DecNumber">0</span><span class="Punctuation">]</span><span class="Operator">-</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="Identifier">BatchSize</span><span class="Punctuation">)</span><span class="Punctuation">:</span>
    
    <span class="Comment"># Pick the minibatch</span>
    <span class="Keyword">let</span> <span class="Identifier">end_batch</span> <span class="Operator">=</span> <span class="Identifier">min</span><span class="Punctuation">(</span><span class="Identifier">x_train</span><span class="Operator">.</span><span class="Identifier">shape</span><span class="Punctuation">[</span><span class="DecNumber">0</span><span class="Punctuation">]</span><span class="Operator">-</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="Identifier">start_batch</span> <span class="Operator">+</span> <span class="Identifier">BatchSize</span><span class="Punctuation">)</span>
    <span class="Keyword">let</span> <span class="Identifier">X_batch</span> <span class="Operator">=</span> <span class="Identifier">X</span><span class="Punctuation">[</span><span class="Identifier">start_batch</span> <span class="Operator">..&lt;</span> <span class="Identifier">end_batch</span><span class="Punctuation">,</span> <span class="Identifier">_</span><span class="Punctuation">]</span>
    <span class="Keyword">let</span> <span class="Identifier">target</span> <span class="Operator">=</span> <span class="Identifier">y_train</span><span class="Punctuation">[</span><span class="Identifier">start_batch</span> <span class="Operator">..&lt;</span> <span class="Identifier">end_batch</span><span class="Punctuation">]</span>
    
    <span class="Comment"># Go through the model</span>
    <span class="Keyword">let</span> <span class="Identifier">clf</span> <span class="Operator">=</span> <span class="Identifier">model</span><span class="Operator">.</span><span class="Identifier">forward</span><span class="Punctuation">(</span><span class="Identifier">X_batch</span><span class="Punctuation">)</span>
    
    <span class="Comment"># Go through our cost function</span>
    <span class="Keyword">let</span> <span class="Identifier">loss</span> <span class="Operator">=</span> <span class="Identifier">clf</span><span class="Operator">.</span><span class="Identifier">sparse_softmax_cross_entropy</span><span class="Punctuation">(</span><span class="Identifier">target</span><span class="Punctuation">)</span>
    
    <span class="Comment"># Backpropagate the errors and let the optimizer fix them.</span>
    <span class="Identifier">loss</span><span class="Operator">.</span><span class="Identifier">backprop</span><span class="Punctuation">(</span><span class="Punctuation">)</span>
    <span class="Identifier">optim</span><span class="Operator">.</span><span class="Identifier">update</span><span class="Punctuation">(</span><span class="Punctuation">)</span>
  
  <span class="Comment"># Let's see how we fare:</span>
  <span class="Identifier">ctx</span><span class="Operator">.</span><span class="Identifier">no_grad_mode</span><span class="Punctuation">:</span>
    <span class="Identifier">echo</span> <span class="Operator">&amp;</span><span class="StringLit">&quot;</span><span class="EscapeSequence">\n</span><span class="StringLit">Epoch #{epoch} done. Testing accuracy&quot;</span>
    
    <span class="Keyword">let</span> <span class="Identifier">y_pred</span> <span class="Operator">=</span> <span class="Identifier">model</span>
                  <span class="Operator">.</span><span class="Identifier">forward</span><span class="Punctuation">(</span><span class="Identifier">X</span><span class="Punctuation">)</span>
                  <span class="Operator">.</span><span class="Identifier">value</span>
                  <span class="Operator">.</span><span class="Identifier">softmax</span>
                  <span class="Operator">.</span><span class="Identifier">argmax</span><span class="Punctuation">(</span><span class="Identifier">axis</span> <span class="Operator">=</span> <span class="DecNumber">1</span><span class="Punctuation">)</span>
                  <span class="Operator">.</span><span class="Identifier">squeeze</span>
    
    <span class="Keyword">let</span> <span class="Identifier">score</span> <span class="Operator">=</span> <span class="Identifier">y_pred</span><span class="Operator">.</span><span class="Identifier">accuracy_score</span><span class="Punctuation">(</span><span class="Identifier">y_train</span><span class="Punctuation">)</span>
    <span class="Identifier">echo</span> <span class="Operator">&amp;</span><span class="StringLit">&quot;Accuracy: {score:.3f}%&quot;</span>
    <span class="Identifier">echo</span> <span class="StringLit">&quot;</span><span class="EscapeSequence">\n</span><span class="StringLit">&quot;</span>


<span class="Comment"># Our network is trained, let's see if it's well behaved</span>

<span class="Comment"># Now let's use what we really want to fizzbuzz, numbers from 1 to 100</span>
<span class="Keyword">var</span> <span class="Identifier">x_buzz</span> <span class="Operator">=</span> <span class="Identifier">newTensor</span><span class="Punctuation">[</span><span class="Identifier">float32</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="DecNumber">100</span><span class="Punctuation">,</span> <span class="Identifier">NumDigits</span><span class="Punctuation">)</span>
<span class="Keyword">for</span> <span class="Identifier">i</span> <span class="Keyword">in</span> <span class="DecNumber">1</span> <span class="Operator">..</span> <span class="DecNumber">100</span><span class="Punctuation">:</span>
  <span class="Identifier">x_buzz</span><span class="Punctuation">[</span><span class="Identifier">i</span> <span class="Operator">-</span> <span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="Identifier">_</span><span class="Punctuation">]</span> <span class="Operator">=</span> <span class="Identifier">binary_encode</span><span class="Punctuation">(</span><span class="Identifier">i</span><span class="Punctuation">,</span> <span class="Identifier">NumDigits</span><span class="Punctuation">)</span>

<span class="Comment"># Wrap them for neural net</span>
<span class="Keyword">let</span> <span class="Identifier">X_buzz</span> <span class="Operator">=</span> <span class="Identifier">ctx</span><span class="Operator">.</span><span class="Identifier">variable</span> <span class="Identifier">x_buzz</span>

<span class="Comment"># Pass it through the network</span>
<span class="Identifier">ctx</span><span class="Operator">.</span><span class="Identifier">no_grad_mode</span><span class="Punctuation">:</span>
  <span class="Keyword">let</span> <span class="Identifier">y_buzz</span> <span class="Operator">=</span> <span class="Identifier">model</span>
                <span class="Operator">.</span><span class="Identifier">forward</span><span class="Punctuation">(</span><span class="Identifier">X_buzz</span><span class="Punctuation">)</span>
                <span class="Operator">.</span><span class="Identifier">value</span>
                <span class="Operator">.</span><span class="Identifier">softmax</span>
                <span class="Operator">.</span><span class="Identifier">argmax</span><span class="Punctuation">(</span><span class="Identifier">axis</span> <span class="Operator">=</span> <span class="DecNumber">1</span><span class="Punctuation">)</span>
                <span class="Operator">.</span><span class="Identifier">squeeze</span>

<span class="Comment"># Extract the answer</span>
<span class="Keyword">var</span> <span class="Identifier">answer</span><span class="Punctuation">:</span> <span class="Identifier">seq</span><span class="Punctuation">[</span><span class="Identifier">string</span><span class="Punctuation">]</span> <span class="Operator">=</span> <span class="Operator">@</span><span class="Punctuation">[</span><span class="Punctuation">]</span>

<span class="Keyword">for</span> <span class="Identifier">i</span> <span class="Keyword">in</span> <span class="FloatNumber">1.</span><span class="Operator">.</span><span class="DecNumber">100</span><span class="Punctuation">:</span>
  <span class="Identifier">answer</span><span class="Operator">.</span><span class="Identifier">add</span> <span class="Identifier">fizz_buzz</span><span class="Punctuation">(</span><span class="Identifier">i</span><span class="Punctuation">,</span> <span class="Identifier">y_buzz</span><span class="Punctuation">[</span><span class="Identifier">i</span> <span class="Operator">-</span> <span class="DecNumber">1</span><span class="Punctuation">]</span><span class="Punctuation">)</span>

<span class="Identifier">echo</span> <span class="Identifier">answer</span>
<span class="Comment"># @[&quot;1&quot;, &quot;2&quot;, &quot;fizz&quot;, &quot;4&quot;, &quot;buzz&quot;, &quot;6&quot;, &quot;7&quot;, &quot;8&quot;, &quot;fizz&quot;, &quot;10&quot;,</span>
<span class="Comment">#   &quot;11&quot;, &quot;12&quot;, &quot;13&quot;, &quot;14&quot;, &quot;15&quot;, &quot;16&quot;, &quot;17&quot;, &quot;fizz&quot;, &quot;19&quot;, &quot;buzz&quot;,</span>
<span class="Comment">#   &quot;fizz&quot;, &quot;22&quot;, &quot;23&quot;, &quot;24&quot;, &quot;buzz&quot;, &quot;26&quot;, &quot;fizz&quot;, &quot;28&quot;, &quot;29&quot;, &quot;30&quot;,</span>
<span class="Comment">#   &quot;31&quot;, &quot;32&quot;, &quot;fizz&quot;, &quot;34&quot;, &quot;buzz&quot;, &quot;36&quot;, &quot;37&quot;, &quot;38&quot;, &quot;39&quot;, &quot;40&quot;,</span>
<span class="Comment">#   &quot;41&quot;, &quot;fizz&quot;, &quot;43&quot;, &quot;44&quot;, &quot;fizzbuzz&quot;, &quot;46&quot;, &quot;47&quot;, &quot;fizz&quot;, &quot;49&quot;, &quot;50&quot;,</span>
<span class="Comment">#   &quot;fizz&quot;, &quot;52&quot;,&quot;53&quot;, &quot;54&quot;, &quot;buzz&quot;, &quot;56&quot;, &quot;fizz&quot;, &quot;58&quot;, &quot;59&quot;, &quot;fizzbuzz&quot;,</span>
<span class="Comment">#   &quot;61&quot;, &quot;62&quot;, &quot;63&quot;, &quot;64&quot;, &quot;buzz&quot;, &quot;fizz&quot;, &quot;67&quot;, &quot;68&quot;, &quot;fizz&quot;, &quot;buzz&quot;,</span>
<span class="Comment">#   &quot;71&quot;, &quot;fizz&quot;, &quot;73&quot;, &quot;74&quot;, &quot;75&quot;, &quot;76&quot;, &quot;77&quot;,&quot;fizz&quot;, &quot;79&quot;, &quot;buzz&quot;,</span>
<span class="Comment">#   &quot;fizz&quot;, &quot;82&quot;, &quot;83&quot;, &quot;fizz&quot;, &quot;buzz&quot;, &quot;86&quot;, &quot;fizz&quot;, &quot;88&quot;, &quot;89&quot;, &quot;90&quot;,</span>
<span class="Comment">#   &quot;91&quot;, &quot;92&quot;, &quot;fizz&quot;, &quot;94&quot;, &quot;buzz&quot;, &quot;fizz&quot;, &quot;97&quot;, &quot;98&quot;, &quot;fizz&quot;, &quot;buzz&quot;]</span>

<span class="Comment"># I guess 100 neurons are not enough to learn multiplication :/.</span></pre><p>Thank you for your attention and your support,</p>
<p>Be sure to try <a class="reference external" href="https://nim-lang.org/">Nim</a> and <a class="reference external" href="https://github.com/mratsim/Arraymancer">Arraymancer</a>! </p>



    <div class="row">
      <div class="twelve-columns footer">
        <span class="nim-sprite"></span>
        <br/>
        <small style="color: var(--hint);">Made with Nim. Generated: 2024-05-12 14:01:32 UTC</small>
      </div>
    </div>
  </div>
</div>

<header>
  <a class="pagetitle" href="index.html">Arraymancer</a>
  <span>
    <a href="#">Technical reference</a>
    <ul class="monospace" style="padding-bottom: 15px; padding-top: 10px;">
      <span>
      <li>
        <a href="#">Core tensor API</a>
        <ul class="monospace">
          <li><a href="accessors.html">accessors</a></li>
<li><a href="accessors_macros_read.html">accessors_macros_read</a></li>
<li><a href="accessors_macros_syntax.html">accessors_macros_syntax</a></li>
<li><a href="accessors_macros_write.html">accessors_macros_write</a></li>
<li><a href="aggregate.html">aggregate</a></li>
<li><a href="algorithms.html">algorithms</a></li>
<li><a href="blas_l3_gemm.html">blas_l3_gemm</a></li>
<li><a href="complex.html">complex</a></li>
<li><a href="cublas.html">cublas</a></li>
<li><a href="cuda.html">cuda</a></li>
<li><a href="cuda_global_state.html">cuda_global_state</a></li>
<li><a href="data_structure.html">data_structure</a></li>
<li><a href="display.html">display</a></li>
<li><a href="display_cuda.html">display_cuda</a></li>
<li><a href="einsum.html">einsum</a></li>
<li><a href="exporting.html">exporting</a></li>
<li><a href="filling_data.html">filling_data</a></li>
<li><a href="higher_order_applymap.html">higher_order_applymap</a></li>
<li><a href="higher_order_foldreduce.html">higher_order_foldreduce</a></li>
<li><a href="incl_accessors_cuda.html">incl_accessors_cuda</a></li>
<li><a href="incl_higher_order_cuda.html">incl_higher_order_cuda</a></li>
<li><a href="incl_kernels_cuda.html">incl_kernels_cuda</a></li>
<li><a href="init_copy_cpu.html">init_copy_cpu</a></li>
<li><a href="init_copy_cuda.html">init_copy_cuda</a></li>
<li><a href="init_cpu.html">init_cpu</a></li>
<li><a href="init_cuda.html">init_cuda</a></li>
<li><a href="init_opencl.html">init_opencl</a></li>
<li><a href="lapack.html">lapack</a></li>
<li><a href="math_functions.html">math_functions</a></li>
<li><a href="memory_optimization_hints.html">memory_optimization_hints</a></li>
<li><a href="naive_l2_gemv.html">naive_l2_gemv</a></li>
<li><a href="opencl_backend.html">opencl_backend</a></li>
<li><a href="opencl_global_state.html">opencl_global_state</a></li>
<li><a href="openmp.html">openmp</a></li>
<li><a href="operators_blas_l1.html">operators_blas_l1</a></li>
<li><a href="operators_blas_l1_cuda.html">operators_blas_l1_cuda</a></li>
<li><a href="operators_blas_l1_opencl.html">operators_blas_l1_opencl</a></li>
<li><a href="operators_blas_l2l3.html">operators_blas_l2l3</a></li>
<li><a href="operators_blas_l2l3_cuda.html">operators_blas_l2l3_cuda</a></li>
<li><a href="operators_blas_l2l3_opencl.html">operators_blas_l2l3_opencl</a></li>
<li><a href="operators_broadcasted.html">operators_broadcasted</a></li>
<li><a href="operators_broadcasted_cuda.html">operators_broadcasted_cuda</a></li>
<li><a href="operators_broadcasted_opencl.html">operators_broadcasted_opencl</a></li>
<li><a href="operators_comparison.html">operators_comparison</a></li>
<li><a href="operators_logical.html">operators_logical</a></li>
<li><a href="optim_ops_fusion.html">optim_ops_fusion</a></li>
<li><a href="p_accessors.html">p_accessors</a></li>
<li><a href="p_accessors_macros_desugar.html">p_accessors_macros_desugar</a></li>
<li><a href="p_accessors_macros_read.html">p_accessors_macros_read</a></li>
<li><a href="p_accessors_macros_write.html">p_accessors_macros_write</a></li>
<li><a href="p_checks.html">p_checks</a></li>
<li><a href="p_complex.html">p_complex</a></li>
<li><a href="p_display.html">p_display</a></li>
<li><a href="p_empty_tensors.html">p_empty_tensors</a></li>
<li><a href="p_init_cuda.html">p_init_cuda</a></li>
<li><a href="p_init_opencl.html">p_init_opencl</a></li>
<li><a href="p_kernels_interface_cuda.html">p_kernels_interface_cuda</a></li>
<li><a href="p_kernels_interface_opencl.html">p_kernels_interface_opencl</a></li>
<li><a href="p_operator_blas_l2l3.html">p_operator_blas_l2l3</a></li>
<li><a href="p_shapeshifting.html">p_shapeshifting</a></li>
<li><a href="selectors.html">selectors</a></li>
<li><a href="shapeshifting.html">shapeshifting</a></li>
<li><a href="shapeshifting_cuda.html">shapeshifting_cuda</a></li>
<li><a href="shapeshifting_opencl.html">shapeshifting_opencl</a></li>
<li><a href="syntactic_sugar.html">syntactic_sugar</a></li>
<li><a href="tensor_cuda.html">tensor_cuda</a></li>
<li><a href="tensor_opencl.html">tensor_opencl</a></li>
<li><a href="ufunc.html">ufunc</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Neural network API</a>
        <ul class="monospace">
          <li><a href="conv2D.html">Layers: Convolution 2D</a></li>
<li><a href="cross_entropy_losses.html">Loss: Cross-Entropy losses</a></li>
<li><a href="embedding.html">Layers: Embedding</a></li>
<li><a href="flatten.html">flatten</a></li>
<li><a href="gcn.html">gcn</a></li>
<li><a href="gru.html">Layers: GRU (Gated Linear Unit)</a></li>
<li><a href="init.html">Layers: Initializations</a></li>
<li><a href="linear.html">Layers: Linear/Dense</a></li>
<li><a href="maxpool2D.html">Layers: Maxpool 2D</a></li>
<li><a href="mean_square_error_loss.html">Loss: Mean Square Error</a></li>
<li><a href="nn_dsl.html">Neural network: Declaration</a></li>
<li><a href="optimizers.html">Optimizers</a></li>
<li><a href="relu.html">Activation: Relu (Rectified linear Unit)</a></li>
<li><a href="sigmoid.html">Activation: Sigmoid</a></li>
<li><a href="softmax.html">Softmax</a></li>
<li><a href="tanh.html">Activation: Tanh</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Linear algebra, stats, ML</a>
        <ul class="monospace">
          <li><a href="accuracy_score.html">Accuracy score</a></li>
<li><a href="algebra.html">algebra</a></li>
<li><a href="auxiliary_blas.html">auxiliary_blas</a></li>
<li><a href="auxiliary_lapack.html">auxiliary_lapack</a></li>
<li><a href="common_error_functions.html">Common errors, MAE and MSE (L1, L2 loss)</a></li>
<li><a href="dbscan.html">dbscan</a></li>
<li><a href="decomposition.html">Eigenvalue decomposition</a></li>
<li><a href="decomposition_lapack.html">decomposition_lapack</a></li>
<li><a href="decomposition_rand.html">Randomized Truncated SVD</a></li>
<li><a href="distributions.html">distributions</a></li>
<li><a href="init_colmajor.html">init_colmajor</a></li>
<li><a href="kde.html">kde</a></li>
<li><a href="kmeans.html">K-Means</a></li>
<li><a href="least_squares.html">Least squares solver</a></li>
<li><a href="least_squares_lapack.html">least_squares_lapack</a></li>
<li><a href="linear_systems.html">Linear systems solver</a></li>
<li><a href="overload.html">overload</a></li>
<li><a href="pca.html">Principal Component Analysis (PCA)</a></li>
<li><a href="solve_lapack.html">solve_lapack</a></li>
<li><a href="special_matrices.html">Special linear algebra matrices</a></li>
<li><a href="stats.html">Statistics</a></li>
<li><a href="triangular.html">triangular</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">IO & Datasets</a>
        <ul class="monospace">
          <li><a href="imdb.html">IMDB</a></li>
<li><a href="io_csv.html">CSV reading and writing</a></li>
<li><a href="io_hdf5.html">HDF5 files reading and writing</a></li>
<li><a href="io_image.html">Images reading and writing</a></li>
<li><a href="io_npy.html">Numpy files reading and writing</a></li>
<li><a href="io_stream_readers.html">io_stream_readers</a></li>
<li><a href="mnist.html">MNIST</a></li>
<li><a href="util.html">util</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Autograd</a>
        <ul class="monospace">
          <li><a href="autograd_common.html">Data structure</a></li>
<li><a href="gates_basic.html">Basic operations</a></li>
<li><a href="gates_blas.html">Linear algebra operations</a></li>
<li><a href="gates_hadamard.html">Hadamard product (elementwise matrix multiply)</a></li>
<li><a href="gates_reduce.html">Reduction operations</a></li>
<li><a href="gates_shapeshifting_concat_split.html">Concatenation, stacking, splitting, chunking operations</a></li>
<li><a href="gates_shapeshifting_views.html">Linear algebra operations</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Neuralnet primitives</a>
        <ul class="monospace">
          <li><a href="conv.html">conv</a></li>
<li><a href="cudnn.html">cudnn</a></li>
<li><a href="cudnn_conv_interface.html">cudnn_conv_interface</a></li>
<li><a href="nnp_activation.html">Activations</a></li>
<li><a href="nnp_conv2d_cudnn.html">Convolution 2D - CuDNN</a></li>
<li><a href="nnp_convolution.html">Convolution 2D</a></li>
<li><a href="nnp_embedding.html">Embeddings</a></li>
<li><a href="nnp_gru.html">Gated Recurrent Unit (GRU)</a></li>
<li><a href="nnp_linear.html">Linear / Dense layer</a></li>
<li><a href="nnp_maxpooling.html">Maxpooling</a></li>
<li><a href="nnp_numerical_gradient.html">Numerical gradient</a></li>
<li><a href="nnp_sigmoid_cross_entropy.html">Sigmoid Cross-Entropy loss</a></li>
<li><a href="nnp_softmax.html">Softmax</a></li>
<li><a href="nnp_softmax_cross_entropy.html">Softmax Cross-Entropy loss</a></li>
<li><a href="nnpack.html">nnpack</a></li>
<li><a href="nnpack_interface.html">nnpack_interface</a></li>
<li><a href="p_activation.html">p_activation</a></li>
<li><a href="p_logsumexp.html">p_logsumexp</a></li>
<li><a href="p_nnp_checks.html">p_nnp_checks</a></li>
<li><a href="p_nnp_types.html">p_nnp_types</a></li>
        </ul>
      </li>
      </span>
      <span>
      <li>
        <a href="#">Other docs</a>
        <ul class="monospace">
          <li><a href="align_unroller.html">align_unroller</a></li>
<li><a href="ast_utils.html">ast_utils</a></li>
<li><a href="compiler_optim_hints.html">compiler_optim_hints</a></li>
<li><a href="cpuinfo_x86.html">cpuinfo_x86</a></li>
<li><a href="datatypes.html">datatypes</a></li>
<li><a href="deprecate.html">deprecate</a></li>
<li><a href="dynamic_stack_arrays.html">dynamic_stack_arrays</a></li>
<li><a href="foreach.html">foreach</a></li>
<li><a href="foreach_common.html">foreach_common</a></li>
<li><a href="foreach_staged.html">foreach_staged</a></li>
<li><a href="functional.html">functional</a></li>
<li><a href="gemm.html">gemm</a></li>
<li><a href="gemm_packing.html">gemm_packing</a></li>
<li><a href="gemm_prepacked.html">gemm_prepacked</a></li>
<li><a href="gemm_tiling.html">gemm_tiling</a></li>
<li><a href="gemm_ukernel_avx.html">gemm_ukernel_avx</a></li>
<li><a href="gemm_ukernel_avx2.html">gemm_ukernel_avx2</a></li>
<li><a href="gemm_ukernel_avx512.html">gemm_ukernel_avx512</a></li>
<li><a href="gemm_ukernel_avx_fma.html">gemm_ukernel_avx_fma</a></li>
<li><a href="gemm_ukernel_dispatch.html">gemm_ukernel_dispatch</a></li>
<li><a href="gemm_ukernel_generator.html">gemm_ukernel_generator</a></li>
<li><a href="gemm_ukernel_generic.html">gemm_ukernel_generic</a></li>
<li><a href="gemm_ukernel_sse.html">gemm_ukernel_sse</a></li>
<li><a href="gemm_ukernel_sse2.html">gemm_ukernel_sse2</a></li>
<li><a href="gemm_ukernel_sse4_1.html">gemm_ukernel_sse4_1</a></li>
<li><a href="gemm_utils.html">gemm_utils</a></li>
<li><a href="global_config.html">global_config</a></li>
<li><a href="initialization.html">initialization</a></li>
<li><a href="math_ops_fusion.html">math_ops_fusion</a></li>
<li><a href="memory.html">memory</a></li>
<li><a href="nested_containers.html">nested_containers</a></li>
<li><a href="openmp.html">openmp</a></li>
<li><a href="sequninit.html">sequninit</a></li>
<li><a href="simd.html">simd</a></li>
<li><a href="tokenizers.html">tokenizers</a></li>
        </ul>
      </li>
      </span>
    </ul>
  </span>
  <span>
    <a href="#">Tutorial</a>
    <ul class="monospace">
      <li><a href="tuto.first_steps.html">First steps</a></li>
      <li><a href="tuto.slicing.html">Taking a slice of a tensor</a></li>
      <li><a href="tuto.linear_algebra.html">Matrix & vectors operations</a></li>
      <li><a href="tuto.broadcasting.html">Broadcasted operations</a></li>
      <li><a href="tuto.shapeshifting.html">Transposing, Reshaping, Permuting, Concatenating</a></li>
      <li><a href="tuto.map_reduce.html">Map & Reduce</a></li>
      <li><a href="tuto.iterators.html">Basic iterators</a></li>
    </ul>
  </span>
  <span>
    <a href="#">Spellbook (How-To&apos;s)</a>
    <ul class="monospace">
      <li><a href="howto.type_conversion.html">How to convert a Tensor type?</a></li>
      <li><a href="howto.ufunc.html">How to create a new universal function?</a></li>
      <li><a href="howto.perceptron.html">How to create a multilayer perceptron?</a></li>
    </ul>
  </span>
  <span>
    <a href="#">Under the hood</a>
    <ul class="monospace">
      <li><a href="uth.speed.html">How Arraymancer achieves its speed?</a></li>
      <li><a href="uth.copy_semantics.html">Why does `=` share data by default aka reference semantics?</a></li>
      <li><a href="uth.opencl_cuda_nim.html">Working with OpenCL and Cuda in Nim</a></li>
    </ul>
  </span>
</header>
</body>
</html>
